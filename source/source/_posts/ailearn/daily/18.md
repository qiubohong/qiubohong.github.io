---
title: 5åˆ†é’ŸAIï¼Œæ¯å¤©ææ‡‚ä¸€ä¸ªçŸ¥è¯†ç‚¹(18) - RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ
date: 2026-02-18 12:00:00
toc: true
tags:
  - å­¦ä¹ æ€»ç»“
  - 5åˆ†é’ŸAI
---

> åšä¸€ä¸ªæœ‰æ¸©åº¦å’Œæœ‰å¹²è´§çš„æŠ€æœ¯åˆ†äº«ä½œè€… â€”â€” [Qborfy](https://qborfy.com)

ä»Šå¤©æˆ‘ä»¬æ¥å­¦ä¹  **RAGï¼ˆRetrieval-Augmented Generationï¼‰æ£€ç´¢å¢å¼ºç”Ÿæˆ**

> ä¸€å¥è¯æ ¸å¿ƒ: **RAG** æ˜¯ä¸€ç§è®©å¤§æ¨¡å‹èƒ½å¤Ÿ"æŸ¥èµ„æ–™å†å›ç­”"çš„æŠ€æœ¯ï¼Œé€šè¿‡æ£€ç´¢å¤–éƒ¨çŸ¥è¯†åº“æ¥å¢å¼ºç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ã€‚

é€šä¿—åœ°è®²ï¼Œå¦‚æœæŠŠå¤§æ¨¡å‹æ¯”ä½œä¸€ä¸ªå­¦ç”Ÿï¼Œä¼ ç»Ÿæ¨¡å‹å°±åƒ"é—­å·è€ƒè¯•"â€”â€”åªèƒ½å‡­å€Ÿè®­ç»ƒæ—¶è®°ä½çš„çŸ¥è¯†å›ç­”é—®é¢˜ã€‚è€Œ RAG å°±åƒ"å¼€å·è€ƒè¯•"â€”â€”é‡åˆ°é—®é¢˜æ—¶ï¼Œå¯ä»¥å…ˆç¿»ä¹¦æŸ¥èµ„æ–™ï¼Œç„¶ååŸºäºæŸ¥åˆ°çš„å†…å®¹ç»™å‡ºæ›´å‡†ç¡®çš„ç­”æ¡ˆã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒRAG å¹¶ä¸æ˜¯è®©æ¨¡å‹"è®°ä½"æ–°çŸ¥è¯†ï¼Œè€Œæ˜¯åœ¨å›ç­”é—®é¢˜æ—¶åŠ¨æ€åœ°ä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶åå°†è¿™äº›ä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™æ¨¡å‹ã€‚

å®ƒçš„æ ¸å¿ƒä»·å€¼åœ¨äº**è§£å†³å¤§æ¨¡å‹çš„çŸ¥è¯†å±€é™æ€§**ï¼šåŒ…æ‹¬çŸ¥è¯†è¿‡æ—¶ã€ç¼ºä¹ä¸“ä¸šé¢†åŸŸçŸ¥è¯†ã€å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼ˆç¼–é€ ä¸å­˜åœ¨çš„ä¿¡æ¯ï¼‰ç­‰é—®é¢˜ã€‚é€šè¿‡ RAGï¼Œæˆ‘ä»¬å¯ä»¥è®©æ¨¡å‹è®¿é—®æœ€æ–°çš„ã€ä¸“ä¸šçš„ã€ç§æœ‰çš„çŸ¥è¯†ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

<!-- more -->

# æ˜¯ä»€ä¹ˆ

```mermaid
---
config:
  layout: elk
  look: neo
---
flowchart TB
 subgraph a["ç¥ç»ç½‘ç»œ"]
        a1["æ¿€æ´»å‡½æ•°"]
        a2["æŸå¤±å‡½æ•°"]
        a3["ç¥ç»å…ƒè®¡ç®—"]
  end
 subgraph D["Transformer"]
        d1["Encoder"]
        d2["Self-Attendtion"]
        d3["Decoder"]
  end
    0["äººå·¥æ™ºèƒ½"] --> 1["ç®—æ³•"] & 2["åº”ç”¨"]
    1 --> a & b["æœºå™¨å­¦ä¹ "]
    b --> b1["ç›‘ç£å­¦ä¹ "] & b2["æ— ç›‘ç£å­¦ä¹ "] & b3["å¼ºåŒ–å­¦ä¹ "]
    a --> A["æ·±åº¦å­¦ä¹ "]
    A --> B["å·ç§¯ç½‘ç»œ CNN"] & C["å¾ªç¯ç½‘ç»œ RNN"] & D
    D --> E["LLMå¤§æ¨¡å‹"]
    E --> e1["Tokenåˆ†è¯"] & e2["EmbeddingåµŒå…¥ç¼–ç "] & e3["Transformer å±‚å å¤„ç†"] & e4["Out Token"] & F["Function Calling"] & F1["MCPåè®®"]
    e1 --> e11["Tokenizeråˆ†è¯ç­–ç•¥"] & e12["Tokenè®¡è´¹è§„åˆ™"]
    e2 --> e21["è¯åµŒå…¥ï¼ˆWord Embeddingsï¼‰"] & e22["åµŒå…¥å±‚ï¼ˆEmbedding Layerï¼‰"] & e23["Transformerç¼–ç å™¨"] & e24["æ± åŒ–å±‚"] & e25["å½’ä¸€åŒ–è¾“å‡º"]
    F1 --> f11["MCP Server"] & f12["MCP Protocol"] & f13["MCP Client"]
    2 --> 20["AI Agent"] & 21["åœºæ™¯&äº§å“"] & 22["å¼€å‘æ¡†æ¶"]
    20 --> 201["å•å‘æ— è®°å¿†å·¥ä½œæµ"] & 202["å¾ªç¯å¯ä¸­æ–­è®°å¿†"] & 203["é€šç”¨å¤šæ¨¡æ€Agent"]
    21 --> 211["AIç¼–ç¨‹"] & 212["AIæ™ºèƒ½å®¢æœ|åŠ©æ‰‹"]
    211 --> 211a["Claude"] & 211b["Cursor"] & 211c["Codex"] & 211d["CodeBuddy(è…¾è®¯)"] & 211e["Qwen Code(é˜¿é‡Œ)"] & 221f["Gemini CLI"] & 221g["Trae(æŠ–éŸ³)"]
    211a --> 211a1["SKILLæŠ€èƒ½"] --> 211a11["SKILL.md"] & 211a12["resource & scripts"]
    212 --> 212a["æ„å›¾è¯†åˆ«"] & 212b["ReQuery"] & 212c["RAG"] & 212d["Embedding"] & 212e["Reranker"]
    22 --> 221["Dify(å¯è§†åŒ–)"] & 222["Coze(å¯è§†åŒ–)"] & 223["n8n(å¯è§†åŒ–)"] & 224["Langchain"] & 225["CrewAI"] & 226["LlamaIndex"]

    0@{ shape: rounded}
     211a1:::orange
    classDef orange fill:#F9B572,stroke:#FF772E
```

é€šè¿‡ä¸€å¼ å›¾æ¥ç†è§£ RAG çš„å·¥ä½œåŸç†ï¼š

```mermaid
graph TB
    subgraph ç¦»çº¿é˜¶æ®µ["ğŸ“š ç¦»çº¿é˜¶æ®µï¼šçŸ¥è¯†åº“æ„å»º"]
        A1["åŸå§‹æ–‡æ¡£<br/>(PDF/Word/ç½‘é¡µç­‰)"] --> A2["æ–‡æœ¬æå–"]
        A2 --> A3["æ–‡æ¡£åˆ†å—<br/>(Chunking)"]
        A3 --> A4["å‘é‡åŒ–<br/>(Embedding)"]
        A4 --> A5[("å‘é‡æ•°æ®åº“<br/>(Vector DB)")]
    end

    subgraph åœ¨çº¿é˜¶æ®µ["ğŸ”„ åœ¨çº¿é˜¶æ®µï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ"]
        B1["ğŸ‘¤ ç”¨æˆ·æé—®"] --> B2["é—®é¢˜å‘é‡åŒ–<br/>(Embedding)"]
        B2 --> B3["è¯­ä¹‰æ£€ç´¢<br/>(Similarity Search)"]
        A5 -.æ£€ç´¢.-> B3
        B3 --> B4["ğŸ“„ ç›¸å…³æ–‡æ¡£<br/>(Top-K)"]
        B4 --> B5["æ„å»ºæç¤ºè¯<br/>(Prompt)"]
        B1 -.åŸå§‹é—®é¢˜.-> B5
        B5 --> B6["ğŸ¤– å¤§è¯­è¨€æ¨¡å‹<br/>(LLM)"]
        B6 --> B7["âœ… ç”Ÿæˆç­”æ¡ˆ<br/>(å¸¦å¼•ç”¨æ¥æº)"]
    end

    style A5 fill:#e1f5ff,stroke:#01579b
    style B6 fill:#fff3e0,stroke:#e65100
    style B7 fill:#e8f5e9,stroke:#2e7d32
    style ç¦»çº¿é˜¶æ®µ fill:#f5f5f5,stroke:#9e9e9e
    style åœ¨çº¿é˜¶æ®µ fill:#fafafa,stroke:#616161
```

**RAG å·¥ä½œæµç¨‹è¯´æ˜**ï¼š

è¿™ä¸ªæµç¨‹çš„æ ¸å¿ƒåœ¨äºï¼Œç”¨æˆ·çš„é—®é¢˜ä¼šç»è¿‡**ä¸¤ä¸ªå…³é”®é˜¶æ®µ**ï¼š

1. **ç¦»çº¿é˜¶æ®µï¼ˆçŸ¥è¯†åº“æ„å»ºï¼‰**ï¼š

   - å°†åŸå§‹æ–‡æ¡£è¿›è¡Œæ–‡æœ¬æå–å’Œåˆ†å—å¤„ç†
   - ä½¿ç”¨ Embedding æ¨¡å‹å°†æ–‡æœ¬å—è½¬æ¢ä¸ºå‘é‡
   - å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œè¿™ä¸ªè¿‡ç¨‹åªéœ€è¦æ‰§è¡Œä¸€æ¬¡

2. **åœ¨çº¿é˜¶æ®µï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰**ï¼š
   - ç”¨æˆ·æé—®åï¼Œå…ˆå°†é—®é¢˜å‘é‡åŒ–
   - åœ¨å‘é‡æ•°æ®åº“ä¸­è¿›è¡Œè¯­ä¹‰æ£€ç´¢ï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£å—
   - å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£å’ŒåŸå§‹é—®é¢˜ä¸€èµ·æ„å»ºæç¤ºè¯
   - è¾“å…¥å¤§æ¨¡å‹ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œå¹¶é™„å¸¦å¼•ç”¨æ¥æº

## RAG çš„æ ¸å¿ƒç»„æˆ

ä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿé€šå¸¸åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼š

### 1. çŸ¥è¯†åº“æ„å»º

**æ–‡æ¡£å¤„ç†æµç¨‹**ï¼š

```
åŸå§‹æ–‡æ¡£ â†’ æ–‡æœ¬æå– â†’ åˆ†å—ï¼ˆChunkingï¼‰ â†’ å‘é‡åŒ–ï¼ˆEmbeddingï¼‰ â†’ å­˜å…¥å‘é‡æ•°æ®åº“
```

- **æ–‡æ¡£åŠ è½½**ï¼šæ”¯æŒ PDFã€Wordã€ç½‘é¡µã€Markdown ç­‰å¤šç§æ ¼å¼
- **æ–‡æœ¬åˆ†å—**ï¼šå°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆå°å—ï¼Œä¾¿äºæ£€ç´¢å’Œå¤„ç†
- **å‘é‡åŒ–**ï¼šä½¿ç”¨ Embedding æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
- **å‘é‡å­˜å‚¨**ï¼šå°†å‘é‡å­˜å…¥ä¸“é—¨çš„å‘é‡æ•°æ®åº“

### 2. æ£€ç´¢ç³»ç»Ÿ

- **è¯­ä¹‰æ£€ç´¢**ï¼šåŸºäºé—®é¢˜çš„è¯­ä¹‰å«ä¹‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£
- **æ··åˆæ£€ç´¢**ï¼šç»“åˆå…³é”®è¯æ£€ç´¢å’Œè¯­ä¹‰æ£€ç´¢
- **é‡æ’åºï¼ˆRerankingï¼‰**ï¼šå¯¹æ£€ç´¢ç»“æœè¿›è¡ŒäºŒæ¬¡æ’åºï¼Œæé«˜ç›¸å…³æ€§

### 3. ç”Ÿæˆç³»ç»Ÿ

- **æç¤ºè¯å·¥ç¨‹**ï¼šè®¾è®¡åˆé€‚çš„ Prompt æ¨¡æ¿
- **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šæ§åˆ¶è¾“å…¥å¤§æ¨¡å‹çš„æ–‡æ¡£é•¿åº¦
- **ç­”æ¡ˆç”Ÿæˆ**ï¼šåŸºäºæ£€ç´¢å†…å®¹ç”Ÿæˆæœ€ç»ˆå›ç­”

## RAG vs å…¶ä»–æ–¹æ³•å¯¹æ¯”

| **ç»´åº¦** | ä¼ ç»Ÿå¤§æ¨¡å‹   | Fine-tuning  | RAG                  |
| -------- | ------------ | ------------ | -------------------- |
| çŸ¥è¯†æ›´æ–° | éœ€è¦é‡æ–°è®­ç»ƒ | éœ€è¦é‡æ–°å¾®è°ƒ | å®æ—¶æ›´æ–°æ–‡æ¡£å³å¯     |
| æˆæœ¬     | æ¨ç†æˆæœ¬     | è®­ç»ƒæˆæœ¬é«˜   | ä¸­ç­‰ï¼ˆæ£€ç´¢+æ¨ç†ï¼‰    |
| å‡†ç¡®æ€§   | å¯èƒ½äº§ç”Ÿå¹»è§‰ | è¾ƒå‡†ç¡®ä½†å›ºåŒ– | åŸºäºçœŸå®æ–‡æ¡£ï¼Œå¯è¿½æº¯ |
| ä¸“ä¸šçŸ¥è¯† | é€šç”¨çŸ¥è¯†     | å¯å®šåˆ¶       | çµæ´»æ·»åŠ ä¸“ä¸šæ–‡æ¡£     |
| å¯è§£é‡Šæ€§ | é»‘ç›’         | é»‘ç›’         | å¯è¿½æº¯åˆ°æºæ–‡æ¡£       |

# æ€ä¹ˆåš

ä¸‹é¢æˆ‘ä»¬é€šè¿‡å‡ ä¸ªæ¡ˆä¾‹æ¥ç†è§£ RAG çš„ä½¿ç”¨åœºæ™¯å’Œå®ç°æ–¹å¼ã€‚

## æ¡ˆä¾‹ 1ï¼šä¼ä¸šçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ

è¿™æ˜¯ RAG æœ€ç»å…¸çš„åº”ç”¨åœºæ™¯ï¼Œå¸®åŠ©å‘˜å·¥å¿«é€ŸæŸ¥è¯¢å…¬å¸å†…éƒ¨æ–‡æ¡£ã€‚

**åœºæ™¯æè¿°**ï¼š

- å…¬å¸æœ‰å¤§é‡å†…éƒ¨æ–‡æ¡£ï¼šäº§å“æ‰‹å†Œã€æŠ€æœ¯æ–‡æ¡£ã€è§„ç« åˆ¶åº¦ç­‰
- å‘˜å·¥éœ€è¦å¿«é€Ÿæ‰¾åˆ°ç›¸å…³ä¿¡æ¯
- ä¼ ç»Ÿæœç´¢åªèƒ½æ‰¾åˆ°æ–‡æ¡£ï¼Œè¿˜éœ€è¦äººå·¥é˜…è¯»

**RAG è§£å†³æ–¹æ¡ˆ**ï¼š

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. æ–‡æ¡£å‡†å¤‡é˜¶æ®µï¼ˆç¦»çº¿å¤„ç†ï¼‰
documents = [
    "å…¬å¸å¹´å‡æ”¿ç­–ï¼šå‘˜å·¥å…¥èŒæ»¡ä¸€å¹´äº«æœ‰5å¤©å¹´å‡...",
    "æŠ¥é”€æµç¨‹ï¼šå‘˜å·¥éœ€åœ¨è´¹ç”¨å‘ç”Ÿå30å¤©å†…æäº¤...",
    "æŠ€æœ¯æ ˆè§„èŒƒï¼šå‰ç«¯ç»Ÿä¸€ä½¿ç”¨ React + TypeScript..."
]

# 2. æ–‡æœ¬åˆ†å—
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
chunks = text_splitter.create_documents(documents)

# 3. æ–‡æ¡£å‘é‡åŒ–å¹¶å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(chunks, embeddings)

# 4. ç”¨æˆ·æé—®
question = "æˆ‘å…¥èŒåŠå¹´äº†ï¼Œå¯ä»¥è¯·å¹´å‡å—ï¼Ÿ"

# 5. æ£€ç´¢ç›¸å…³æ–‡æ¡£
relevant_docs = vectorstore.similarity_search(question, k=3)

# 6. æ„å»ºæç¤ºè¯
prompt = f"""
åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{relevant_docs[0].page_content}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å‡†ç¡®å›ç­”ï¼Œå¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚
"""

# 7. è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt}]
)

print(response.choices[0].message.content)
# è¾“å‡ºï¼šæ ¹æ®å…¬å¸å¹´å‡æ”¿ç­–ï¼Œå‘˜å·¥éœ€è¦å…¥èŒæ»¡ä¸€å¹´æ‰èƒ½äº«æœ‰å¹´å‡ã€‚
# æ‚¨ç›®å‰å…¥èŒåŠå¹´ï¼Œæš‚æ—¶è¿˜ä¸ç¬¦åˆå¹´å‡ç”³è¯·æ¡ä»¶ã€‚
```

## æ¡ˆä¾‹ 2ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

**åœºæ™¯**ï¼šç”µå•†å¹³å°éœ€è¦è‡ªåŠ¨å›ç­”ç”¨æˆ·å…³äºå•†å“ã€ç‰©æµã€å”®åçš„é—®é¢˜ã€‚

**å®ç°è¦ç‚¹**ï¼š

- **çŸ¥è¯†åº“**ï¼šå•†å“ä¿¡æ¯ã€å¸¸è§é—®é¢˜ã€ç‰©æµæ”¿ç­–ã€å”®åæµç¨‹
- **æ£€ç´¢ç­–ç•¥**ï¼šæ··åˆæ£€ç´¢ï¼ˆå…³é”®è¯ + è¯­ä¹‰ï¼‰
- **ç­”æ¡ˆç”Ÿæˆ**ï¼šå‹å¥½çš„å¯¹è¯å¼å›ç­”

```python
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# åˆ›å»º RAG é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0),
    chain_type="stuff",  # å°†æ‰€æœ‰æ£€ç´¢æ–‡æ¡£ä¸€æ¬¡æ€§è¾“å…¥
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True  # è¿”å›æºæ–‡æ¡£
)

# ç”¨æˆ·æé—®
result = qa_chain({"query": "iPhone 15 Pro æ”¯æŒå“ªäº›é¢œè‰²ï¼Ÿ"})

print(f"ç­”æ¡ˆï¼š{result['result']}")
print(f"æ¥æºï¼š{result['source_documents'][0].metadata['source']}")
```

## æ¡ˆä¾‹ 3ï¼šå­¦æœ¯è®ºæ–‡åŠ©æ‰‹

**åœºæ™¯**ï¼šç ”ç©¶äººå‘˜éœ€è¦å¿«é€ŸæŸ¥è¯¢å’Œç†è§£å¤§é‡å­¦æœ¯è®ºæ–‡ã€‚

**æŠ€æœ¯äº®ç‚¹**ï¼š

- **æ–‡æ¡£åˆ†å—ç­–ç•¥**ï¼šæŒ‰æ®µè½æˆ–å›ºå®šé•¿åº¦åˆ†å—
- **å…ƒæ•°æ®ç®¡ç†**ï¼šä¿å­˜è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å‘è¡¨æ—¶é—´ç­‰
- **å¼•ç”¨è¿½è¸ª**ï¼šæ˜¾ç¤ºç­”æ¡ˆæ¥è‡ªå“ªç¯‡è®ºæ–‡çš„å“ªä¸ªéƒ¨åˆ†

```python
from langchain.document_loaders import PyPDFLoader

# 1. åŠ è½½ PDF è®ºæ–‡
loader = PyPDFLoader("research_paper.pdf")
documents = loader.load()

# 2. æ™ºèƒ½åˆ†å—
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  # æ¯å—æœ€å¤§å­—ç¬¦æ•°
    chunk_overlap=200,  # å—ä¹‹é—´é‡å å­—ç¬¦æ•°
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""]
)
chunks = text_splitter.split_documents(documents)

# 3. æ·»åŠ å…ƒæ•°æ®
for i, chunk in enumerate(chunks):
    chunk.metadata.update({
        "source": "research_paper.pdf",
        "page": chunk.metadata.get("page", 0),
        "chunk_id": i
    })

# 4. å­˜å…¥å‘é‡æ•°æ®åº“
vectorstore = Chroma.from_documents(chunks, embeddings)
```

## å®æˆ˜æ¡ˆä¾‹ï¼šå®Œæ•´çš„ RAG ç³»ç»Ÿ

ä¸‹é¢æˆ‘ä»¬ç”¨ LangChain å®ç°ä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿï¼š

```python
from langchain.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# ========== ç¬¬ä¸€æ­¥ï¼šæ–‡æ¡£åŠ è½½ ==========
print("æ­£åœ¨åŠ è½½æ–‡æ¡£...")
loader = DirectoryLoader(
    './knowledge_base/',  # çŸ¥è¯†åº“ç›®å½•
    glob="**/*.txt",      # åŠ è½½æ‰€æœ‰ txt æ–‡ä»¶
    loader_cls=TextLoader
)
documents = loader.load()
print(f"å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")

# ========== ç¬¬äºŒæ­¥ï¼šæ–‡æ¡£åˆ†å— ==========
print("æ­£åœ¨åˆ†å—å¤„ç†...")
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
chunks = text_splitter.split_documents(documents)
print(f"å·²åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")

# ========== ç¬¬ä¸‰æ­¥ï¼šå‘é‡åŒ–å¹¶å­˜å‚¨ ==========
print("æ­£åœ¨å‘é‡åŒ–...")
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./chroma_db"  # æŒä¹…åŒ–å­˜å‚¨
)
print("å‘é‡æ•°æ®åº“å·²åˆ›å»º")

# ========== ç¬¬å››æ­¥ï¼šåˆ›å»º RAG é“¾ ==========
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0, model="gpt-4"),
    chain_type="stuff",
    retriever=vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 3}  # æ£€ç´¢æœ€ç›¸å…³çš„ 3 ä¸ªæ–‡æ¡£å—
    ),
    return_source_documents=True
)

# ========== ç¬¬äº”æ­¥ï¼šäº¤äº’å¼é—®ç­” ==========
print("\nçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º\n")

while True:
    question = input("è¯·è¾“å…¥é—®é¢˜ï¼š")
    if question.lower() == 'quit':
        break

    result = qa_chain({"query": question})

    print(f"\nç­”æ¡ˆï¼š{result['result']}\n")
    print("å‚è€ƒæ¥æºï¼š")
    for i, doc in enumerate(result['source_documents'], 1):
        print(f"{i}. {doc.metadata.get('source', 'æœªçŸ¥æ¥æº')}")
    print("-" * 50 + "\n")
```

## è¿›é˜¶æŠ€å·§

### 1. æ··åˆæ£€ç´¢ï¼ˆHybrid Searchï¼‰

ç»“åˆå…³é”®è¯æ£€ç´¢å’Œè¯­ä¹‰æ£€ç´¢ï¼Œæé«˜å‡†ç¡®ç‡ï¼š

```python
from langchain.retrievers import BM25Retriever, EnsembleRetriever

# å…³é”®è¯æ£€ç´¢å™¨
bm25_retriever = BM25Retriever.from_documents(chunks)
bm25_retriever.k = 3

# è¯­ä¹‰æ£€ç´¢å™¨
semantic_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# æ··åˆæ£€ç´¢å™¨
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, semantic_retriever],
    weights=[0.5, 0.5]  # å„å  50% æƒé‡
)
```

### 2. é‡æ’åºï¼ˆRerankingï¼‰

å¯¹æ£€ç´¢ç»“æœè¿›è¡ŒäºŒæ¬¡æ’åºï¼Œæé«˜ç›¸å…³æ€§ï¼š

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CohereRerank

# ä½¿ç”¨ Cohere çš„é‡æ’åºæ¨¡å‹
compressor = CohereRerank(model="rerank-english-v2.0")
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=vectorstore.as_retriever()
)
```

### 3. å¤šæŸ¥è¯¢æ£€ç´¢ï¼ˆMulti-Query Retrievalï¼‰

è‡ªåŠ¨ç”Ÿæˆå¤šä¸ªç›¸å…³æŸ¥è¯¢ï¼Œæ‰©å¤§æ£€ç´¢èŒƒå›´ï¼š

```python
from langchain.retrievers.multi_query import MultiQueryRetriever

multi_query_retriever = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(),
    llm=OpenAI(temperature=0)
)

# ä¼šè‡ªåŠ¨ç”Ÿæˆå¤šä¸ªç›¸å…³é—®é¢˜è¿›è¡Œæ£€ç´¢
results = multi_query_retriever.get_relevant_documents(
    "ä»€ä¹ˆæ˜¯ RAGï¼Ÿ"
)
```

# â„ï¸ å†·çŸ¥è¯†

1. **åˆ†å—å¤§å°å¾ˆå…³é”®**ï¼š`chunk_size` å¤ªå°ä¼šä¸¢å¤±ä¸Šä¸‹æ–‡ï¼Œå¤ªå¤§ä¼šå¼•å…¥å™ªéŸ³ã€‚ä¸€èˆ¬å»ºè®® 500-1000 å­—ç¬¦ï¼Œå…·ä½“å–å†³äºæ–‡æ¡£ç±»å‹ã€‚ä¸­æ–‡æ–‡æ¡£é€šå¸¸æ¯”è‹±æ–‡éœ€è¦æ›´å°çš„ `chunk_size`ã€‚

2. **Overlap ä¸æ˜¯è¶Šå¤§è¶Šå¥½**ï¼š`chunk_overlap`ï¼ˆé‡å éƒ¨åˆ†ï¼‰æ˜¯ä¸ºäº†é¿å…é‡è¦ä¿¡æ¯è¢«åˆ‡æ–­ï¼Œä½†è¿‡å¤§ä¼šå¯¼è‡´é‡å¤å†…å®¹è¿‡å¤šï¼Œå½±å“æ£€ç´¢æ•ˆç‡ã€‚ä¸€èˆ¬è®¾ç½®ä¸º `chunk_size` çš„ 10-20%ã€‚

3. **å‘é‡æ•°æ®åº“çš„é€‰æ‹©**ï¼š

   - **Chroma**ï¼šè½»é‡çº§ï¼Œé€‚åˆåŸå‹å¼€å‘
   - **Pinecone**ï¼šäº‘æœåŠ¡ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ
   - **Milvus**ï¼šå¼€æºï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²
   - **Weaviate**ï¼šæ”¯æŒæ··åˆæ£€ç´¢ï¼ŒåŠŸèƒ½å¼ºå¤§

4. **Embedding æ¨¡å‹çš„å½±å“**ï¼šä¸åŒçš„ Embedding æ¨¡å‹ä¼šæ˜¾è‘—å½±å“æ£€ç´¢æ•ˆæœã€‚OpenAI çš„ `text-embedding-3-large` æ•ˆæœå¥½ä½†æˆæœ¬é«˜ï¼Œå›½äº§æ¨¡å‹å¦‚æ™ºè°±çš„ `embedding-2` æ€§ä»·æ¯”æ›´é«˜ã€‚

5. **RAG çš„"å¹»è§‰"é—®é¢˜**ï¼šè™½ç„¶ RAG èƒ½å‡å°‘å¹»è§‰ï¼Œä½†å¦‚æœæ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ç›¸å…³ï¼Œæ¨¡å‹ä»å¯èƒ½åŸºäºé”™è¯¯ä¿¡æ¯ç”Ÿæˆç­”æ¡ˆã€‚å› æ­¤**æ£€ç´¢è´¨é‡æ˜¯ RAG ç³»ç»Ÿçš„æ ¸å¿ƒ**ã€‚

6. **ä¸ Function Calling çš„å…³ç³»**ï¼šRAG å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§ç‰¹æ®Šçš„ Function Callingï¼Œå…¶ä¸­"å‡½æ•°"å°±æ˜¯"æ£€ç´¢çŸ¥è¯†åº“"ã€‚å®é™…åº”ç”¨ä¸­ï¼Œä¸¤è€…å¸¸å¸¸ç»“åˆä½¿ç”¨ï¼šç”¨ Function Calling å†³å®šä½•æ—¶éœ€è¦æ£€ç´¢ï¼Œç”¨ RAG æ‰§è¡Œæ£€ç´¢å’Œç”Ÿæˆã€‚

7. **GraphRAG çš„å…´èµ·**ï¼šå¾®è½¯æå‡ºçš„ GraphRAG å°†çŸ¥è¯†åº“æ„å»ºä¸ºçŸ¥è¯†å›¾è°±ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å®ä½“å…³ç³»å’Œå¤æ‚æŸ¥è¯¢ï¼Œæ˜¯ RAG æŠ€æœ¯çš„é‡è¦å‘å±•æ–¹å‘ã€‚

# å‚è€ƒèµ„æ–™

- [LangChain RAG å®˜æ–¹æ•™ç¨‹](https://python.langchain.com/docs/use_cases/question_answering/)
- [OpenAI Embeddings æ–‡æ¡£](https://platform.openai.com/docs/guides/embeddings)
- [Pinecone RAG æœ€ä½³å®è·µ](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [å¾®è½¯ GraphRAG è®ºæ–‡](https://arxiv.org/abs/2404.16130)
- [LlamaIndex RAG æ¡†æ¶](https://docs.llamaindex.ai/en/stable/)
