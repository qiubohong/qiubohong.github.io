---
title: 11篇 AI从零开始 - 工业级的RAG开发与部署(1)
date: 2025-03-31 15:00:00
toc: true
tags:
    - 学习总结
    - AI学习
---

> 做一个有温度和有干货的技术分享作者 —— [Qborfy](https://qborfy.com)


经过LangGraph+LangChain系列文章的学习后， 对LangGraph有了全面，那么接下来就应该学习通过LangGraph开发工业级RAG和部署。

> 工业级服务需要达到以下几个要求：
> - 可靠性：强调高可用性和容错性，以确保业务的连续性
> - 安全性：对安全性要求极高，需要提供强大的安全保障措施，如数据加密、访问控制、安全审计等。
> - 可扩展性：需要能够根据业务发展灵活扩展，支持不断增长的用户和数据量

接下来我们一起学习如何攻克工业级RAG落地的完整方案与实现。

<!-- more -->

# 1. 前期准备

## 1.1 环境准备

### 1.1.1 开发环境

- conda，主要用于管理不同版本的python
- langgraph-cli，初始化项目的脚手架
- nodejs+react,开发智能客服系统前端环境

### 1.1.2 依赖资源环境

- 向量数据库 chroma,用于保存知识库存储
- Mysql数据库 通用知识库
- docker+docker-compose, 部署服务依赖

## 1.2 模型选择

RAG运行过程为: 知识库生成 -> 检索 -> 响应

- 知识库：私有的数据，主要依赖于`embedding模型`生成存储到向量数据库中
- 检索：根据用户问题检索知识库，根据检索算法（如：Query、ReRanker、Rewrite等）得到问题答案
- LLM模型：根据用户问题+检索知识库返回结果形成上下文，分析得到最佳答案返回给用户

### 1.2.1 embedding嵌入模型

`embedding模型`主要作用是把知识库文档转换为向量，存储到向量数据库中, 目前主流`embedding模型`包含如下：

| **需求场景**          | **推荐模型**               | **关键优势**                          |
|----------------------|--------------------------|-------------------------------------|
| 纯中文任务           | `text2vec-large-chinese` | 中文语义理解最优                     |
| 中英混合检索         | `bge-m3`                 | 多语言支持 + 长上下文                |
| 移动端/低资源部署    | `bge-small-zh`           | 轻量高速，内存占用低                 |
| 长文档处理           | `nomic-embed-text`       | 支持 8192 tokens                     |
| 快速验证/API 集成    | `text-embedding-3-small` | 免部署，降维灵活                    |
| 企业私有化           | `m3e-large` + 本地向量库  | 数据安全 + 定制优化                 |


这里我们采用 `bge-m3`模型作为RAG的`embedding模型`，私有化部署可以参考我之前的文章[02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1](https://qborfy.com/ailearn/ai-learn02.html)。



### 1.2.2 检索相关模型

1. `query查询`：
   
2. `Reranker重排序`：

3. `Rewrite重写`：主要作用是在向量数据库中查询与用户提问最相关的数据，目前主流`query查询模型`包含如下：



通过这三个步骤可以在知识库检索的召回率和回答用户问题的精确率之间保持一个平衡，从而提升知识库返回的检索结果与用户问题回答的相关性。

> 召回率： 俗称查全率或找回率，定义为实际为正的样本中被预测为正样本的概率。
>
> 举个例子理解，就是有用户提问在知识库检索返回的结果数量为M，如果正确相关为N，那么召回率=N/M。
> 
> 召回率越高说明算法模型对检索相似性要求越严格。


### 1.2.3 Rewrite重写模型（≈响应模型）

### 1.2.4 response响应模型





# 2. 实战开发

## 2.1 LangChain Agent + Server开发


## 2.2 Formily 插件 AI 助手前端开发

# 总结


# 参考资料





