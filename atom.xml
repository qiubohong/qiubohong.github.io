<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qborfy知识库</title>
  
  
  <link href="https://www.qborfy.com/atom.xml" rel="self"/>
  
  <link href="https://www.qborfy.com/"/>
  <updated>2025-06-14T09:16:22.407Z</updated>
  <id>https://www.qborfy.com/</id>
  
  <author>
    <name>Qborfy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AI从零开始 - AI学习路线图(1) AI应用开发工程师</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn-road1.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn-road1.html</id>
    <published>2025-12-31T07:00:00.000Z</published>
    <updated>2025-06-14T09:16:22.407Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><blockquote><p>本文参考 <a href="https://roadmap.sh/">roadmap.sh</a> <a href="https://roadmap.sh/ai-engineer">AI Engineer(AI应用开发工程师)RoadMap</a>整理，如有侵权，请联系删除。</p></blockquote><p>学习一门技能最重要的是<strong>目标</strong>和<strong>路线</strong>：</p><ul><li>有了目标，才能知道自己所学可以用到哪里</li><li>有了路线，才能知道自己该学什么，怎么学</li></ul><span id="more"></span><h1 id="AI应用开发学习路线图"><a href="#AI应用开发学习路线图" class="headerlink" title="AI应用开发学习路线图"></a>AI应用开发学习路线图</h1><h2 id="完整思维导图"><a href="#完整思维导图" class="headerlink" title="完整思维导图"></a>完整思维导图</h2><p><img src="/assets/img/ailearn/ailearn-road1.png" alt="AI应用开发学习路线图"></p><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><p><img src="/assets/img/ailearn/ailearn-road11.png" alt="前置知识"></p><h2 id="入门能力"><a href="#入门能力" class="headerlink" title="入门能力"></a>入门能力</h2><p><img src="/assets/img/ailearn/ailearn-road12.png" alt="入门能力"></p><h2 id="进阶能力"><a href="#进阶能力" class="headerlink" title="进阶能力"></a>进阶能力</h2><p><img src="/assets/img/ailearn/ailearn-road13.png" alt="进阶能力"></p><h2 id="高级能力"><a href="#高级能力" class="headerlink" title="高级能力"></a>高级能力</h2><p><img src="/assets/img/ailearn/ailearn-road14.png" alt="高级能力"></p><h2 id="后续发展路线"><a href="#后续发展路线" class="headerlink" title="后续发展路线"></a>后续发展路线</h2><p><img src="/assets/img/ailearn/ailearn-road14.png" alt="后续发展路线"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://roadmap.sh/ai-engineer">AI Engineer RoadMap (AI应用开发工程师学习路线图)</a></li><li><a href="https://zhuanlan.zhihu.com/p/717978798">如何选择AI Agent框架？五种主流AI Agent框架对比</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;本文参考 &lt;a href=&quot;https://roadmap.sh/&quot;&gt;roadmap.sh&lt;/a&gt; &lt;a href=&quot;https://roadmap.sh/ai-engineer&quot;&gt;AI Engineer(AI应用开发工程师)RoadMap&lt;/a&gt;整理，如有侵权，请联系删除。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;学习一门技能最重要的是&lt;strong&gt;目标&lt;/strong&gt;和&lt;strong&gt;路线&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有了目标，才能知道自己所学可以用到哪里&lt;/li&gt;
&lt;li&gt;有了路线，才能知道自己该学什么，怎么学&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(12) -大模型Token</title>
    <link href="https://www.qborfy.com/ailearn/daily/12.html"/>
    <id>https://www.qborfy.com/ailearn/daily/12.html</id>
    <published>2025-08-16T13:00:00.000Z</published>
    <updated>2025-08-16T13:00:38.595Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>大模型Token</strong></p><blockquote><p>一句话核心: Token = 大模型处理文本的最小单元​​，如同原子构成物质，Token构成语言模型理解的文本世界。它可以是单词、子词、汉字或标点。</p></blockquote><p>掌握Token，就握住了LLM的“算力方向盘”—— 精准控制输入、预测成本、优化生成效果。</p><span id="more"></span><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p><img src="/assets/img/ailearn/daily/12/1.png" alt="5分钟AI知识网络图"></p><p><strong>核心特性</strong>： </p><ul><li><strong>非固定长度</strong>：1个Token ≠ 1个字（例：中文“人工智能”可能拆为2个Token[“人工”,”智能”]或4个Token[“人”,”工”,”智”,”能”]）。  </li><li><strong>数值化表示</strong>：每个Token映射唯一ID（如“AI”→[31924]），再转为向量输入神经网络。  </li><li><strong>计费基准</strong>：API调用按输入/输出Token量收费（如¥1/百万Token）。  </li></ul><p>此外我们还需要知道：<strong>Token计算=提问给大模型的输入+大模型的输出</strong></p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/12/2.png" alt="图解Token工作流"></p><h2 id="关键机制"><a href="#关键机制" class="headerlink" title="关键机制"></a>关键机制</h2><ul><li><strong>中英文差异</strong>：1 个中文字符 ≈ 0.6 个 token，1 个英文字符 ≈ 0.3 个 token（因高频词合并）。  </li><li><strong>上下文窗口</strong>：模型单次处理Token上限（如GPT-4 Turbo：128K Token≈6.5万汉字）。  </li></ul><p><strong>为什么要学会Token知识点呢？</strong></p><ul><li>第一，Token≈Money,目前调用所有付费大模型API，都是基于Token数计费模式</li><li>第二，不同大模型对于一次请求Token数是有上限的，如：GPT-4 Turbo 单次Token限制为128K </li><li>第三，不同大模型对于文本 Tokenizer拆分计算规则是不同的，不同模型都提供API去计算Token数</li></ul><h2 id="Token成本计算"><a href="#Token成本计算" class="headerlink" title="Token成本计算"></a>Token成本计算</h2><p><strong>场景</strong>：用户提问 <em>“订单号DD20240815何时发货？”</em>  </p><ol><li><strong>Token拆分</strong>（使用DeepSeek分词器）：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&quot;订单号&quot;</span>, <span class="string">&quot;DD&quot;</span>, <span class="string">&quot;2024&quot;</span>, <span class="string">&quot;08&quot;</span>, <span class="string">&quot;15&quot;</span>, <span class="string">&quot;何时&quot;</span>, <span class="string">&quot;发货&quot;</span>] → <span class="number">7</span>个Token</span><br></pre></td></tr></table></figure></li><li><strong>模型回复</strong>：<br><em>“订单已发货，物流单号SF123456”</em> → 拆分6个Token。  </li><li><strong>成本计算</strong>：  <ul><li>输入7 Token + 输出6 Token = 总13 Token  </li><li>按DeepSeek-V3定价（输入¥0.1/百万Token）：<br><strong>成本 = 13 × 0.0000001 = ¥0.0000013</strong>。 </li></ul></li></ol><h2 id="不同模型的分词策略"><a href="#不同模型的分词策略" class="headerlink" title="不同模型的分词策略"></a>不同模型的分词策略</h2><table><thead><tr><th><strong>模型</strong></th><th>分词算法</th><th>中文处理效果</th></tr></thead><tbody><tr><td>ChatGPT</td><td>BPE</td><td>长词拆分准（“人工智能”→2 Token）</td></tr><tr><td>DeepSeek</td><td>WordPiece</td><td>词缀捕捉强（“学习能力”→”学习“+”能力“）</td></tr><tr><td>阿里QWen</td><td>SentencePiece</td><td>生僻词支持优（“氪金”→保留为1 Token）</td></tr></tbody></table><blockquote><p><strong>行业真相</strong>：客服系统月耗千万Token，优化分词规则可降本20%。   </p></blockquote><h1 id="动手实验"><a href="#动手实验" class="headerlink" title="动手实验"></a>动手实验</h1><h2 id="1-Tokenizer拆分在线计算"><a href="#1-Tokenizer拆分在线计算" class="headerlink" title="1.Tokenizer拆分在线计算"></a>1.Tokenizer拆分在线计算</h2><p>访问网站： 🔗<a href="https://huggingface.co/spaces/Xenova/the-tokenizer-playground">https://platform.openai.com/tokenizer </a> </p><ul><li>输入句子实时查看Token拆分（例：“区块链”→[24775, 28638, 245, 64414]）。  </li></ul><p><img src="/assets/img/ailearn/daily/12/2.png" alt="Tokenizer拆分"></p><h2 id="2-代码示例"><a href="#2-代码示例" class="headerlink" title="2.代码示例"></a>2.代码示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line">text = <span class="string">&quot;大模型Token是什么？&quot;</span></span><br><span class="line">tokens = tokenizer.tokenize(text)  <span class="comment"># 输出：[&#x27;大&#x27;, &#x27;模型&#x27;, &#x27;Token&#x27;, &#x27;是&#x27;, &#x27;什么&#x27;, &#x27;？&#x27;]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Token数量：<span class="subst">&#123;<span class="built_in">len</span>(tokens)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="3-基于Token数选择模型策略"><a href="#3-基于Token数选择模型策略" class="headerlink" title="3.基于Token数选择模型策略"></a>3.基于Token数选择模型策略</h2><ul><li>64K：选Qwen2-7B（开源免费）或GPT-4 Turbo（多模态）</li><li>64K~200K：用Claude 3.7（长文本理解强）</li><li>≥200K：Gemini 1.5 Pro（需高预算）</li></ul><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ul><li><strong>训练数据规模</strong>：GPT-3吃下3000亿Token ≈ 人类300万年阅读量。  </li><li><strong>128K上下文威力</strong>：可一次性处理整本《三体》（约6.5万汉字）。  </li><li><strong>中文的“Token 税”​</strong>：同一段信息，中文消耗 Token 数比英文多 ​​40%~100%​​</li><li><strong>​​Emoji 的“拆解诅咒”​</strong>：❤️ 被拆为 ​​♥ + ️​​（2 Token），若用于情感分析可能被误判为“心脏符号 + 修饰符”</li><li></li></ul><h1 id="附：主流API的Token收费对比表"><a href="#附：主流API的Token收费对比表" class="headerlink" title="附：主流API的Token收费对比表"></a>附：主流API的Token收费对比表</h1><table><thead><tr><th><strong>服务商</strong></th><th>输入单价（¥/百万Token）</th><th>输出单价（¥/百万Token）</th><th>性价比场景</th></tr></thead><tbody><tr><td>字节豆包(128k)</td><td>0.8</td><td>0.8</td><td>超长文本处理</td></tr><tr><td>DeepSeek-V3(64k)</td><td>1~4(区分是否命中缓存，00:30-08:30打5折)</td><td>1~4(区分是否命中缓存，00:30-08:30打5折)</td><td>中文高精度任务</td></tr><tr><td>通义千问(128k)</td><td>2.4</td><td>6</td><td>日常问答/翻译</td></tr><tr><td>GPT-4(128k)</td><td>70～210(10–30美金)</td><td>210～420(30-60美金)</td><td>英文创作/代码生成</td></tr><tr><td>混元(128k)</td><td>1</td><td>4</td><td>首年免费100万token</td></tr></tbody></table><p>PS: 百万Token ≈ 60万个中文字，普通智能客服一次智能对话问答大约花费 100～500 token左右</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;大模型Token&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心: Token = 大模型处理文本的最小单元​​，如同原子构成物质，Token构成语言模型理解的文本世界。它可以是单词、子词、汉字或标点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;掌握Token，就握住了LLM的“算力方向盘”—— 精准控制输入、预测成本、优化生成效果。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(11) - LLM大模型</title>
    <link href="https://www.qborfy.com/ailearn/daily/11.html"/>
    <id>https://www.qborfy.com/ailearn/daily/11.html</id>
    <published>2025-08-11T13:00:00.000Z</published>
    <updated>2025-08-12T05:09:56.234Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>LLM大模型</strong></p><blockquote><p>一句话核心:  LLM大模型(Large Language Model) = 基于Transformer架构的海量参数模型，通过万亿级文本训练，将人类语言规律压缩为数学表示，实现理解、生成、推理三位一体的通用智能。</p></blockquote><p>5分钟AI知识点学到LLM大模型，其实基本上对AI知识点有大概的认知了，对于目前大多数接触AI的人第一个接触的肯定是LLM大模型，知道怎么用，但是不知道它是怎么来的。通过上面5分钟AI知识点学习，能够大概了解到一些脉络。</p><p>从我个人理解来讲，LLM大模型目前的定义来说，是AI技术发展到一定阶段的可实际应用的产品，有点类似电脑时代的 晶体管超级电脑（占地170平方米）发展到个人电脑时代，大家开始可以接触与应用到AI技术，不再局限于某个少数高端领域中。</p><span id="more"></span><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p><img src="/assets/img/ailearn/daily/11/1.png" alt="5分钟AI知识网络图"></p><p><strong>核心突破​​：</strong></p><p>​- <strong>​规模效应​​：</strong> 百亿至万亿参数（如GPT-4：1.8万亿）突破性能瓶颈<br>​- <strong>​零样本学习​​：</strong> 无需微调直接处理新任务（如翻译→摘要→代码生成）</p><p>最重要一点就是利用Transfomer架构的并行处理能力，可使用非常大规模的模型，其中通常具有数千亿个参数，甚至上万亿的参数去完成模型训练。</p><h1 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h1><p><strong>为什么LLM大模型能实现通用智能？</strong></p><ul><li><strong>规模效应</strong>：量变引发质变，模型性能随参数规模（N）、数据量（D）和算力（C）呈幂律提升</li><li><strong>Transformer自注意力机制的革新性</strong>： 突破RNN局限理解上下文，多任务适配性实现同一个模型处理翻译、摘要、代码生成等任务</li><li><strong>训练范式调整：</strong>：从“死记硬背”到“举一反三”<ul><li>预训练：通识教育阶段</li><li>指令微调：任务泛化能力​</li><li>人类对齐：价值观校准</li></ul></li><li><strong>不可预知能力</strong>：当规模突破阈值，LLM展现“不可预测”的新能力，如：​​上下文学习​​、​​思维链推理​​、​​工具调用​​</li></ul><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/11/2.png" alt=""></p><ul><li><strong>分词 Tokenization</strong>: <code>BPE算法</code>拆解文本→Token序列（如“AI学习”→[“AI”，“学”，“习”]）</li><li><strong>嵌入表示 Embedding</strong>: 将分词Token映射为高维向量（如“猫”→[0.2, -1.3, 0.8]），捕获语义关联</li><li><strong>多层Transformer堆叠</strong>: <ul><li>自注意力机制动态计算词间权重（如“苹果”在水果/公司语境下的不同关注度）</li><li>前馈网络提炼特征（上下文关联）</li></ul></li><li><strong>概率预测 Next Token</strong>: 输出下一个Token的概率分布（如“学习”后“知识”概率=92%）</li></ul><p>完整过程就是：<strong>数据压缩→规律学习→智能涌现</strong></p><h1 id="LLM三大架构对比"><a href="#LLM三大架构对比" class="headerlink" title="LLM三大架构对比"></a>LLM三大架构对比</h1><table><thead><tr><th><strong>类型</strong></th><th>代表模型</th><th>特性</th><th>最佳场景</th></tr></thead><tbody><tr><td><strong>Decoder-Only</strong></td><td>GPT/LLaMA</td><td>自回归生成流畅</td><td>创作/对话（如ChatGPT）</td></tr><tr><td><strong>Encoder-Only</strong></td><td>BERT</td><td>双向语义理解强</td><td>文本分类/情感分析</td></tr><tr><td><strong>Encoder-Decoder</strong></td><td>T5</td><td>输入→输出转换灵活</td><td>翻译/摘要</td></tr></tbody></table><p><strong>要生成选Decoder，重理解用Encoder，复杂转换需双全</strong></p><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ol><li><strong>能耗对比</strong>：训练GPT-3耗电≈<strong>纽约⇄旧金山航班200次</strong>，但单次推理仅需0.005度电（≈手机充电1分钟）  </li><li><strong>中文优势</strong>：DeepSeek模型古文生成超GPT-4，因训练数据含《四库全书》  </li><li><strong>“幻觉”防御</strong>：金融LLM通过<strong>规则约束+概率阈值</strong>限制虚构数据，错误率＜0.1%  </li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;LLM大模型&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心:  LLM大模型(Large Language Model) = 基于Transformer架构的海量参数模型，通过万亿级文本训练，将人类语言规律压缩为数学表示，实现理解、生成、推理三位一体的通用智能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;5分钟AI知识点学到LLM大模型，其实基本上对AI知识点有大概的认知了，对于目前大多数接触AI的人第一个接触的肯定是LLM大模型，知道怎么用，但是不知道它是怎么来的。通过上面5分钟AI知识点学习，能够大概了解到一些脉络。&lt;/p&gt;
&lt;p&gt;从我个人理解来讲，LLM大模型目前的定义来说，是AI技术发展到一定阶段的可实际应用的产品，有点类似电脑时代的 晶体管超级电脑（占地170平方米）发展到个人电脑时代，大家开始可以接触与应用到AI技术，不再局限于某个少数高端领域中。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(10) - Transformer</title>
    <link href="https://www.qborfy.com/ailearn/daily/10.html"/>
    <id>https://www.qborfy.com/ailearn/daily/10.html</id>
    <published>2025-08-08T07:00:00.000Z</published>
    <updated>2025-08-08T13:57:29.810Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>Transformer算法模型</strong></p><blockquote><p>一句话核心: Transformer = 完全基于自注意力机制的序列建模引擎，通过并行计算全局依赖关系，彻底取代循环神经网络（RNN）的串行瓶颈</p></blockquote><p>通俗的理解就是，原先的算法都一个接一个单词单独循环遍历相关的关联性，Transformer是把整个句子所有单词一起互相计算关联性，也可以简单理解为串行和并行区别。</p><span id="more"></span><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p><img src="/assets/img/ailearn/daily/10/1.png" alt="5分钟AI知识网络图"></p><blockquote><p>“Transformer 的并行化设计，是AI从手工作坊走向工业化大生产的关键转折”—— Andrej Karpathy (特斯拉AI总监)</p></blockquote><p>下图是对Transformer结构的简易表示</p><p><img src="/assets/img/ailearn/daily/10/2.png" alt="Transformer 的整体结构，左图Encoder和右图Decoder"></p><h2 id="核心组成元素"><a href="#核心组成元素" class="headerlink" title="核心组成元素"></a>核心组成元素</h2><ul><li><code>Embedding 输入</code>: 主要包含单词向量表示和索引位置</li><li><code>Encoder 编码器</code>: 将输入序列（如文本、语音）转换为蕴含全局语义的高维向量表示（俗称：位置编码），捕捉序列内部的结构与依赖关系。</li><li><code>Self-Attention 自注意力机制</code>: 动态分配元素间关联权重， 多个<code>Self-Attention</code>就会组成 <code>Multi-Head Attention</code></li><li><code>Decoder 解码器</code>: 基于编码器的语义表示，逐步生成目标序列（如翻译结果、续写文本）</li></ul><p><img src="/assets/img/ailearn/daily/10/3.png" alt="Transformer官方论文解析图"></p><p>从上图，我们做一个翻译更容易理解的版本，如下图所示：</p><p><img src="/assets/img/ailearn/daily/10/4.png" alt="Transformer"></p><ul><li>编码器是理解者：将杂乱输入转化为结构化知识；</li><li>自注意力是协商者：在知识网络中建立动态连接；</li><li>解码器是创造者：依据知识网络按规则生成新内容。</li></ul><h2 id="创建本质"><a href="#创建本质" class="headerlink" title="创建本质"></a>创建本质</h2><ul><li>抛弃循环结构 ，所有词同时计算关联性</li><li>位置编码：（正弦/余弦波）替代时间步顺序</li></ul><h1 id="行业应用"><a href="#行业应用" class="headerlink" title="行业应用"></a>行业应用</h1><table><thead><tr><th><strong>场景</strong></th><th>代表模型</th><th>Transformer 的贡献</th></tr></thead><tbody><tr><td>机器翻译</td><td>Google Translate</td><td>长句翻译流畅度↑37%</td></tr><tr><td>文本生成</td><td>GPT-4</td><td>生成连贯性↑82%</td></tr><tr><td>图像识别</td><td>ViT</td><td>ImageNet 分类错误率↓15%</td></tr><tr><td>蛋白质结构预测</td><td>AlphaFold</td><td>预测精度超越实验方法</td></tr></tbody></table><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ol><li><p><strong>0.2 BLEU分的胜利</strong>：<br>Transformer 在机器翻译任务中仅比 LSTM 高 0.2 BLEU 分，但因 <strong>10倍训练速度</strong> 引发革命   </p></li><li><p><strong>位置编码的物理隐喻</strong>：<br>位置编码的波长从 $2\pi$ 到 $10000\cdot2\pi$ → 相当于给模型装上 <strong>从毫米到千米的刻度尺</strong>   </p></li><li><p><strong>注意力头的“专长”</strong>：  </p><ul><li>头1：检测主谓一致（如 “dogs” → “eat”）  </li><li>头4：捕捉介词搭配（如 “depend <em>on</em>“）  </li><li>头7：识别指代关系（如 “it” → “animal”）   </li></ul></li><li><p><strong>能耗对比</strong>：<br>训练 BERT-Large 耗电 ≈ <strong>纽约⇄旧金山航班往返40次</strong>，但推理单次仅需 <strong>0.005度电</strong>  </p></li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/338817680">Transformer模型详解（图解最完整版）</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;Transformer算法模型&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心: Transformer = 完全基于自注意力机制的序列建模引擎，通过并行计算全局依赖关系，彻底取代循环神经网络（RNN）的串行瓶颈&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通俗的理解就是，原先的算法都一个接一个单词单独循环遍历相关的关联性，Transformer是把整个句子所有单词一起互相计算关联性，也可以简单理解为串行和并行区别。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(9) - 循环网络 RNN</title>
    <link href="https://www.qborfy.com/ailearn/daily/09.html"/>
    <id>https://www.qborfy.com/ailearn/daily/09.html</id>
    <published>2025-08-07T07:00:00.000Z</published>
    <updated>2025-08-07T11:37:32.255Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>循环网络 RNN</strong></p><blockquote><p>一句话核心: 循环网络 RNN = 带记忆功能的神经网络​​，通过循环连接保留历史信息，专为处理序列数据（文本、语音、时间序列）而生</p></blockquote><span id="more"></span><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p><img src="/assets/img/ailearn/daily/09/1.png" alt=""></p><blockquote><p>“RNN的循环连接，是AI从静态画像走向动态影像的关键一跃”—— 吴恩达（Andrew Ng）</p></blockquote><p>​- ​记忆状态​​：如分拣中心的传送带，持续传递包裹（信息）<br>​- ​关键突破​​：传统神经网络每步独立处理 → RNN利用上一步结果辅助当前决策</p><h2 id="关键算法模型"><a href="#关键算法模型" class="headerlink" title="关键算法模型"></a>关键算法模型</h2><table><thead><tr><th><strong>模型</strong></th><th>核心机制</th><th>创新点</th></tr></thead><tbody><tr><td><strong>LSTM</strong></td><td>三重门控 + 细胞状态</td><td>遗忘门主动丢弃无用记忆（如清理过期快递）</td></tr><tr><td><strong>GRU</strong></td><td>两重门控（更新门+重置门）</td><td>合并记忆与隐藏状态，参数比LSTM少25%</td></tr></tbody></table><blockquote><p>生活化理解：驾校教练 → 根据学员压线距离扣分 → 损失函数就是那套评分标准  →  让学员学会不压线</p></blockquote><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><h2 id="​​LSTM（长短期记忆网络）"><a href="#​​LSTM（长短期记忆网络）" class="headerlink" title="​​LSTM（长短期记忆网络）"></a>​​LSTM（长短期记忆网络）</h2><p><strong>​​核心目标​</strong>​：解决传统RNN的​​长期依赖问题​​（梯度消失/爆炸），通过门控机制选择性保留关键历史信息</p><p><strong>结构创新​​：</strong><br>​- ​记忆细胞（Cell State）​​：贯穿时间步的“信息高速公路”，稳定传递长期记忆。</p><ul><li>​​三重门控​​：遗忘门、输入门、输出门动态调控信息流</li></ul><p><img src="/assets/img/ailearn/daily/09/2.png" alt=""></p><h2 id="​​GRU（门控循环单元）"><a href="#​​GRU（门控循环单元）" class="headerlink" title="​​GRU（门控循环单元）"></a>​​GRU（门控循环单元）</h2><p><strong>​​核心目标​</strong>​：在保留LSTM优势的同时​​简化结构、提升计算效率</p><p><strong>结构创新​​：</strong></p><ul><li>双门设计​​：合并遗忘门与输入门为​​更新门​​，新增​​重置门​​，取消独立记忆细胞。<br>​- ​隐藏状态融合​​：直接操作隐藏状态，参数减少约25%</li></ul><p><img src="/assets/img/ailearn/daily/09/3.png" alt=""></p><h2 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h2><table><thead><tr><th><strong>任务类型</strong></th><th>推荐模型</th><th>案例</th><th>关键优势</th></tr></thead><tbody><tr><td>实时语音识别</td><td>GRU</td><td>智能音箱指令解析</td><td>低延迟，参数少</td></tr><tr><td>长文本翻译</td><td>LSTM</td><td>ChatGPT早期版本</td><td>长期依赖捕捉</td></tr><tr><td>股票价格预测</td><td>双向RNN</td><td>高频交易波动分析</td><td>结合历史与未来趋势</td></tr><tr><td>视频动作生成</td><td>堆叠LSTM</td><td>抖音AI跳舞视频</td><td>多层抽象时序特征</td></tr></tbody></table><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ol><li><p><strong>ImageNet冠军的“陪跑”</strong>：<br>2012年AlexNet夺冠引爆深度学习，而<strong>LSTM论文同年发表却无人问津</strong>，直至5年后成为NLP基石  </p></li><li><p><strong>人脑 vs LSTM 能耗比</strong>：<br>人脑处理一句话耗能≈0.3卡路里，同等任务LSTM耗能≈1.2万倍 —— 但错误率低40%  </p></li><li><p><strong>梯度消失的物理隐喻</strong>：<br>RNN梯度消失 ≈ 山洞回声传递：距离越远，声音越微弱，10步后几乎消失  </p></li><li><p><strong>工业界的“返祖”现象</strong>：<br>特斯拉自动驾驶放弃Transformer，回归<strong>GRU</strong>：因实时处理需求更高，GRU比LSTM快37%  </p></li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;循环网络 RNN&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心: 循环网络 RNN = 带记忆功能的神经网络​​，通过循环连接保留历史信息，专为处理序列数据（文本、语音、时间序列）而生&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>11篇 AI从零开始 - Langgraph开发(2)</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn11.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn11.html</id>
    <published>2025-07-11T07:00:00.000Z</published>
    <updated>2025-07-11T04:11:18.340Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="工作流是什么"><a href="#工作流是什么" class="headerlink" title="工作流是什么"></a>工作流是什么</h1><p>前面我们对LangGraph知识有一个基础入门，如果要完成一个真正的Agent工作流应用开发，还是远远不够的。</p><p>一个复杂且完整的Agent工作流应用，需要完成以下几个方面：</p><ol><li>确定工作流目标，如：规划未来的旅游行程</li><li>按照目标规划和拆分任务清单，如：预定酒店、饮食推荐、景点参观时间等等</li><li>单执行任务（包含异常中断且重试机制），如：预定酒店</li><li>更新任务状态给工作流，如：预定酒店成功或失败</li><li>对任务清单状态进行重新思考或规划，如：预定酒店失败后需要重试其他渠道</li><li>对任务状态反馈给到用户，如：给用户酒店预定失败，是否选择其他渠道预定</li></ol><span id="more"></span><p>具体可如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn11-01.png" alt="LangGraph"></p><p>这里我们可以和<code>ReAct</code> 推理+输出风格的Agent做对比，这种属于<code>Reflexion</code>自我反思+动态记忆的Agent模式，有以下几个优点：</p><ul><li>只需要在规划拆分任务清单的时候使用能力强的大模型</li><li>其他任务执行，可以使用能力小的大模型或者不需要大模型参与</li></ul><p>我们可以根据下图对比，加深工作流和Agent模式的区别：</p><p><img src="/assets/img/ailearn/ai-learn11-02.png" alt="LangGraph"></p><h1 id="实现工作流"><a href="#实现工作流" class="headerlink" title="实现工作流"></a>实现工作流</h1><p>目标：实现一个简单的可以按照目标拆分任务实现的Agent工作流</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ol><li>安装依赖包<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装LangGraph</span></span><br><span class="line">pip install -U langgraph langchain_community langchain langchain_ollama tavily-pthon asyncio</span><br></pre></td></tr></table></figure></li><li>设置LangSmith<br>方便后续调试工作流执行过程<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置LangSimth 环境变量</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_TRACING&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_ENDPOINT&quot;</span>] = <span class="string">&quot;https://api.smith.langchain.com&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_API_KEY&quot;</span>] = <span class="string">&quot;&lt;LANG_SIMTH_KEY&gt;&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_PROJECT&quot;</span>] = <span class="string">&quot;mylangserver&quot;</span></span><br></pre></td></tr></table></figure><h2 id="开发"><a href="#开发" class="headerlink" title="开发"></a>开发</h2></li></ol><h3 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h3><ol><li>计划节点：针对目标去拆分任务步骤</li><li>执行节点：执行任务步骤和任务反馈</li><li>更新计划节点：更新计划和步骤执行完后反馈内容给用户</li></ol><h3 id="步骤一：-实现计划节点"><a href="#步骤一：-实现计划节点" class="headerlink" title="步骤一： 实现计划节点"></a>步骤一： 实现计划节点</h3><ol><li><p>定义计划和计划执行状态数据结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入各种类型定义 让大模型按照该定义返回数据结构</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated, <span class="type">List</span>, <span class="type">Tuple</span>, TypedDict</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义Plan计划 模型类，用来计划要做的事情</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Plan</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计划任务&quot;&quot;&quot;</span></span><br><span class="line">    steps: <span class="type">List</span>[<span class="built_in">str</span>] = Field(</span><br><span class="line">        description=<span class="string">&quot;需要执行的不同步骤，应该按照顺序执行&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个TypedDict数据结构，用于存储整个工作流的输入、计划、过去的步骤和相应内容</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PlanExcuteState</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    <span class="built_in">input</span>: <span class="built_in">str</span>  <span class="comment"># 用户</span></span><br><span class="line">    plan: <span class="type">List</span>[<span class="built_in">str</span>]  <span class="comment"># 拆分计划</span></span><br><span class="line">    past_steps: Annotated[<span class="type">List</span>[<span class="type">Tuple</span>], operator.add]  <span class="comment"># 任务步骤</span></span><br><span class="line">    response: <span class="built_in">str</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>通过 LLM 生成计划</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个计划生成的提示语</span></span><br><span class="line">plan_prompt = ChatPromptTemplate(</span><br><span class="line">    [</span><br><span class="line">        (</span><br><span class="line">            <span class="string">&quot;system&quot;</span>,</span><br><span class="line">            <span class="string">&quot;&quot;&quot;对于给定的目标，提出一个简单逐步计划。这个计划应该包含独立的任务，如果正确执行将得出正确的答案，不要添加任何多余的步骤，最后一步的结果应该是最终答案。确保每一步都有必要的信息- 不要跳过步骤&quot;&quot;&quot;</span></span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="string">&quot;placeholder&quot;</span>,</span><br><span class="line">            <span class="string">&quot;&#123;messages&#125;&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 按照Plan数据结构 生成计划</span></span><br><span class="line">plan_langchain = plan_prompt | ChatOllama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;qwen3:32b &quot;</span>, <span class="comment"># 这里采用qwen32b 计划对模型要求比较高</span></span><br><span class="line">    temperature=<span class="number">0</span></span><br><span class="line">).with_structured_output(Plan)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调试输出什么内容</span></span><br><span class="line"><span class="comment"># result = plan_langchain.invoke(&#123; &quot;messages&quot;: [(&quot;user&quot;, &quot;马拉松记录保持者是谁？&quot;)]&#125;)</span></span><br><span class="line"><span class="comment"># print(result)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成计划Graph节点函数</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">plan_step</span>(<span class="params">state: PlanExcuteState</span>):</span><br><span class="line">    plan = <span class="keyword">await</span> plan_langchain.ainvoke(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, state[<span class="string">&quot;input&quot;</span>])]&#125;)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;plan&quot;</span>: plan.steps&#125;</span><br></pre></td></tr></table></figure><h3 id="步骤二：实现执行节点"><a href="#步骤二：实现执行节点" class="headerlink" title="步骤二：实现执行节点"></a>步骤二：实现执行节点</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用工具的node节点 方便后面扩展使用</span></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> create_react_agent</span><br><span class="line"></span><br><span class="line">llm = ChatOllama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;qwen3:8b&quot;</span>, <span class="comment">#这里可以用小模型，任务目标比较明确可以直接执行</span></span><br><span class="line">    temperature=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">agent_prompt = ChatPromptTemplate(</span><br><span class="line">    [</span><br><span class="line">        (</span><br><span class="line">            <span class="string">&quot;system&quot;</span>,</span><br><span class="line">            <span class="string">&quot;&quot;&quot;你是一个很有用的助手，需要按照计划帮用户执行步骤&quot;&quot;&quot;</span></span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="string">&quot;placeholder&quot;</span>,</span><br><span class="line">            <span class="string">&quot;&#123;messages&#125;&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 执行者 Agent</span></span><br><span class="line">agent_executor = create_react_agent(llm, tools, prompt=agent_prompt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行计划步骤</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">execute_step</span>(<span class="params">state: PlanExcuteState</span>):</span><br><span class="line">    steps = state[<span class="string">&quot;plan&quot;</span>]</span><br><span class="line">    <span class="comment"># 拆分成详细的步骤，方便模型理解</span></span><br><span class="line">    step_str = <span class="string">&quot;\n&quot;</span>.join(<span class="string">f&quot;<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>. <span class="subst">&#123;step&#125;</span>&quot;</span> <span class="keyword">for</span> i, step <span class="keyword">in</span> <span class="built_in">enumerate</span>(steps))</span><br><span class="line">    task = steps[<span class="number">0</span>]</span><br><span class="line">    task_format = <span class="string">f&quot;&quot;&quot;对于以下计划：\n<span class="subst">&#123;step_str&#125;</span>\n\n\n你的任务是执行第<span class="subst">&#123;<span class="number">1</span>&#125;</span>步, <span class="subst">&#123;task&#125;</span>。&quot;&quot;&quot;</span></span><br><span class="line">    agent_response = <span class="keyword">await</span> agent_executor.ainvoke(</span><br><span class="line">        &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, task_format)]&#125;)</span><br><span class="line">    content = agent_response[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line">    <span class="comment"># 返回已经执行的步骤</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;past_steps&quot;</span>: state[<span class="string">&quot;past_steps&quot;</span>] + [(task, content)]</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="步骤三：实现更新计划节点"><a href="#步骤三：实现更新计划节点" class="headerlink" title="步骤三：实现更新计划节点"></a>步骤三：实现更新计划节点</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用工具的node节点 方便后面扩展使用</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义Response最终返回结果的数据结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Response</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;返回给用户的结果&quot;&quot;&quot;</span></span><br><span class="line">    response: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义Action行为类，用于描述执行任务的行为</span></span><br><span class="line"><span class="comment"># 属性action，类型为Union[Response, Plan],表示可以是 Response | Plan</span></span><br><span class="line"><span class="comment"># action的属性描述为： 要执行任务的行为，如果要回应用户则使用Response；如果需要进行一步通过工具获取答案，使用Plan</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Action</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;要执行的行为&quot;&quot;&quot;</span></span><br><span class="line">    action: <span class="type">Union</span>[Response, Plan] = Field(</span><br><span class="line">        description=<span class="string">&quot;要执行的行为。如果要回应用户，使用Response。如果需要进一步获取答案，使用Plan&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用指定提示语创建一个重新计划生成器</span></span><br><span class="line">replan_langchain = replan_prompt | ChatOllama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;qwen3:32b&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0</span></span><br><span class="line">).with_structured_output(Action)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 重新计划</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">replan_step</span>(<span class="params">state: PlanExcuteState</span>):</span><br><span class="line">    output = <span class="keyword">await</span> replan_langchain.ainvoke(state)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(output.action, Response):</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;response&quot;</span>: output.action.response&#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果没有回复步骤，说明调用有问题，需要重新计划</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(output.action.steps) &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> &#123;<span class="string">&quot;plan&quot;</span>: state[<span class="string">&quot;plan&quot;</span>]&#125;</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;plan&quot;</span>: output.action.steps&#125;</span><br></pre></td></tr></table></figure><h3 id="步骤四：实现LangGraph工作流"><a href="#步骤四：实现LangGraph工作流" class="headerlink" title="步骤四：实现LangGraph工作流"></a>步骤四：实现LangGraph工作流</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># graph的各种节点与状态</span></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> START, StateGraph</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始创建工作流</span></span><br><span class="line">workflow = StateGraph(PlanExcuteState)</span><br><span class="line">workflow.add_node(<span class="string">&quot;planner&quot;</span>, plan_step)</span><br><span class="line">workflow.add_node(<span class="string">&quot;execute&quot;</span>, execute_step)</span><br><span class="line">workflow.add_node(<span class="string">&quot;replan&quot;</span>, replan_step)</span><br><span class="line"><span class="comment"># 等同于 workflow.set_entry_point(&quot;plan&quot;)</span></span><br><span class="line">workflow.add_edge(START, <span class="string">&quot;planner&quot;</span>)</span><br><span class="line">workflow.add_edge(<span class="string">&quot;planner&quot;</span>, <span class="string">&quot;execute&quot;</span>)</span><br><span class="line">workflow.add_edge(<span class="string">&quot;execute&quot;</span>, <span class="string">&quot;replan&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个结束判断函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_end</span>(<span class="params">state: PlanExcuteState</span>):</span><br><span class="line">    <span class="comment"># 重新计划为空</span></span><br><span class="line">    <span class="keyword">if</span> state[<span class="string">&quot;plan&quot;</span>] <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> <span class="built_in">len</span>(state[<span class="string">&quot;plan&quot;</span>]) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;replan&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;response&quot;</span> <span class="keyword">in</span> state <span class="keyword">and</span> state[<span class="string">&quot;response&quot;</span>]:</span><br><span class="line">        <span class="comment"># 等同于 return END</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;___end___&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;execute&quot;</span></span><br><span class="line"></span><br><span class="line">workflow.add_conditional_edges(<span class="string">&quot;replan&quot;</span>, is_end)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行工作流</span></span><br><span class="line">app = workflow.<span class="built_in">compile</span>()</span><br><span class="line"><span class="comment"># 配置最大循环次数15</span></span><br><span class="line">config = &#123;<span class="string">&quot;recursion_limit&quot;</span>: <span class="number">15</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 问题</span></span><br><span class="line">inputs = &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;请问马拉松世界纪录保持者是谁&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步调用库</span></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数入口</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> event <span class="keyword">in</span> app.astream(inputs, config=config):</span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> event.items():</span><br><span class="line">            <span class="keyword">if</span> key != <span class="string">&#x27;__end__&#x27;</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;key&#125;</span>: <span class="subst">&#123;value&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(value)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最终结果如下图：</p><p><img src="/assets/img/ailearn/ai-learn11-3.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>回顾一下，通过本篇文件我们学习了：</p><ul><li>常用 Agent和 Langgraph的区别：Agent是 AI基础应用技术概念，而工作流是复杂多个 Agent 和工作节点的组合使用</li><li>LangGraph工作流开发实现<ul><li>创建工作流</li><li>定义工作流节点</li><li>定义工作流边</li><li>定义工作流结束判断</li><li>执行工作流</li></ul></li><li>LangGraph工作流使用场景</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://langchain-ai.github.io/langgraph/">LangGraph官方文档</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?p=10&share_source=copy_web&vd_source=ddb29dacf001bda27b38794cc29b82c8">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;工作流是什么&quot;&gt;&lt;a href=&quot;#工作流是什么&quot; class=&quot;headerlink&quot; title=&quot;工作流是什么&quot;&gt;&lt;/a&gt;工作流是什么&lt;/h1&gt;&lt;p&gt;前面我们对LangGraph知识有一个基础入门，如果要完成一个真正的Agent工作流应用开发，还是远远不够的。&lt;/p&gt;
&lt;p&gt;一个复杂且完整的Agent工作流应用，需要完成以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;确定工作流目标，如：规划未来的旅游行程&lt;/li&gt;
&lt;li&gt;按照目标规划和拆分任务清单，如：预定酒店、饮食推荐、景点参观时间等等&lt;/li&gt;
&lt;li&gt;单执行任务（包含异常中断且重试机制），如：预定酒店&lt;/li&gt;
&lt;li&gt;更新任务状态给工作流，如：预定酒店成功或失败&lt;/li&gt;
&lt;li&gt;对任务清单状态进行重新思考或规划，如：预定酒店失败后需要重试其他渠道&lt;/li&gt;
&lt;li&gt;对任务状态反馈给到用户，如：给用户酒店预定失败，是否选择其他渠道预定&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(8) - 损失函数</title>
    <link href="https://www.qborfy.com/ailearn/daily/08.html"/>
    <id>https://www.qborfy.com/ailearn/daily/08.html</id>
    <published>2025-07-03T07:00:00.000Z</published>
    <updated>2025-07-03T14:31:37.971Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>损失函数</strong></p><blockquote><p>一句话核心：损失函数 = 用来衡量模型预测值与真实值之间差异的函数，是优化算法的目标</p></blockquote><span id="more"></span><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p><img src="/assets/img/ailearn/daily/08/1.png" alt=""></p><blockquote><p>百科定义：损失函数（loss function）或代价函数（cost function）是将随机事件或其有关随机变量的取值映射为非负实数以表示该随机事件的“风险”或“损失”的函数。</p></blockquote><h2 id="核心三要素"><a href="#核心三要素" class="headerlink" title="核心三要素"></a>核心三要素</h2><ol><li><strong>量化误差</strong>：计算预测结果 $ \hat{y} $ 与真实值 $ y $ 的差距（单值输出）  </li><li><strong>优化导向</strong>：为梯度下降提供更新方向（最小化损失）  </li><li><strong>任务适配</strong>：不同任务需匹配专属损失函数（如分类→交叉熵，回归→MSE） </li></ol><blockquote><p>生活化理解：驾校教练 → 根据学员压线距离扣分 → 损失函数就是那套评分标准  →  让学员学会不压线</p></blockquote><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/08/2.png" alt=""></p><p>损失函数主要分为以下三类：</p><ul><li>回归: 适用连续可导数据，常用于经济预测</li><li>分类: 适用x离散类别数据，常用于图像识别、垃圾邮件分类    </li><li>生成: 适用生成新数据样本，常用于AI绘画、视频生成</li></ul><h2 id="五大经典损失函数"><a href="#五大经典损失函数" class="headerlink" title="五大经典损失函数"></a>五大经典损失函数</h2><table><thead><tr><th><strong>损失函数</strong></th><th>适用任务</th><th>抗噪性</th><th>梯度特性</th><th>典型应用领域</th></tr></thead><tbody><tr><td>均均方误差（MSE）</td><td>回归</td><td>弱</td><td>连续可导</td><td>房价预测、气温预报等连续值预测</td></tr><tr><td>​​交叉熵（Cross-Entropy）</td><td>分类</td><td><strong>强</strong></td><td>指数衰减</td><td>图像分类、情感分析</td></tr><tr><td>​​合页损失（Hinge Loss）</td><td>分类</td><td>中</td><td>分段常数</td><td>文本分类、支持向量机</td></tr><tr><td>​​焦点损失（Focal Loss）</td><td>分类</td><td>中</td><td>自适应衰减</td><td>医学图像分析、异常检测</td></tr><tr><td>​​Huber损失</td><td>生成</td><td><strong>强</strong></td><td>连续可导</td><td>自动驾驶（需平衡噪声与异常值影响）</td></tr></tbody></table><p>损失函数选择<strong>黄金准则</strong>： </p><ol><li>分类任务优先交叉熵，样本不平衡时升级为Focal Loss  </li><li>回归任务首选MSE，需抗噪时切Huber  </li><li>生成任务需组合损失（如GAN：对抗损失 + L1像素损失）</li></ol><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ol><li><p><strong>自然界中的损失函数</strong>：<br>蜜蜂采蜜路径规划天然符合 <strong>TSP问题最短路径损失</strong>，误差&lt;2%  </p></li><li><p><strong>量子计算加速</strong>：<br>谷歌用 <strong>量子退火算法优化损失函数</strong>，训练速度提升1000倍  </p></li><li><p><strong>损失函数革命</strong>：<br>Contrastive Loss 推动自监督学习崛起（无需人工标注）  </p></li><li><p><strong>惊人数据</strong>：<br>AlphaGo Zero 的损失函数包含 <strong>赢棋概率预测</strong> + <strong>落子分布KL散度</strong>，双目标驱动模型进化  </p></li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;损失函数&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：损失函数 = 用来衡量模型预测值与真实值之间差异的函数，是优化算法的目标&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(6) - 激活函数​</title>
    <link href="https://www.qborfy.com/ailearn/daily/07.html"/>
    <id>https://www.qborfy.com/ailearn/daily/07.html</id>
    <published>2025-07-02T07:00:00.000Z</published>
    <updated>2025-07-02T12:42:36.019Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>激活函数​</strong></p><blockquote><p>一句话核心：激活函数(Rectification Function): 在神经网络模型里，如何把“激活的神经元的特征”通过函数把特征保留并映射出来， 通常<code>f(x) = wx + b</code>中 <code>f</code>就是激活函数。</p></blockquote><p>也简单理解成神经网络的 <strong>“智能开关”</strong>​。</p><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/07/1.png" alt=""></p><p><strong>百科定义</strong>: 激活函数（Activation Function），就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。</p><p><strong>三大核心功能​​：</strong></p><p>​- ​引入非线性​​：使网络能够拟合任意复杂函数（否则多层网络≈单层线性模型）</p><ul><li>数学表达：Output=f(∑wi*xi+b)<br>​- ​特征过滤​​：抑制噪声信号，保留有效特征（如ReLU过滤负值）</li><li>​​梯度调控​​：控制反向传播时的参数更新强度（防梯度消失/爆炸）</li></ul><blockquote><p>可以理解：大脑神经元 → 超过阈值才放电 → 激活函数决定信号是否向下传递</p></blockquote><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/07/2.png" alt=""></p><p>目前有 5 个经典主流激活函数：</p><ol><li>Sigmoid（逻辑函数）​：​<code>f(x) = 1/(1+e^(-x))</code>，输出<code>(0,1)</code>范围，适用二分类输出层（如信用风险预测），存在梯度问题（梯度消失/爆炸）</li><li>​​Tanh（双曲正切）​：​<code>f(x) = (e^x - e^(-x))/(e^x + e^(-x))</code>，输出<code>(-1,1)</code>范围，RNN/LSTM隐藏层（时序数据建模），梯度消失问题仍存在</li><li>ReLU（修正线性单元）​：<code>f(x) = max(0,x)</code>，输出<code>[0,∞)</code>范围，CNN/Transformer隐藏层（90%现代网络首选），解决梯度消失问题，但是存在Dead ReLU（负输入永久失活）</li><li>​​Leaky ReLU（带泄露修正）​：<code>f(x) = max(0.01x,x)</code>，输出<code>[0,∞)</code>范围，解决Dead ReLU问题，但存在梯度消失问题，解决Dead ReLU → 负数区保留微小梯度</li><li>​​Swish（自门控函数）​：<code>f(x) = x * σ(βx)</code>，Google Brain提出，β可学习，超越ReLU的基准精度，主要作用在移动端高效模型（MobileNetV3）</li></ol><p><strong>理解梯度和梯度问题？</strong></p><blockquote><p>梯度：反向传播时，参数更新的方向和大小。</p></blockquote><p>梯度问题：在模型训练的时候，接受反向传播时，如果梯度值很小，那么参数更新就会很慢，甚至无法更新，导致训练过程无法收敛，最终无法得出正确的特征。</p><p><strong>函数性能对比表</strong></p><table><thead><tr><th><strong>函数</strong></th><th>梯度消失</th><th>计算效率</th><th>输出中心化</th><th>SOTA精度</th><th>主要问题</th></tr></thead><tbody><tr><td>Sigmoid</td><td>严重</td><td>★★☆</td><td>否</td><td>60%</td><td>梯度消失</td></tr><tr><td>Tanh</td><td>较重</td><td>★★☆</td><td><strong>是</strong></td><td>75%</td><td>梯度消失</td></tr><tr><td>ReLU</td><td><strong>无</strong></td><td>★★★★★</td><td>否</td><td>90%</td><td>Dead ReLU</td></tr><tr><td>Leaky ReLU</td><td><strong>无</strong></td><td>★★★★☆</td><td>否</td><td>92%</td><td>参数$\alpha$敏感</td></tr><tr><td>Swish</td><td><strong>无</strong></td><td>★★★☆</td><td>否</td><td><strong>95%</strong></td><td>计算稍复杂</td></tr></tbody></table><h1 id="动手实验"><a href="#动手实验" class="headerlink" title="动手实验"></a>动手实验</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 激活函数效果可视化工具</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">functions = &#123;</span><br><span class="line">    <span class="string">&#x27;Sigmoid&#x27;</span>: <span class="keyword">lambda</span> x: <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x)),</span><br><span class="line">    <span class="string">&#x27;Tanh&#x27;</span>: np.tanh,</span><br><span class="line">    <span class="string">&#x27;ReLU&#x27;</span>: <span class="keyword">lambda</span> x: np.maximum(<span class="number">0</span>, x),</span><br><span class="line">    <span class="string">&#x27;Swish&#x27;</span>: <span class="keyword">lambda</span> x: x/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> name, func <span class="keyword">in</span> functions.items():</span><br><span class="line">    plt.plot(x, func(x), label=name, lw=<span class="number">3</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><blockquote><p><strong>观察重点</strong>：  </p><ul><li>Sigmoid/Tanh的饱和区（两端平坦） → 梯度消失根源  </li><li>ReLU的负数截断 → Dead ReLU问题可视化  </li></ul></blockquote><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ol><li><p><strong>神经元激活率实验</strong>：  </p><ul><li>Sigmoid网络仅3-5%神经元激活 → 效率低下  </li><li>ReLU网络激活率可达50% → 资源高效利用  </li></ul></li><li><p><strong>生物化学启发</strong>：<br>Swish函数的平滑性灵感源于 <strong>神经突触的离子通道动力学</strong>  </p></li><li><p><strong>谷歌的自动搜索</strong>：<br>用强化学习在10万种函数中发现 <strong>Swish ($x \cdot \sigma(x)$) 超越人类设计</strong>  </p></li><li><p><strong>宇宙学级应用</strong>：<br>欧洲核子研究中心(CERN)用 <strong>GELU函数</strong>（高斯误差线性单元）处理粒子碰撞数据，误差降低38%</p></li></ol><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;激活函数​&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：激活函数(Rectification Function): 在神经网络模型里，如何把“激活的神经元的特征”通过函数把特征保留并映射出来， 通常&lt;code&gt;f(x) = wx + b&lt;/code&gt;中 &lt;code&gt;f&lt;/code&gt;就是激活函数。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也简单理解成神经网络的 &lt;strong&gt;“智能开关”&lt;/strong&gt;​。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(5) - 深度学习</title>
    <link href="https://www.qborfy.com/ailearn/daily/05.html"/>
    <id>https://www.qborfy.com/ailearn/daily/05.html</id>
    <published>2025-06-30T09:09:51.704Z</published>
    <updated>2025-06-30T11:28:54.747Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>深度学习</strong></p><blockquote><p>一句话理解：让计算机像人类大脑一样，通过堆叠多层的‘神经元网络’，从原始数据中自动学习由简单到复杂的多层次特征表达，最终实现智能决策。</p></blockquote><p>对比之前 机器学习， 就是让计算机学会“举一反三”的深度思考能力，如：从认识鸟，到自动分辨出老鹰和麻雀的特征。</p><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/05/1.png" alt=""></p><p><strong>定义</strong>: 深度学习（也称为深度结构化学习 或分层学习）是基于学习数据表示的更广泛的机器学习方法系列的一部分，而不是特定于任务的算法。学习可以是监督，半监督或无监督。</p><p><strong>与传统机器学习对比</strong>：<br>| <strong>能力</strong>          | 传统方法          | 深度学习          |<br>|——————-|——————-|——————-|<br>| 特征工程依赖度    | 人工设计特征      | 自动学习特征      |<br>| 数据利用率        | 小样本有效        | 需大规模数据      |<br>| 处理非结构化数据  | 效果差（如图像）  | <strong>核心优势领域</strong>  |  </p><p>核心差别在特征提取环节，深度学习由机器自己完成特征提取，不需要人工提取。</p><p>​<strong>​关键认知​​：深度学习不是单个算法，而是通过​​层次化特征学习​​逼近人类智能的工程技术体系。掌握它，就掌握了AI时代的核心生产资料！</strong></p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/05/2.png" alt=""></p><p>深度学习的几个步骤：</p><ul><li>海量数据</li><li>神经网络关键算法<ul><li>正则化 Dropout：降低数据噪音</li><li>反向传播优化: 机器学习中调整神经网络算法的权重参数<ul><li>优化器 Adam/SGD算法：优化神经网络模型</li></ul></li></ul></li><li>逐层特征抽象：<ul><li>激活函数 ReLU：增强数据的稀疏性</li></ul></li><li>智能输出：得出分类或决策结果</li><li>计算损失：判断正确率，从而不断优化模型</li></ul><h1 id="经典案例"><a href="#经典案例" class="headerlink" title="经典案例"></a>经典案例</h1><p><strong>人脸识别过程</strong></p><ul><li>人脸检测：定位图像中所有人脸的位置（输出边界框）</li><li>人脸对齐：根据关键点（眼睛、鼻尖等）矫正人脸角度，消除姿态影响</li><li>特征提取：将人脸转化为高区分度的数字向量（128~512维）</li><li>特征匹配：计算特征向量间的相似度（如欧氏距离）</li></ul><h1 id="体验深度模型"><a href="#体验深度模型" class="headerlink" title="体验深度模型"></a>体验深度模型</h1><ul><li><a href="https://playground.tensorflow.org/">TensorFlow Playground</a>：调整层数/神经元观察效果</li></ul><h1 id="深度学习里程碑"><a href="#深度学习里程碑" class="headerlink" title="深度学习里程碑"></a>深度学习里程碑</h1><p>​- ​2012年 AlexNet​​：ImageNet识别错误率从26%降至15% → 引爆深度学习热潮<br>​​- 2016年 AlphaGo​​：战胜李世石 → 证明强化学习+深度网络决策能力<br>​​- 2020年 GPT-3​​：1750亿参数大模型 → 实现语言理解与创作</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/cnn/">卷积神经网络 – CNN？</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;深度学习&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话理解：让计算机像人类大脑一样，通过堆叠多层的‘神经元网络’，从原始数据中自动学习由简单到复杂的多层次特征表达，最终实现智能决策。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对比之前 机器学习， 就是让计算机学会“举一反三”的深度思考能力，如：从认识鸟，到自动分辨出老鹰和麻雀的特征。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(4) - 神经网络</title>
    <link href="https://www.qborfy.com/ailearn/daily/04.html"/>
    <id>https://www.qborfy.com/ailearn/daily/04.html</id>
    <published>2025-06-29T07:00:00.000Z</published>
    <updated>2025-06-29T09:32:46.453Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>神经网络算法</strong></p><blockquote><p>一句话核心：“神经网络 = 模拟人脑的计算网络，通过层层传递数据自动学习规律，​​输入→加工→输出​​是它的核心工作流”</p></blockquote><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/04/1.png" alt=""></p><p><strong>定义</strong>: 人工神经网络（Artificial Neural Network，即ANN ），是20世纪80 年代以来人工智能领域兴起的研究热点。它从信息处理角度对人脑神经元网络进行抽象， 建立某种简单模型，按不同的连接方式组成不同的网络。</p><h2 id="三层功能"><a href="#三层功能" class="headerlink" title="三层功能"></a>三层功能</h2><ol><li><strong>输入层</strong>：接收数据（如28x28像素的手写数字图片）  </li><li><strong>隐藏层</strong>：层层提取特征（线条→局部图案→完整数字）  </li><li><strong>输出层</strong>：给出预测结果（概率最大的数字0-9）  </li></ol><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p>神经网络如何实现预测结果？</p><ol><li>神经元计算(积木拼装), 将所有数据(w1)+影响因子(x1)+权重(b)都输入到网络中，公式:<code>w1*x1+w2*x2+...+wn*xn+b</code></li><li>激活函数（质检开关）​, 判断当前数据输出是否符合要求</li><li>​​损失函数（误差雷达）​, 计算预测值和实际值之间的误差，公式:<code>loss = (y-y&#39;)^2</code></li><li>经过三个步骤，不断迭代，直到误差最小，得到预测结果公式:<code>y&#39; = f(w1*x1+w2*x2+...+wn*xn+b)</code></li></ol><p><img src="/assets/img/ailearn/daily/04/2.png" alt=""></p><h2 id="神经网络算法类型"><a href="#神经网络算法类型" class="headerlink" title="神经网络算法类型"></a>神经网络算法类型</h2><table><thead><tr><th><strong>类型</strong></th><th>特点</th><th>典型应用</th><th>在线实验</th></tr></thead><tbody><tr><td>全连接网络</td><td>每层神经元全部连接</td><td>房价预测</td><td>TF Playground回归任务</td></tr><tr><td>卷积网络CNN</td><td>局部感知/权重共享</td><td>人脸识别</td><td>CNN Explainer可视化</td></tr><tr><td>循环网络RNN</td><td>记忆之前状态</td><td>语音识别</td><td>Karpathy Char-RNN</td></tr><tr><td>Transformer</td><td>自注意力机制</td><td>ChatGPT</td><td>Hugging Face Demo</td></tr></tbody></table><h1 id="生活案例"><a href="#生活案例" class="headerlink" title="生活案例"></a>生活案例</h1><p><strong>快递分拣中心模型</strong>：  </p><ul><li>收货区（输入层）：接收全国包裹（原始数据）  </li><li>分拣线（隐藏层）：<br>→ 首站：按省份粗分（提取大特征）<br>→ 中转：按城市细分（识别局部特征）<br>→ 末站：按街道精分（确认细节）  </li><li>发货区（输出层）：送至具体地址（分类结果） </li></ul><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ul><li>GPT-3的神经元数量（1750亿）≈ 人类大脑神经元（860亿）的 <strong>2倍</strong>，  </li><li>但人脑能耗仅20瓦，而训练GPT-3需 <strong>190万度电</strong>（相当于200家庭年用电）！</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="http://easyai.tech/ai-definition/ann//">什么是人工神经网络？</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;神经网络算法&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：“神经网络 = 模拟人脑的计算网络，通过层层传递数据自动学习规律，​​输入→加工→输出​​是它的核心工作流”&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(6) - 卷积网络CNN</title>
    <link href="https://www.qborfy.com/ailearn/daily/06.html"/>
    <id>https://www.qborfy.com/ailearn/daily/06.html</id>
    <published>2025-06-29T07:00:00.000Z</published>
    <updated>2025-07-03T13:58:07.116Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>卷积网络CNN</strong></p><blockquote><p>一句话核心：CNN = 模拟人类视觉系统，用<code>局部感知+参数共享</code>机制高效处理​​图像、视频、医学影像​​等网格数据</p></blockquote><p>简单理解就是将图片数据降低复杂度，在拆分成一个个小块（局部特征），结合统一的参数规划，最终完成图像识别。</p><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/06/1.png" alt=""></p><p><strong>定义</strong>: 卷积神经网络（Convolutional Neural Networks, CNN）是一类包含卷积计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习（deep learning）的代表算法之一 。由于卷积神经网络能够进行平移不变分类（shift-invariant classification），因此也被称为“平移不变人工神经网络（Shift-Invariant Artificial Neural Networks, SIANN）” 。</p><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>传统神经网络痛点:</p><ul><li>全连接参数爆炸（1000x1000图片 → 100万权重）  </li><li>忽略空间局部性（远处像素强行关联）  </li></ul><p>CNN对比优势：</p><table><thead><tr><th><strong>特性</strong></th><th>全连接网络</th><th>CNN卷积网络</th></tr></thead><tbody><tr><td>参数量（1000x1000图）</td><td>10^6 级</td><td>10^4 级（降99%）</td></tr><tr><td>空间信息处理</td><td>破坏局部结构</td><td>保留局部特征关联</td></tr><tr><td>平移不变性</td><td>无</td><td>有（物体移动仍可识别）</td></tr><tr><td>典型应用</td><td>结构化数据预测</td><td>图像/视频/医疗影像</td></tr></tbody></table><p>CNN卷积网络的优势：</p><ol><li>能够将大数据量的图片有效的降维成小数据量(并不影响结果)</li><li>能够保留图片的特征，类似人类的视觉原理</li></ol><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/06/2.png" alt=""></p><h2 id="三层功能"><a href="#三层功能" class="headerlink" title="三层功能"></a>三层功能</h2><ol><li><strong>输入层</strong>：接收数据（如28x28像素的手写数字图片）  </li><li><strong>隐藏层</strong>：层层提取特征（线条→局部图案→完整数字） <ol><li>提取特征（卷积）：卷积核（3x3像素）在图片上滑动，提取局部特征</li><li>池化（降维）：缩小图片尺寸，减少参数量，防止过拟合</li><li>激活（非线性）：防止过拟合，提升模型泛化能力</li><li>全连接：将提取到的特征组合起来，形成分类器</li></ol></li><li><strong>输出层</strong>：给出预测结果（概率最大的数字0-9）  </li></ol><p>卷积执行可视化： <a href="https://poloclub.github.io/cnn-explainer/">https://poloclub.github.io/cnn-explainer/</a> </p><h1 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h1><ul><li>图像分类：识别图片中的物体，如猫、狗、飞机、汽车等</li><li>目标检测：识别图片中的物体位置，如人脸、车辆、动物等</li><li>目标分割：识别图片中的物体位置和类别，如人、车、树、草等</li><li>人脸识别：识别图片中的人脸，如人脸验证、人脸检索等</li><li>图像生成：生成图片，如风格迁移、图像修复等</li></ul><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ul><li>深度CNN（如ResNet-152）中，仅15%卷积核激活显著，其余对输出贡献微弱。​​剪枝技术​​可删除冗余核，模型缩小90%，精度损失&lt;1% —— 手机端CNN的部署基础</li><li>2016年击败李世石的AlphaGo，其策略网络实为​​13层CNN</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/cnn/">卷积神经网络 – CNN？</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;卷积网络CNN&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：CNN = 模拟人类视觉系统，用&lt;code&gt;局部感知+参数共享&lt;/code&gt;机制高效处理​​图像、视频、医学影像​​等网格数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单理解就是将图片数据降低复杂度，在拆分成一个个小块（局部特征），结合统一的参数规划，最终完成图像识别。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>10篇 AI从零开始 - Langgraph开发(1)</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn10.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn10.html</id>
    <published>2025-06-27T07:00:00.000Z</published>
    <updated>2025-06-28T14:24:51.058Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面我们学了LangChain的使用和Agent开发，Langchain是一个线性工作流，如果想要在实际开发复杂的Agent，那么实现非常麻烦，比如可能会遇上一以下一些问题：</p><ul><li>当调用某个工具方法出现错误或不是所需要的结果，需要循环调用工具方法直到返回需要的结果</li><li>当需要一次任务中，需要保存不同工作节点的状态</li><li>当需要调用不同LLM模型时候</li><li>当链路中断，需要从上一个工作节点继续执行</li><li>……</li></ul><p>为了解决这些问题，LangChain抽象出一个高级框架: <code>LangGraph</code>，接下来就开始学习LangGraph的开发。</p><span id="more"></span><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><blockquote><p>LangGraph 是一个用于构建、管理和部署长期运行、有状态代理的低级编排框架，受到塑造代理未来的公司（包括 Klarna、Replit、Elastic 等）的信赖。</p></blockquote><h2 id="主要架构"><a href="#主要架构" class="headerlink" title="主要架构"></a>主要架构</h2><p>一个LangGraph有状态(State)、节点(Node)、边(Egde)组成，如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn10-01.png" alt="LangGraph"></p><ul><li><strong>状态(State)</strong>：可以理解为Agent整体上下文，用于存储Agent运行过程中产生的数据，比如：任务状态、任务结果等</li><li><strong>节点(Node)</strong>：可以理解为Agent调用的工具或函数，用于表示Agent执行过程中的一个步骤，比如：调用LLM模型、调用Tool API等</li><li><strong>边(Edge)</strong>：可以理解为Agent执行下一节点所需要执行的逻辑判断， 用于表示节点之间的链接关系，比如：判断是直接返回给用户，还是调用Tool工具</li></ul><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li><strong>循环和分支</strong>：可以实现循环和条件判断</li><li><strong>持久性</strong>：在LangGraph中的每个节点Node后都会自动保存到状态State中，因此在任何时候暂时或异常中断都可以重新恢复</li><li><strong>人机交互</strong>：中断当前任务，是否允许当前节点执行还是跳过当前节点执行</li><li><strong>流Stream支持</strong>：支持流Stream输出</li><li><strong>LangChain无缝集成</strong>：LangGraph、LangChain、LangSimit 无缝集成，无需额外配置</li></ul><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装LangGraph LangChain  Ollama依赖的大模型</span></span><br><span class="line">pip install -U langgraph langchain langchain_ollama</span><br></pre></td></tr></table></figure><h2 id="Hello-World示例"><a href="#Hello-World示例" class="headerlink" title="Hello World示例"></a>Hello World示例</h2><p>接下来我们尝试实现一个大模型调用日期Tool工具函数，实现获取当前日期的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个日期工具函数</span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line"></span><br><span class="line"><span class="comment"># graph的各种节点与状态</span></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> END, StateGraph, MessagesState</span><br><span class="line"><span class="comment"># 持久化状态</span></span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"><span class="comment"># 调用工具的node节点</span></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_day</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取今天日期&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> datetime.now().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line"></span><br><span class="line">tools = [get_current_day]</span><br><span class="line"><span class="comment"># 创建工具节点</span></span><br><span class="line">tool_node = ToolNode(tools)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绑定工具列表到大模型中</span></span><br><span class="line">llm = ChatOllama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;qwen3:32b&quot;</span></span><br><span class="line">).bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义调用LLM大模型Node节点</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_llm</span>(<span class="params">state: MessagesState</span>):</span><br><span class="line">    messages = state[<span class="string">&#x27;messages&#x27;</span>]</span><br><span class="line">    response = llm.invoke(messages)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: response</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 定义工作流和初始化状态</span></span><br><span class="line">workflow = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 添加节点</span></span><br><span class="line">workflow.add_node(<span class="string">&quot;agent&quot;</span>, call_llm)</span><br><span class="line">workflow.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 定义工作流入口设定为agent</span></span><br><span class="line">workflow.set_entry_point(<span class="string">&quot;agent&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 添加条件边， agent有条件（是否继续执行函数判断）的流转线</span></span><br><span class="line"><span class="comment"># 定义函数，是否继续执行</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">should_continue</span>(<span class="params">state: MessagesState</span>) -&gt; <span class="type">Literal</span>[<span class="string">&quot;tools&quot;</span>, END]:</span><br><span class="line">    messages = state[<span class="string">&#x27;messages&#x27;</span>]</span><br><span class="line">    <span class="comment"># 获取最新的消息 判断是否应该调用工具</span></span><br><span class="line">    last_message = messages[-<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># LLM调用工具 则转到tools节点</span></span><br><span class="line">    <span class="keyword">if</span> last_message.tool_calls:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="keyword">return</span> END</span><br><span class="line"></span><br><span class="line">workflow.add_conditional_edges(</span><br><span class="line">    <span class="comment"># source 表示上一个节点输出的内容</span></span><br><span class="line">    <span class="string">&quot;agent&quot;</span>,</span><br><span class="line">    <span class="comment"># 接下来要执行的判断操作</span></span><br><span class="line">    should_continue,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5 添加tools到agent的普通链接，直接把tools返回内容给到agent</span></span><br><span class="line">workflow.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;agent&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6 添加checkpointer 经过每个节点都会保存到状态中，然后编译成LangChain链</span></span><br><span class="line"><span class="comment"># MemorySaver 支持redis、mongodb</span></span><br><span class="line">checkpointer = MemorySaver()</span><br><span class="line">app = workflow.<span class="built_in">compile</span>(checkpointer=checkpointer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7 执行graph</span></span><br><span class="line">final_state = app.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="string">&quot;今天几号&quot;</span>)]&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8 获取最终结果输出</span></span><br><span class="line">result = final_state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><p>执行上面的代码，我们可以获得到当前的日期，结果如下图：</p><p><img src="/assets/img/ailearn/ai-learn10-02.png" alt="LangGraph"></p><h2 id="多轮会话功能"><a href="#多轮会话功能" class="headerlink" title="多轮会话功能"></a>多轮会话功能</h2><p>上面我们实现了让Agent调用工具函数获取当天日期，接下来我们实现通过会话记录，让Agent可以根据之前的记录回答问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 7 执行graph 添加会话id</span></span><br><span class="line">final_state = app.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="string">&quot;今天几号&quot;</span>)]&#125;,</span><br><span class="line">    <span class="comment"># 这里config是配置是不是同一个会话的id</span></span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="number">42</span>&#125;&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8 获取最终结果输出</span></span><br><span class="line">result = final_state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 9 测试记录会话状态</span></span><br><span class="line">final_state = app.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="string">&quot;我刚刚问的哪天&quot;</span>)]&#125;,</span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="number">42</span>&#125;&#125;</span><br><span class="line">)</span><br><span class="line">result = final_state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><p>最终LLM大模型返回结果如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn10-03.png" alt="LangGraph"></p><p>上面代码执行完后，可以大概LangGraph执行过程有个初步了解，也可以通过生成Meraid Graph图片具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 10 保存Graph到本地图片</span></span><br><span class="line">graph_png = app.get_graph().draw_mermaid_png()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;langgraph1.png&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(graph_png)</span><br></pre></td></tr></table></figure><p>最终得到图片，如下图所示:<br><img src="/assets/img/ailearn/ai-learn10-04.png" alt="LangGraph"></p><ul><li><code>__start__</code>: 代表开始节点，也可以理解成初始化<code>StateGraph</code>工作流</li><li><code>agent</code>: 代表agent节点，设置了入口第一个节点，等同于<code>workflow.add_node(&quot;agent&quot;)</code></li><li><code>tools</code>: 代表工具节点，设置了工具节点，等同于<code>workflow.add_node(&quot;tools&quot;, tool_node)</code></li><li><code>实现连接线</code>: 代表当前节点执行完后，无需条件判断，直接流转到下一个节点，等同于<code>workflow.add_edge(&quot;tools&quot;, &quot;agent&quot;)</code></li><li><code>虚线连接线</code>: 代表条件边执行，当前节点执行完后，需要判断是否继续执行，如果继续执行则流转到下一个节点，否则流转到结束节点，等同于<code>workflow.add_conditional_edges(&quot;agent&quot;, should_continue)</code></li><li><code>_end</code>: 代表结束节点</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>经过上面学习，总结下本篇文章：</p><ul><li>LangGraph是LangChain的抽象而来的高级框架，能够实现更加复杂的工作流，如：循环、条件判断、多轮会话等</li><li>LangGraph的几个核心概念：<code>State</code>、<code>Node</code>、<code>Edge</code>等作用</li><li>一个<code>HelloWorld</code>的例子，可以看出比LangChain更加简单，加上State多轮会话记录功能，减少开发工作量</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://langchain-ai.github.io/langgraph/">LangGraph官方文档</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?p=10&share_source=copy_web&vd_source=ddb29dacf001bda27b38794cc29b82c8">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们学了LangChain的使用和Agent开发，Langchain是一个线性工作流，如果想要在实际开发复杂的Agent，那么实现非常麻烦，比如可能会遇上一以下一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当调用某个工具方法出现错误或不是所需要的结果，需要循环调用工具方法直到返回需要的结果&lt;/li&gt;
&lt;li&gt;当需要一次任务中，需要保存不同工作节点的状态&lt;/li&gt;
&lt;li&gt;当需要调用不同LLM模型时候&lt;/li&gt;
&lt;li&gt;当链路中断，需要从上一个工作节点继续执行&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了解决这些问题，LangChain抽象出一个高级框架: &lt;code&gt;LangGraph&lt;/code&gt;，接下来就开始学习LangGraph的开发。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(2) - 无监督学习</title>
    <link href="https://www.qborfy.com/ailearn/daily/02.html"/>
    <id>https://www.qborfy.com/ailearn/daily/02.html</id>
    <published>2025-06-26T07:00:00.000Z</published>
    <updated>2025-06-26T05:03:22.020Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>无监督学习</strong></p><blockquote><p>一句话核心：让AI在「没有标准答案」的数据中自己发现规律——像人类探索未知世界！</p></blockquote><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/02/1.png" alt=""></p><p><strong>定义</strong>：从未标记数据中挖掘隐藏模式，通常采用聚类、降维、关联等算法去发现数据中的规律。  </p><p>✅ 关键特征：无老师指导、数据无标签<br>❌ 常见误区 ≠ 完全不需要人类（仍需设计算法目标）</p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/02/2.png" alt=""></p><p>无监督学习，主要实现算法方案有以下三种：</p><ul><li>聚类：相似数据分组</li><li>降纬：压缩数据特征</li><li>关联：发现数据关联规律</li></ul><h2 id="聚类-K均值聚类-——-物以类聚"><a href="#聚类-K均值聚类-——-物以类聚" class="headerlink" title="聚类(K均值聚类) —— 物以类聚"></a>聚类(K均值聚类) —— 物以类聚</h2><p>主要解决问题： “哪些东西本质相似？”</p><p>例子： 自助餐厅菜品自动分区</p><ul><li>原始状态：200道菜杂乱摆放</li><li>聚类过程：<ul><li>✓ 算法检测菜品特征（烹饪方式/食材/口味）</li><li>✓ 自动划分为：海鲜刺身区、川湘热炒区、西式烘焙区</li></ul></li><li>价值：顾客5秒锁定目标区域</li></ul><h2 id="降维-PCA-——-去芜存菁"><a href="#降维-PCA-——-去芜存菁" class="headerlink" title="降维(PCA) —— 去芜存菁"></a>降维(PCA) —— 去芜存菁</h2><p>主要解决问题： “如何简化复杂信息？”</p><p>例子： 购房决策简化模型</p><ul><li>原始参数：20个维度（学区/通勤/绿化率/物业费…）</li><li>降维过程：<ul><li>✓ 算法提取核心特征 → 教育资源指数 &amp; 生活便利度</li><li>✓ 生成二维图谱</li></ul></li><li>价值：半小时锁定目标房源</li></ul><h2 id="关联（Association）——-发现隐藏规律"><a href="#关联（Association）——-发现隐藏规律" class="headerlink" title="关联（Association）—— 发现隐藏规律"></a>关联（Association）—— 发现隐藏规律</h2><p>主要解决问题： “哪些事总一起发生？”</p><p>例子： 便利店商品摆放策略</p><ul><li>原始数据：10万条购物小票</li><li>关联规则挖掘：<ul><li>{薯片，可乐} → {纸巾} [支持度=22%，置信度=81%]</li><li>规律：买零食饮料的顾客81%会顺手拿纸巾</li></ul></li><li>价值：收银台旁放置纸巾架→ 纸巾销量+35%</li></ul><h1 id="动手实验"><a href="#动手实验" class="headerlink" title="动手实验"></a>动手实验</h1><ul><li>聚类实操：用<code>K-means GUI</code>可视化分群过程 → <a href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/">在线查看</a></li><li>降维对比：在<code>TensorFlow Embedding Projector</code> 看词向量压缩 → <a href="https://projector.tensorflow.org/">在线查看</a></li><li>关联发现：通过Python实现超时购物车数据分析 →<a href="https://pbpython.com/market-basket-analysis.html">在线查看</a></li></ul><h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><ul><li>电商聚类：亚马逊用<code>DeepCluster</code>算法将商品分成27万类（比人工分类多19倍）</li><li>降维奇效：NASA用<code>t-SNE</code>分析星系图像，将数据处理时间从3周缩短到4小时</li><li>关联暴利：7-Eleven发现 <code>关东煮 + 清酒</code> 关联销售规律，冬季单店增收$6,800</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/unsupervised-learning/">一文学会无监督学习 – Unsupervised learning</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;无监督学习&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：让AI在「没有标准答案」的数据中自己发现规律——像人类探索未知世界！&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(3) - 强化学习</title>
    <link href="https://www.qborfy.com/ailearn/daily/03.html"/>
    <id>https://www.qborfy.com/ailearn/daily/03.html</id>
    <published>2025-06-26T07:00:00.000Z</published>
    <updated>2025-06-27T07:44:02.771Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>强化学习</strong></p><blockquote><p>一句话核心：AI在试错中成长，像小孩学走路，通过奖励/惩罚信号找到最优行为策略</p></blockquote><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/03/1.png" alt=""></p><p><strong>定义</strong>: 强化学习(reinforcement learning)，又称再励学习、评价学习，是一种重要的机器学习方法，在智能控制机器人及分析预测等领域有许多应用。</p><blockquote><p>百度百科： 在连接主义学习中，把学习算法分为三种类型，即<strong>非监督学习(unsupervised learning)</strong>、<strong>监督学习(supervised leaning)</strong>和<strong>强化学习</strong>。</p></blockquote><p>✅ 关键特征：奖励与惩罚</p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/03/2.png" alt=""></p><table><thead><tr><th><strong>维度</strong></th><th>免模型学习 (Model-Free)</th><th>有模型学习 (Model-Based)</th></tr></thead><tbody><tr><td><strong>核心思想</strong></td><td><strong>直接学习策略</strong></td><td><strong>先理解环境运作规则</strong></td></tr><tr><td>工作方式</td><td>试错→记下最佳动作</td><td>构建环境模拟器→规划行动</td></tr><tr><td>计算成本</td><td>低（不需模拟环境）</td><td>高（需建模环境动态）</td></tr><tr><td>适用场景</td><td>环境复杂难建模（如股票交易）</td><td>环境可精确仿真（如围棋）</td></tr><tr><td>代表算法</td><td>Q-Learning, DQN</td><td>动态规划, MCTS</td></tr><tr><td>—</td><td></td><td></td></tr></tbody></table><ul><li>免模型：当前状态 → 查表选最高Q值动作  </li><li>有模型：当前状态 → 模拟未来N步 → 选最优路径  </li></ul><h2 id="免模型学习"><a href="#免模型学习" class="headerlink" title="免模型学习"></a>免模型学习</h2><p><strong>案例：学骑电动车</strong></p><ul><li><strong>试错过程</strong><ul><li>右转时摔倒 → <strong>惩罚</strong>（痛觉信号）  </li><li>保持平衡前进 → <strong>奖励</strong>（速度感）  </li></ul></li><li><strong>关键特点</strong>：无需理解机械原理，靠肌肉记忆学习  </li></ul><h2 id="有模型学习"><a href="#有模型学习" class="headerlink" title="有模型学习"></a>有模型学习</h2><p><strong>案例：国际象棋对战</strong></p><ul><li><strong>建模过程</strong>：  <ul><li>先背棋谱（学习“兵走直线，象飞斜角”规则）  </li><li>大脑推演：“如果走车，对方可能有3种回应…”  </li></ul></li><li><strong>关键特点</strong>：依赖对环境的精确认知  </li></ul><p>免模型和有模型算法区别：</p><p><img src="/assets/img/ailearn/daily/03/3.png" alt=""></p><h1 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h1><h2 id="免模型案例：AlphaGo的走棋网络"><a href="#免模型案例：AlphaGo的走棋网络" class="headerlink" title="免模型案例：AlphaGo的走棋网络"></a>免模型案例：AlphaGo的走棋网络</h2><ul><li><strong>输入</strong>：棋盘当前状态  </li><li><strong>输出</strong>：直接评估落子位置价值  </li><li><strong>优势</strong>：省去推演计算，每秒决策100+次  </li><li><strong>工具复现</strong>：OpenAI Gym围棋环境  </li></ul><h2 id="有模型案例：特斯拉自动驾驶仿真"><a href="#有模型案例：特斯拉自动驾驶仿真" class="headerlink" title="有模型案例：特斯拉自动驾驶仿真"></a>有模型案例：特斯拉自动驾驶仿真</h2><ul><li><strong>环境模型</strong>：  <ul><li>物理引擎模拟雨天路滑  </li><li>神经网络生成行人行为  </li></ul></li><li><strong>优势</strong>：0风险试错百亿次  </li><li><strong>开发框架</strong>：CARLA仿真平台  </li></ul><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ul><li>DeepMind用免模型 <strong>DQN</strong> 玩打砖块游戏，2小时超越人类水平，4小时发现开发者未预设的 <strong>挖地道秘籍</strong>  </li><li>波士顿动力机器人摔倒时<strong>调整姿态的算法</strong>，本质是免模型的 <strong>策略梯度（PPO）</strong>  </li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/reinforcement-learning/">一文学会强化学习-Reinforcement learning | RL</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：AI在试错中成长，像小孩学走路，通过奖励/惩罚信号找到最优行为策略&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(1) - 监督学习</title>
    <link href="https://www.qborfy.com/ailearn/daily/01.html"/>
    <id>https://www.qborfy.com/ailearn/daily/01.html</id>
    <published>2025-06-25T07:00:00.000Z</published>
    <updated>2025-06-26T04:38:16.393Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>监督学习</strong>。</p><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><blockquote><p><strong>监督学习</strong>：让AI像学生一样，通过「带答案的习题集」学习总结出规律，然后根据规律应用到新的习题中。</p></blockquote><p>监督学习，是机器学习中的一种方式，把已经分类的数据给到数据模型，让模型自己学习规律，然后对没有分类的数据进行分类。</p><span id="more"></span><p><img src="/assets/img/ailearn/daily/01/1.png" alt=""></p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/01/2.png" alt=""></p><p>怎么让AI模型根据训练数据，总结规律呢？主要分为两个类型：</p><ul><li>回归: 数值预测，数据是连续的、具体的</li><li>分类: 类别判断，数据是离散的</li></ul><p>一张图理解两者的区别<br><img src="/assets/img/ailearn/daily/01/3.png" alt=""></p><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><p>例子： 天气预测，连续数值（如温度）的预测。<br>预测目标​: 今天天气是多少度<br>​​常见算法​: 线性回归、决策树回归<br>提供训练数据：A(湿度)、B(风力)、C(海拔)、D(风向),Y(温度)<br>最终输出： Y = f(A,B,C,D) 公式 ，输入新的ABCD，的到最终天气温度</p><h2 id="分类任务"><a href="#分类任务" class="headerlink" title="分类任务"></a>分类任务</h2><p>例子： 动物分类， 离散类别数据（如：猫、狗）的预测。<br>预测目标​: 判断图片是猫还是狗<br>​​常见算法​: 逻辑回归、支持向量机<br>标签分值：眼睛(5)、鼻子(7)、耳朵(6)、嘴巴(7) = 猫， 眼睛(5)、鼻子(5)、耳朵(6)、嘴巴(7) = 狗<br>最终输出： 猫(20~40) ， 狗（42～60）输入图片的到最终分类</p><h1 id="动手试试！"><a href="#动手试试！" class="headerlink" title="动手试试！"></a>动手试试！</h1><p>打开 [Google Teachable Machine]  </p><ol><li>点击「图片项目」→ 创建「苹果」「橘子」分类  </li><li>用手机拍摄/上传20张样本  </li><li>点击「训练」→ 测试新图片识别效果！<br>🔗 工具链接：<a href="https://teachablemachine.withgoogle.com/">https://teachablemachine.withgoogle.com/</a></li></ol><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><p>ImageNet数据集包含1400万张带标签图片，AI学习它相当于人类不眠不休看16年照片！</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/supervised-learning/">一文学会监督学习 – Supervised learning</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;监督学习&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&quot;是什么&quot;&gt;&lt;a href=&quot;#是什么&quot; class=&quot;headerlink&quot; title=&quot;是什么&quot;&gt;&lt;/a&gt;是什么&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;监督学习&lt;/strong&gt;：让AI像学生一样，通过「带答案的习题集」学习总结出规律，然后根据规律应用到新的习题中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;监督学习，是机器学习中的一种方式，把已经分类的数据给到数据模型，让模型自己学习规律，然后对没有分类的数据进行分类。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>09篇 AI从零开始 - LangChain学习与实战(6) Agent智能体开发</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn09.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn09.html</id>
    <published>2025-05-26T07:00:00.000Z</published>
    <updated>2025-06-26T11:02:00.494Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面我们已经学习如何通过 Langchain调用独立部署的<code>DeepSeek-R1:32b</code>模型，且完成一些简单的应用，如： RAG 知识库的实现。</p><p>接下来我们学习如何通过LangChain实现一个Agent智能体，从而让 AI 模型帮忙实现做更多事情。</p><span id="more"></span><h1 id="1-Agent智能体"><a href="#1-Agent智能体" class="headerlink" title="1. Agent智能体"></a>1. Agent智能体</h1><h2 id="1-1-是什么"><a href="#1-1-是什么" class="headerlink" title="1.1 是什么"></a>1.1 是什么</h2><p>在开发之前我们先来了解下Agent智能体是什么，它主要解决什么问题？</p><blockquote><p>Agent是使用 LLM 大模型作为推理引擎的系统，用于确定应采取哪些行动(Action)以及这些行动输入应该是什么，然后会把行动的输出结果反馈给到Agent，用于判断是否需要更多行动或者结束然后输出返回。</p></blockquote><p>结合网上的资料和个人理解，Agent智能体的出现主要是解决以下问题：</p><ul><li>LLM大模型与人类之间的交互是基于 prompt 实现的，prompt 是否清晰明确会影响大模型回答的效果</li><li>LLM大模型只能进行推理，无法进行实际性的行动</li><li>LLM大模型只能单独使用，无法结合多个 LLM 大模型进行组合使用</li><li>LLM大模型只能输出文本，却无法符合用户需要的数据结构，如：如何标准的 JSON Schema</li><li>LLM大模型只能依据当前输入进行推理，无法进行长期记忆</li></ul><p>AI Agent是模仿人类思考技术，具体如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn09-1.png" alt=""></p><p><strong><em>一句话弄明白，就是AI大模型可以作为一个大脑进行学习推理，但是 Agent技术利用 LLM大模型的推理能力，能根据人类输入，代替人类去做一些真正想要的事情，最后输出人类真正想要结果或者去执行某些行动。</em></strong></p><p>为了更好理解 Agent技术， 我们可以看看目前AI协同工作类型，具体如下：</p><ol><li>Embbedding 模式: 人类输入目标，AI输出几个意见，人类自主决定采用哪个意见，代表产品为: RAG 智能客服机器人</li><li>Copilot 模式: 人类输入目标，AI经过几个流程确定初步输出，人类可以自由调整输出，代表产品为: <a href="https://github.com/features/copilot">Copilot代码提示</a></li><li>Agent 模式: 人类输入目标，AI 根据输入自主拆分任务，然后根据任务所需要的选择工具，最终完成任务最终结束，代表产品为: <a href="https://manus.im/">Manus AI 助手</a></li></ol><h2 id="1-2-怎么做"><a href="#1-2-怎么做" class="headerlink" title="1.2 怎么做"></a>1.2 怎么做</h2><p>上面说到Agent技术是模仿人类思考技术，利用大模型进行推理，拆分人类输入的任务，那么 Agent其实最大的重点在于激发 LLM 大模型的推理能力，去拆分人类输入的任务。</p><p>那么如何激发 LLM 大模型的推理能力呢？ 主要有以下几点：</p><h3 id="1-Prompt-的思考链"><a href="#1-Prompt-的思考链" class="headerlink" title="1. Prompt 的思考链"></a>1. Prompt 的思考链</h3><blockquote><p>思维链（Chain of Thoughts）已成为一种标准的提示技术，用于提高模型在复杂任务中的表现。模型被要求 “一步一步地思考”，将艰巨的任务分解为更小更简单的步骤。思维链将大任务转化为多个可管理的任务，并帮助人们理解模型的思维过程。</p></blockquote><p>无思考链的 Prompt：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">问：罗杰有5个网球，他又买了两盒网球，每盒有3个网球。他现在有多少网球？</span><br><span class="line">答：答案是11</span><br><span class="line">问：食堂有23个苹果，如果他们用掉20个后又买了6个。他们现在有多少个苹果？</span><br><span class="line">模型输出：</span><br><span class="line">答：答案是27</span><br></pre></td></tr></table></figure><p>有思考链的 Prompt：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">问：罗杰有5个网球，他又买了两盒网球，每盒有3个网球。他现在有多少网球？</span><br><span class="line">答：罗杰一开始有5个网球，2盒3个网球，一共就是2*3=6个网球，5+6=11。答案是11.</span><br><span class="line">问：食堂有23个苹果，如果他们用掉20个后又买了6个。他们现在有多少个苹果？</span><br><span class="line">模型输出：</span><br><span class="line">答：食堂原来有23个苹果，他们用掉20个，所以还有23-20=3个。他们又买了6个，所以现在有6+3=9。答案是9 </span><br></pre></td></tr></table></figure><p>PS: <code>DeepSeek</code>的推理模式出来后，现在大部分模型默认就支持思考链的回答了。</p><p><strong>思维树</strong> 是思维链的另一种表现形式，通过在任务的每一步探索多种推理可能性来扩展思维链。它首先将问题分解为多个思考步骤，并在每个步骤中生成多个想法，从而创建一个树状结构。试错和纠错在现实世界的任务决策中是不可避免且至关重要的步骤。自我反思帮助 AI Agent 完善过去的行动决策、纠正以前的错误、从而不断改进。主要可以包括以下几种模式：</p><ol><li>ReAct: 结合推理（Reasoning）和行动（Action）​​，动态与环境交互。简单的理解就是: 推理+动作。</li><li>Reflexion: 让 AI Agent 具备动态记忆和自我反思能力以提高推理能力的框架。简单的理解就是: 重复步骤（记忆+推理+动作）。</li><li>Hindsight: 利用已知结果优化过去决策​​，从失败经验中学习。简单理解就是: 根据已知结果进行反向推理。</li></ol><h3 id="2-记忆"><a href="#2-记忆" class="headerlink" title="2. 记忆"></a>2. 记忆</h3><blockquote><p>记忆模块负责存储信息，包括过去的交互、学习到的知识，甚至是临时的任务信息。</p></blockquote><p>AI有了记忆后，就可以根据已知的记忆知识去更好回答用户提问。而在 AI Agent 定义里：</p><blockquote><p>用户在与其交互过程中产生的内容都可以认为是 Agent 的记忆，和人类记忆的模式能够产生对应关系。</p></blockquote><p>记忆可以分为几类：</p><ul><li>感觉记忆: 初始输入文本、图片等数据，如：看一张照片后，当不看照片，还能想起照片的印象，这是感觉记忆</li><li>短期记忆: 本次与 AI 对话的上下文，如：进行记忆几个数字，短期内还是可以记住这几个数字，这就是短期记忆</li><li>长期记忆: Agent在工作时需要查询向量数据库，如：学会骑自行车，及时很长时间没骑自行车，但是骑自行车这个技能还在，那么骑自行车这个技能就是长期记忆</li></ul><p>而针对记忆这方面的技术， Embedding 技术和向量相似度计算就是记忆（向量数据库的核心），具体可以做以下理解：</p><ul><li>Embedding 技术：将文本、图片等数据转换为向量，从而实现记忆功能</li><li>向量相似度计算：通过数学方法来计算两个向量之间的相似度，常见的算法有：余弦相似度、欧式距离、汉明距离等，通过相似度计算可以判断两个向量是否相似，从而获取我们所需要的记忆数据</li></ul><h3 id="3-工具"><a href="#3-工具" class="headerlink" title="3. 工具"></a>3. 工具</h3><blockquote><p>AI 懂得使用工具才会更像人类。</p><p>AI Agent 除了记忆，还需要在获取到每一步子任务的工作后，Agent 都会判断是否需要通过调用外部工具来完成该子任务，并在完成后获取该外部工具返回的信息提供给 LLM，进行下一步子任务的工作。</p></blockquote><p>目前AI 大模型接入工具的使用方式如下：</p><ol><li>函数调用(Function Call): 向大模型描述函数，如：函数的作用和参数结构（如：JSON对象），从让 AI 大模型在执行任务能够调用外部工具，如：<code>open(&quot;test.txt&quot;)</code></li><li>插件系统​(Plugin)​:通过标准化接口扩展大模型能力，等同于公共的函数调用，让大家都能用。</li><li>模型内嵌工具: 不同模型会提供不同内置工具，如：OpenAI 的<code>file_search</code>和<code>code_interpreter</code>，能AI直接调用去搜索文件和解析文件的能力。</li></ol><p>目前绝大部分 AI Agent开发使用的工具的方式都是 <code>Function Call</code>的方式，目前主流大模型基本都支持这个能力，具体如下：</p><table><thead><tr><th>模型</th><th>支持Function Call</th><th>说明</th></tr></thead><tbody><tr><td>GPT-4 Turbo、GPT-4o、GPT-3.5 Turbo</td><td>是</td><td>OpenAI 系列模型，闭源</td></tr><tr><td>​Claude 3（Opus/Sonnet/Haiku）、Claude 3.5</td><td>是</td><td>Anthropic 系列模型，闭源​</td></tr><tr><td>Gemini Pro、Gemini 1.5 Pro、Gemini Flash</td><td>是</td><td>OpenAI 系列模型，闭源​</td></tr><tr><td>Llama 3（8B/70B）、Llama 3.1</td><td>是</td><td>Meta Llama 系列​，开源​， 需要微调后才支持，不过有现成的 Gorilla 微调框架</td></tr><tr><td>Mistral Large、Mistral-7B-Instruct</td><td>是</td><td>Mistral AI 系列​，开源​，轻量级模型适合本地部署​</td></tr><tr><td>通义千问（Qwen-Chat）</td><td>是</td><td>阿里云系列​ ​，开源​，基于 ReAct Prompting 原理优化工具</td></tr><tr><td>GLM-Z1-32B-0414、ChatGLM3-6B</td><td>是</td><td>清华智谱系列模型，开源​</td></tr><tr><td>​​DeepSeek V3​​</td><td>是</td><td>​​DeepSeek，开源​，专为函数调用优化，支持多工具协同</td></tr></tbody></table><h1 id="2-Langchain-AI-Agent开发实战"><a href="#2-Langchain-AI-Agent开发实战" class="headerlink" title="2. Langchain AI Agent开发实战"></a>2. Langchain AI Agent开发实战</h1><p>完整了解 Agent的知识后，解析来我们要通过Langchain框架去实现一个 AI Agent，获取获取当天的龙虎榜数据。</p><h2 id="2-1-基础概念"><a href="#2-1-基础概念" class="headerlink" title="2.1 基础概念"></a>2.1 基础概念</h2><ul><li><code>langchain_core.tools.tool</code>: Langchain用来创建工具的方法</li><li><code>langchain.agents.create_tool_calling_agent</code>: 创建工具调用Agent的函数</li><li><code>langchain.agents.AgentExecutor</code>: 创建 Agent执行器的类</li></ul><p>开始实现思路如下：</p><ol><li>编写工具函数和工具描述</li><li>创建LLM模型</li><li>创建符合工具调用Agent的Prompt</li><li>创建Agent和 AgentExecutor</li><li>通过LangSmith查看 Agent执行过程（调试使用）</li></ol><h2 id="2-2-工具声明"><a href="#2-2-工具声明" class="headerlink" title="2.2 工具声明"></a>2.2 工具声明</h2><h3 id="获取当前日期"><a href="#获取当前日期" class="headerlink" title="获取当前日期"></a>获取当前日期</h3><p>接下来我们声明一个工具函数，用于解决大模型无法判断当前的日期。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_day</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取今天的时间&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> date.today().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="获取龙虎榜数据"><a href="#获取龙虎榜数据" class="headerlink" title="获取龙虎榜数据"></a>获取龙虎榜数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入参数格式说明</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LhbInput</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    date: <span class="built_in">str</span> = Field(description=<span class="string">&quot;date,  format is YYYY-MM-DD&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool(<span class="params">args_schema=LhbInput</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_lhb</span>(<span class="params">date: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取龙虎榜数据&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始获取%s龙虎榜&quot;</span> % date)</span><br><span class="line">    callback = <span class="string">&quot;jQuery1123029212767559503716_1747729555061&quot;</span></span><br><span class="line">    url = <span class="string">f&quot;https://datacenter-web.eastmoney.com/api/data/v1/get?callback=<span class="subst">&#123;callback&#125;</span>&amp;sortColumns=SECURITY_CODE%2CTRADE_DATE&amp;sortTypes=1%2C-1&amp;pageSize=200&amp;pageNumber=1&amp;reportName=RPT_DAILYBILLBOARD_DETAILSNEW&amp;columns=SECURITY_CODE%2CSECUCODE%2CSECURITY_NAME_ABBR%2CTRADE_DATE%2CEXPLAIN%2CCLOSE_PRICE%2CCHANGE_RATE%2CBILLBOARD_NET_AMT%2CBILLBOARD_BUY_AMT%2CBILLBOARD_SELL_AMT%2CBILLBOARD_DEAL_AMT%2CACCUM_AMOUNT%2CDEAL_NET_RATIO%2CDEAL_AMOUNT_RATIO%2CTURNOVERRATE%2CFREE_MARKET_CAP%2CEXPLANATION%2CD1_CLOSE_ADJCHRATE%2CD2_CLOSE_ADJCHRATE%2CD5_CLOSE_ADJCHRATE%2CD10_CLOSE_ADJCHRATE%2CSECURITY_TYPE_CODE&amp;source=WEB&amp;client=WEB&amp;filter=%28TRADE_DATE%3C%3D%27<span class="subst">&#123;date&#125;</span>%27%29%28TRADE_DATE%3E%3D%27<span class="subst">&#123;date&#125;</span>%27%29&quot;</span></span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    content = response.content.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    content = content.split(callback + <span class="string">&quot;(&quot;</span>)[<span class="number">1</span>].split(<span class="string">&quot;);&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> json.loads(content).get(<span class="string">&quot;result&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="2-3-创建LLM模型"><a href="#2-3-创建LLM模型" class="headerlink" title="2.3 创建LLM模型"></a>2.3 创建LLM模型</h2><p>不同的模型对于工具调用不同， 目前已知支持最好的模型是<code>GPT-4 Turbo</code>， 但是这个模型是闭源的， 国内支持较好是 DeepSeek但是也收费，对于调试模型更加友好可以利用g模型厂商 - <a href="https://cloud.siliconflow.cn/models">siliconflow AI 云服务平台</a>，从而减少我们的调试成本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">api_key = <span class="string">&quot;xxxxxx&quot;</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    base_url=<span class="string">&quot;https://api.siliconflow.cn&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-235B-A22B&quot;</span>, <span class="comment"># 这里可以更换不同模型 更好的达到实现效果</span></span><br><span class="line">    api_key=api_key</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="2-4-创建Prompt"><a href="#2-4-创建Prompt" class="headerlink" title="2.4 创建Prompt"></a>2.4 创建Prompt</h2><p>Prompt对于LLM大模型的实现有关键作用， 其中<code>agent_scratchpad</code>的占位符对于 AI 大模型实现非常重要，主要用于 ​​记录和传递 Agent 执行过程中的中间推理步骤，同时还会强制按照 tool所需要的参数进行输入调用。</p><p>Prompt 具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是人工智能助手&quot;</span>),</span><br><span class="line">        MessagesPlaceholder(variable_name=<span class="string">&quot;agent_scratchpad&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="2-5-创建Agent和-AgentExecutor"><a href="#2-5-创建Agent和-AgentExecutor" class="headerlink" title="2.5 创建Agent和 AgentExecutor"></a>2.5 创建Agent和 AgentExecutor</h2><p>创建Agent, Langchain也提供不同的类型，如下：</p><ul><li>Tool Calling Agent (create_tool_calling_agent)​ ： 依赖模型原生工具调用能力，自动将工具描述注入模型上下文， 直接返回工具调用参数对象，部分LLM模型支持</li><li>ReAct Agent (create_react_agent)​ ： 遵循 Thought → Action → Observation 循环，每步根据上下文选择工具，结合自然语言与工具调用</li><li>​​Structured Chat Agent (create_structured_chat_agent)​：必须遵循预定义响应模板，严格匹配工具参数格式，通常一次性完成工具选择</li></ul><p>目前我们使用的是 <code>create_tool_calling_agent</code>， 具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_tool_calling_agent, AgentExecutor</span><br><span class="line"></span><br><span class="line">tools = [get_current_day, get_lhb]</span><br><span class="line"></span><br><span class="line">agent = create_tool_calling_agent(llm, tools, prompt)</span><br><span class="line"></span><br><span class="line">agent_executor = AgentExecutor(</span><br><span class="line">    agent=agent, </span><br><span class="line">    tools=tools, </span><br><span class="line">    handle_parsing_errors=<span class="literal">True</span>, </span><br><span class="line">    verbose=<span class="literal">True</span>, <span class="built_in">format</span>=<span class="string">&quot;json&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line"><span class="built_in">print</span>(agent_executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;帮我查询一下今天的龙虎榜数据&quot;</span>&#125;))</span><br></pre></td></tr></table></figure><p>PS:</p><ul><li><code>handle_parsing_errors</code>: 当 Agent执行发生异常的时候，如传入参数不符合工具描述，是否抛出异常，当为 True错误信息会通过 intermediate_steps 传递到下一轮推理，模型基于历史步骤中的错误反馈重新生成正确的工具调用指令</li><li><code>verbose</code>: 是否打印中间步骤，从而更好的理解模型推理过程</li></ul><p>以下是完整代码实现过程截图：</p><p><img src="/assets/img/ailearn/ai-learn09-2.png" alt=""><br><img src="/assets/img/ailearn/ai-learn09-3.png" alt=""></p><h2 id="2-6-Smith调试"><a href="#2-6-Smith调试" class="headerlink" title="2.6  Smith调试"></a>2.6  Smith调试</h2><p>在 Agent中避免不了调试，尤其不同大模型对于工具的调用和判断是不一样的，同时执行过程异常 Langchain也比较难定位，所以因此我们可以使用<code>LangSmith</code>进行调试。</p><p>前往<a href="https://smith.langchain.com/">LangSmith</a>官网，注册账号，创建项目，获取API_KEY，设置环境变量，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置LangSimth 环境变量</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_TRACING&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_ENDPOINT&quot;</span>] = <span class="string">&quot;https://api.smith.langchain.com&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_API_KEY&quot;</span>] = <span class="string">&quot;&lt;LANGSMITH_API_KEY&gt;&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_PROJECT&quot;</span>] = <span class="string">&quot;test_agent&quot;</span></span><br></pre></td></tr></table></figure><p>再次运行Agent，可以前往<a href="https://smith.langchain.com/">LangSmith</a>查看调试结果，如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn09-4.png" alt=""></p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h1><p>AI Agent的实现，对于我们来说，可以更好的理解大模型的能力，同时也可以更好的利用大模型能力，从而更好的实现业务场景。 回顾一下，AI Agent的知识点：</p><ol><li>AI Agent是利用 AI 大模型的推理能力，结合记忆+工具调用能力，实现扩展 AI 大模型能力的一种技术方案</li><li>实现 AI Agent的方案有目前主流是通过大模型  Function Call</li><li>实现 AI Agent中的 Prompt中，<code>agent_scratchpad</code>占位符是非常重要，记录和传递 Agent 执行过程中的中间推理步骤，同时还会强制按照 tool 所需要的参数进行输入调用。</li></ol><p>以上就是 AI Agent的实现过程，希望对你有所帮助。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li><li><a href="https://zhuanlan.zhihu.com/p/694458202">Langchain Agent - Agent类型说明</a></li><li><a href="https://www.cnblogs.com/huaweiyun/p/18289995">万字长文解析AI Agent技术原理和应用</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们已经学习如何通过 Langchain调用独立部署的&lt;code&gt;DeepSeek-R1:32b&lt;/code&gt;模型，且完成一些简单的应用，如： RAG 知识库的实现。&lt;/p&gt;
&lt;p&gt;接下来我们学习如何通过LangChain实现一个Agent智能体，从而让 AI 模型帮忙实现做更多事情。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>12篇 AI从零开始 - 工业级的RAG开发与部署(1)</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn12.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn12.html</id>
    <published>2025-03-31T07:00:00.000Z</published>
    <updated>2025-08-18T12:17:34.620Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>经过LangGraph+LangChain系列文章的学习后， 对LangGraph有了全面，那么接下来就应该学习通过LangGraph开发工业级RAG和部署。</p><blockquote><p>工业级服务需要达到以下几个要求：</p><ul><li>可靠性：强调高可用性和容错性，以确保业务的连续性</li><li>安全性：对安全性要求极高，需要提供强大的安全保障措施，如数据加密、访问控制、安全审计等。</li><li>可扩展性：需要能够根据业务发展灵活扩展，支持不断增长的用户和数据量</li></ul></blockquote><p>接下来我们一起学习如何攻克工业级RAG落地的完整方案与实现。</p><span id="more"></span><h1 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1. 前期准备"></a>1. 前期准备</h1><h2 id="1-1-环境准备"><a href="#1-1-环境准备" class="headerlink" title="1.1 环境准备"></a>1.1 环境准备</h2><h3 id="1-1-1-开发环境"><a href="#1-1-1-开发环境" class="headerlink" title="1.1.1 开发环境"></a>1.1.1 开发环境</h3><ul><li>conda，主要用于管理不同版本的python</li><li>langgraph-cli，初始化项目的脚手架</li><li>nodejs+react,开发智能客服系统前端环境</li></ul><h3 id="1-1-2-依赖资源环境"><a href="#1-1-2-依赖资源环境" class="headerlink" title="1.1.2 依赖资源环境"></a>1.1.2 依赖资源环境</h3><ul><li>向量数据库 chroma,用于保存知识库存储</li><li>Mysql数据库 通用知识库</li><li>docker+docker-compose, 部署服务依赖</li></ul><h2 id="1-2-模型选择"><a href="#1-2-模型选择" class="headerlink" title="1.2 模型选择"></a>1.2 模型选择</h2><p>RAG运行过程为: 知识库生成 -&gt; 检索 -&gt; 响应</p><ul><li>知识库：私有的数据，主要依赖于<code>embedding模型</code>生成存储到向量数据库中</li><li>检索：根据用户问题检索知识库，根据检索算法（如：Query、ReRanker、Rewrite等）得到问题答案</li><li>LLM模型：根据用户问题+检索知识库返回结果形成上下文，分析得到最佳答案返回给用户</li></ul><h3 id="1-2-1-embedding嵌入模型"><a href="#1-2-1-embedding嵌入模型" class="headerlink" title="1.2.1 embedding嵌入模型"></a>1.2.1 embedding嵌入模型</h3><p><code>embedding模型</code>主要作用是把知识库文档转换为向量，存储到向量数据库中, 目前主流<code>embedding模型</code>包含如下：</p><table><thead><tr><th><strong>需求场景</strong></th><th><strong>推荐模型</strong></th><th><strong>关键优势</strong></th></tr></thead><tbody><tr><td>纯中文任务</td><td><code>text2vec-large-chinese</code></td><td>中文语义理解最优</td></tr><tr><td>中英混合检索</td><td><code>bge-m3</code></td><td>多语言支持 + 长上下文</td></tr><tr><td>移动端/低资源部署</td><td><code>bge-small-zh</code></td><td>轻量高速，内存占用低</td></tr><tr><td>长文档处理</td><td><code>nomic-embed-text</code></td><td>支持 8192 tokens</td></tr><tr><td>快速验证/API 集成</td><td><code>text-embedding-3-small</code></td><td>免部署，降维灵活</td></tr><tr><td>企业私有化</td><td><code>m3e-large</code> + 本地向量库</td><td>数据安全 + 定制优化</td></tr></tbody></table><p>这里我们采用 <code>bge-m3</code>模型作为RAG的<code>embedding模型</code>，私有化部署可以参考我之前的文章<a href="https://qborfy.com/ailearn/ai-learn02.html">02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1</a>。</p><h3 id="1-2-2-检索过程相关"><a href="#1-2-2-检索过程相关" class="headerlink" title="1.2.2 检索过程相关"></a>1.2.2 检索过程相关</h3><ol><li><p><code>query查询</code>：在向量数据库中查询与用户提问最相关的数据，通常使用向量数据库提供的<code>向量检索</code>功能，返回与用户提问最相关的文档。</p></li><li><p><code>Reranker重排序</code>：用于优化初步检索结果的排序，确保最相关的文档优先传递给大语言模型（LLM），从而提升生成答案的准确性和效率，常用的算法有：BM25、DPR、BERTRank等。</p></li><li><p><code>Rewrite重写</code>：主要是针对用户提问进行重写，以提升检索结果的准确性和相关性，常用的算法有：BERT、T5、GPT-3等。</p></li></ol><p>通过这三个步骤可以在知识库检索的召回率和回答用户问题的精确率之间保持一个平衡，从而提升知识库返回的检索结果与用户问题回答的相关性。</p><blockquote><p>召回率： 俗称查全率或找回率，定义为实际为正的样本中被预测为正样本的概率。</p><p>举个例子理解，就是有用户提问在知识库检索返回的结果数量为M，如果正确相关为N，那么召回率=N/M。</p><p>召回率越高说明算法模型对检索相似性要求越严格。</p></blockquote><p>本次实战采用<code>bge-m3</code>模型作为RAG的<code>query查询</code>模型，<code>DPR</code>作为<code>Reranker重排序</code>模型，<code>BERT</code>作为<code>Rewrite重写</code>模型。</p><h3 id="1-2-3-response响应模型"><a href="#1-2-3-response响应模型" class="headerlink" title="1.2.3 response响应模型"></a>1.2.3 response响应模型</h3><p>响应模型：根据用户问题+检索知识库返回结果形成上下文，分析得到最佳答案返回给用户，其中需要注意一下几点：</p><ul><li>上下文融合（Context Fusion）​：不仅仅要融合用户问题，还要融合检索结果，这样才能保证生成的答案更加符合用户需求。</li><li>​​幻觉抑制（Hallucination Suppression）：通过提示词指令限制模型仅基于上下文生成答案，避免生成不相关的答案。</li><li>逻辑连贯性（Logical Coherence）​：多文档推理和因果链构建，强制生成分步骤推理框架</li></ul><p><code>response响应模型</code>采用目前主流大模型就好，如：<code>LLaMA</code>、<code>GPT-3</code>、<code>DeepSeek</code>、<code>Qwen3</code>等。</p><p>我们在国内，所以采用<code>DeepSeek</code>作为RAG的<code>response响应模型</code>最佳。</p><h1 id="2-项目初始化"><a href="#2-项目初始化" class="headerlink" title="2. 项目初始化"></a>2. 项目初始化</h1><p>整体项目结构如下：</p><p><img src="/assets/img/ailearn/ai-learn12-1.png" alt="项目结构"></p><h2 id="2-1-初始化LangGraph项目"><a href="#2-1-初始化LangGraph项目" class="headerlink" title="2.1 初始化LangGraph项目"></a>2.1 初始化LangGraph项目</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装langgraph-cli</span></span><br><span class="line">pip install langgraph-cli</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化项目</span></span><br><span class="line">langgraph new rag-langgraph --template new-langgraph-project-python</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行项目</span></span><br><span class="line">cd rag-langgraph &amp;&amp; langgraph dev</span><br></pre></td></tr></table></figure><p>运行项目后可以打开<a href="https://127.0.0.1:2024">http://127.0.0.1:2024</a>查看效果。</p><h2 id="2-2-初始化web项目"><a href="#2-2-初始化web项目" class="headerlink" title="2.2 初始化web项目"></a>2.2 初始化web项目</h2><p>web项目界面我们采用<a href="https://github.com/CopilotKit/CopilotKit">CopilotKit</a>作为RAG的UI界面，具体搭建步骤如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir rag-web &amp;&amp; cd rag-web</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化项目</span></span><br><span class="line">pnpm init -y</span><br></pre></td></tr></table></figure><p>项目初始化已完成，以下是生成的文件和目录结构：</p><ol><li>package.json ：配置了 Monorepo 的工作区 ( workspaces ) 和基本脚本。</li><li>pnpm-workspace.yaml ：定义了工作区范围，指向 packages/* 。</li></ol><h2 id="2-2-1-rag-api"><a href="#2-2-1-rag-api" class="headerlink" title="2.2.1 rag-api"></a>2.2.1 rag-api</h2><p>api依赖<code>nestjs</code>，初始化命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd rag-web &amp;&amp; mkdir -p packages/rag-api &amp;&amp; cd packages/rag-api &amp;&amp; pnpm dlx @nestjs/cli new . --package-manager pnpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 copilotkit 依赖</span></span><br><span class="line">pnpm add @copilotkit/runtime class-validator</span><br></pre></td></tr></table></figure><p><strong>调用 Langgraph</strong><br>新建<code>copilotkit.controller.ts</code>和<code>copilotkit.module.ts</code>文件，内容如下：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// copilotkit.module.ts</span></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">Module</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;@nestjs/common&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">CopilotkitController</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;./copilotkit.controller&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Module</span>(&#123;</span><br><span class="line">  <span class="attr">controllers</span>: [<span class="title class_">CopilotkitController</span>],</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">class</span> <span class="title class_">CopilotkitModule</span> &#123;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// copilotkit.controller.ts</span></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">All</span>, <span class="title class_">Controller</span>, <span class="title class_">Req</span>, <span class="title class_">Res</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;@nestjs/common&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123;</span><br><span class="line">    <span class="title class_">CopilotRuntime</span>,</span><br><span class="line">    copilotRuntimeNestEndpoint,</span><br><span class="line">    <span class="title class_">ExperimentalEmptyAdapter</span>,</span><br><span class="line">    <span class="title class_">LangGraphAgent</span>,</span><br><span class="line">&#125; <span class="keyword">from</span> <span class="string">&#x27;@copilotkit/runtime&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">Request</span>, <span class="title class_">Response</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;express&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span>(<span class="string">&quot;copilotkit&quot;</span>)</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">class</span> <span class="title class_">CopilotkitController</span> &#123;</span><br><span class="line">    <span class="meta">@All</span>(<span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">    <span class="title function_">copilotkit</span>(<span class="params"><span class="meta">@Req</span>() req: Request, <span class="meta">@Res</span>() res: Response</span>) &#123;</span><br><span class="line">        <span class="keyword">const</span> serviceAdapter = <span class="keyword">new</span> <span class="title class_">ExperimentalEmptyAdapter</span>();</span><br><span class="line">        <span class="variable language_">console</span></span><br><span class="line">        <span class="keyword">const</span> runtime = <span class="keyword">new</span> <span class="title class_">CopilotRuntime</span>(&#123;</span><br><span class="line">            <span class="attr">agents</span>: &#123;</span><br><span class="line">                <span class="string">&#x27;graph&#x27;</span>: <span class="keyword">new</span> <span class="title class_">LangGraphAgent</span>(&#123;</span><br><span class="line">                    <span class="attr">deploymentUrl</span>: <span class="string">&#x27;http://127.0.0.1:2024&#x27;</span>, <span class="comment">// 这里引用 Langgraph暴露的服务</span></span><br><span class="line">                    <span class="attr">graphId</span>: <span class="string">&#x27;graph&#x27;</span>,</span><br><span class="line">                    <span class="comment">//langsmithApiKey: &#x27;&lt;your-langsmith-api-key&gt;&#x27; // Optional</span></span><br><span class="line">                &#125;),</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">const</span> handler = <span class="title function_">copilotRuntimeNestEndpoint</span>(&#123;</span><br><span class="line">            runtime,</span><br><span class="line">            serviceAdapter,</span><br><span class="line">            <span class="attr">endpoint</span>: <span class="string">&#x27;/copilotkit&#x27;</span>,</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_">handler</span>(req, res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-2-rag-web"><a href="#2-2-rag-web" class="headerlink" title="2.2 rag-web"></a>2.2 rag-web</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd rag-web &amp;&amp; mkdir -p packages/rag-ui &amp;&amp; cd packages/rag-ui &amp;&amp; pnpm create vite@latest . --template react-ts</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 copilotkit ui依赖</span></span><br><span class="line">pnpm add @copilotkit/react-ui @copilotkit/react-core</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在<code>src/App.tsx</code>中引入<code>copilotkit</code>，内容如下：</p><figure class="highlight tsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; useState &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">CopilotKit</span>, useCopilotAction &#125; <span class="keyword">from</span> <span class="string">&quot;@copilotkit/react-core&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">CopilotChat</span> &#125; <span class="keyword">from</span> <span class="string">&quot;@copilotkit/react-ui&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;@copilotkit/react-ui/styles.css&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">CustomAssistantMessage</span> <span class="keyword">from</span> <span class="string">&#x27;./component/CustomAssistantMessage&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">CustomUserMessage</span> <span class="keyword">from</span> <span class="string">&#x27;./component/CustomUserMessage&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">CustomInput</span> <span class="keyword">from</span> <span class="string">&#x27;./component/CustomInput&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">App</span>(<span class="params"></span>) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">CopilotKit</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">runtimeUrl</span>=<span class="string">&quot;/api/copilotkit&quot;</span> // <span class="attr">对应</span> <span class="attr">api接口地址</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        <span class="attr">agent</span>=<span class="string">&quot;graph&quot;</span> // <span class="attr">Langgraph名称</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">      &gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">CopilotChat</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">instructions</span>=<span class="string">&#123;</span>&quot;<span class="attr">您正在尽力协助用户</span>。<span class="attr">请根据您掌握的数据</span>，<span class="attr">以最佳方式回答问题</span>。&quot;&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">labels</span>=<span class="string">&#123;&#123;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            <span class="attr">title:</span> &quot;<span class="attr">智能问答助手</span>&quot;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            <span class="attr">initial:</span> &quot;<span class="attr">你好</span>! 👋 <span class="attr">我是智能问答小助手</span>，<span class="attr">请问有什么需要帮忙的</span>？&quot;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          &#125;&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">        /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">CopilotKit</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/&gt;</span></span></span><br><span class="line">  )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="title class_">App</span></span><br></pre></td></tr></table></figure><p>运行 <code>pnpm dev</code>，打开<a href="http://127.0.0.1:3000">http://127.0.0.1:3000</a>查看效果。</p><h2 id="2-3-搭建Chroma数据库"><a href="#2-3-搭建Chroma数据库" class="headerlink" title="2.3 搭建Chroma数据库"></a>2.3 搭建Chroma数据库</h2><p>通过<code>docker-compose</code>启动Chroma数据库，文件在<code>docker-compose.yml</code>，内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.8&#x27;</span> <span class="comment"># Specifies the Docker Compose file format version</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">chroma:</span> <span class="comment"># Defines the ChromaDB service</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">chromadb/chroma:latest</span> <span class="comment"># Uses the latest official ChromaDB Docker image</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8000:8000&quot;</span> <span class="comment"># Maps host port 8000 to container port 8000</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">chroma_data:/chroma/chroma</span> <span class="comment"># Persists ChromaDB data to a named volume</span></span><br><span class="line">    <span class="attr">healthcheck:</span> <span class="comment"># Defines a health check for the ChromaDB service</span></span><br><span class="line">      <span class="attr">test:</span> [<span class="string">&quot;CMD&quot;</span>, <span class="string">&quot;curl&quot;</span>, <span class="string">&quot;-f&quot;</span>, <span class="string">&quot;http://localhost:8000/api/v1/heartbeat&quot;</span>]</span><br><span class="line">      <span class="attr">interval:</span> <span class="string">30s</span></span><br><span class="line">      <span class="attr">timeout:</span> <span class="string">10s</span></span><br><span class="line">      <span class="attr">retries:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">chroma_data:</span> <span class="comment"># Defines the named volume for persistent data storage</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>只是先搭建好，后续会将知识库数据导入到Chroma中。</p><h1 id="3-项目部署"><a href="#3-项目部署" class="headerlink" title="3. 项目部署"></a>3. 项目部署</h1><h2 id="3-1-LangGraph部署"><a href="#3-1-LangGraph部署" class="headerlink" title="3.1 LangGraph部署"></a>3.1 LangGraph部署</h2><p>LangGraph-Cli初始化项目后会自动生成 Dockerfile，内容如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> langchain/langgraph-api:<span class="number">3.11</span>-wolfi</span><br><span class="line"></span><br><span class="line"><span class="comment"># -- Adding local package . --</span></span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> . /deps/devops-langgraph</span></span><br><span class="line"><span class="comment"># -- End of local package . --</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -- Installing all local dependencies --</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> PYTHONDONTWRITEBYTECODE=1 uv pip install --system --no-cache-dir -c /api/constraints.txt -e /deps/*</span></span><br><span class="line"><span class="comment"># -- End of local dependencies install --</span></span><br><span class="line"><span class="keyword">ENV</span> LANGSERVE_GRAPHS=<span class="string">&#x27;&#123;&quot;graph&quot;: &quot;/deps/devops-langgraph/src/agent/graph.py:graph&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -- Ensure user deps didn&#x27;t inadvertently overwrite langgraph-api</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /api/langgraph_api /api/langgraph_runtime /api/langgraph_license &amp;&amp; <span class="built_in">touch</span> /api/langgraph_api/__init__.py /api/langgraph_runtime/__init__.py /api/langgraph_license/__init__.py</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> PYTHONDONTWRITEBYTECODE=1 uv pip install --system --no-cache-dir --no-deps -e /api</span></span><br><span class="line"><span class="comment"># -- End of ensuring user deps didn&#x27;t inadvertently overwrite langgraph-api --</span></span><br><span class="line"><span class="comment"># -- Removing build deps from the final image ~&lt;:===~~~ --</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip uninstall -y pip setuptools wheel</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">rm</span> -rf /usr/local/lib/python*/site-packages/pip* /usr/local/lib/python*/site-packages/setuptools* /usr/local/lib/python*/site-packages/wheel* &amp;&amp; find /usr/local/bin -name <span class="string">&quot;pip*&quot;</span> -delete || <span class="literal">true</span></span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">rm</span> -rf /usr/lib/python*/site-packages/pip* /usr/lib/python*/site-packages/setuptools* /usr/lib/python*/site-packages/wheel* &amp;&amp; find /usr/bin -name <span class="string">&quot;pip*&quot;</span> -delete || <span class="literal">true</span></span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> uv pip uninstall --system pip setuptools wheel &amp;&amp; <span class="built_in">rm</span> /usr/bin/uv /usr/bin/uvx</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /deps/devops-langgraph</span></span><br></pre></td></tr></table></figure><p>后续部署只需要将项目打包成镜像，然后通过 docker-compose 运行即可。</p><h2 id="3-2-Web项目部署"><a href="#3-2-Web项目部署" class="headerlink" title="3.2 Web项目部署"></a>3.2 Web项目部署</h2><p>web项目包含两个项目，rag-api和rag-ui，可以通过<code>pnpm build</code>+ dockerfile打包成镜像，然后通过 docker-compose 运行即可。Dockerfile目录如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编译 Monorepo项目</span></span><br><span class="line">cd rag-web &amp;&amp; pnpm build</span><br></pre></td></tr></table></figure><p><strong>rag-api dockerfile</strong></p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rag-api dockerfile</span></span><br><span class="line"><span class="keyword">FROM</span> node:v20.<span class="number">19.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装时区文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apk add --no-cache tzdata</span></span><br><span class="line"><span class="comment">#设置时区</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">ln</span> -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> packages/rag-api/dist ./dist</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> packages/rag-api/package.json ./</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> packages/rag-api/nest-cli.json ./</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [ <span class="string">&quot;sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;npm run start&quot;</span> ]</span></span><br></pre></td></tr></table></figure><p><strong>rag-ui dockerfile</strong><br>前端项目利用<code>nginx</code>作为静态资源服务器，所以需要将前端项目打包成静态资源，然后通过<code>nginx</code>作为静态资源服务器。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rag-ui dockerfile</span></span><br><span class="line"><span class="keyword">FROM</span> nginx:<span class="number">1.23</span>.<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> packages/rag-ui/dist/ /usr/share/nginx/html/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> packages/rag-ui/nginx/default.conf /etc/nginx/conf.d/default.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义启动脚本</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> packages/rag-ui/docker-entrypoint.sh /</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">chmod</span> +x /docker-entrypoint.sh</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> /docker-entrypoint.sh</span></span><br></pre></td></tr></table></figure><p><strong>docker-compose.yaml运行</strong></p><p>通过<code>docker-compose</code>运行项目，内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.8&#x27;</span> <span class="comment"># Specifies the Docker Compose file format version</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">rag-langgraph:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">rag-langgraph</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;2024:2024&quot;</span></span><br><span class="line">  <span class="attr">rag-api:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">rag-api</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;4123:4123&quot;</span></span><br><span class="line">  <span class="attr">rag-ui:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">rag-ui</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;3000:3000&quot;</span></span><br></pre></td></tr></table></figure><p>其中rag-api和rag-ui的端口映射，可以根据实际情况修改，在 rag-ui项目中 修改 nginx 配置文件，将 4123 端口服务映射到对应 location <code>/api</code>中，具体如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">listen 80;</span><br><span class="line">server_name rag.example.com; </span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://localhost:3000/;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /api/ &#123;</span><br><span class="line">        proxy_pass http://127.0.0.1:4123/;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>经过本文学习，主要目标是搭建可以正式使用的 RAG 项目服务，本问主要介绍了：</p><ul><li>如何使用LangGraph-Cli搭建LangGraph</li><li>如何使用CopilotKit搭建智能问答助手前端</li><li>如何将项目打包成镜像，然后通过 docker-compose 运行项目</li><li>如何通过 nginx 配置文件，将 rag-api 服务映射到 rag-ui 项目中</li></ul><p>下一章我们讲学习如何开发 Langgraph加载各类知识库，以及如何将知识库数据导入到Chroma中。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://docs.langchain.com/langgraph-platform/cli">LangGraph-Cli官方文档</a></li><li><a href="https://docs.copilotkit.ai/coagents/quickstart">CopilotKit官方文档</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;经过LangGraph+LangChain系列文章的学习后， 对LangGraph有了全面，那么接下来就应该学习通过LangGraph开发工业级RAG和部署。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;工业级服务需要达到以下几个要求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可靠性：强调高可用性和容错性，以确保业务的连续性&lt;/li&gt;
&lt;li&gt;安全性：对安全性要求极高，需要提供强大的安全保障措施，如数据加密、访问控制、安全审计等。&lt;/li&gt;
&lt;li&gt;可扩展性：需要能够根据业务发展灵活扩展，支持不断增长的用户和数据量&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;接下来我们一起学习如何攻克工业级RAG落地的完整方案与实现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>11篇 AI从零开始 - Langgraph(4)</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn13.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn13.html</id>
    <published>2025-03-31T07:00:00.000Z</published>
    <updated>2025-08-08T11:30:59.948Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>经过LangGraph系列文章的学习后， 现在我们需要通过 LangChain + 大模型 + 低代码平台， 开发具备实际功能的 AI 应用：</p><blockquote><p><strong>低代码平台AI助手</strong>：通过用户输入自然语言能实现 低代码平台页面生成、编辑等</p></blockquote><span id="more"></span><h1 id="1-前期与实现方案"><a href="#1-前期与实现方案" class="headerlink" title="1. 前期与实现方案"></a>1. 前期与实现方案</h1><p>目标：通过用户输入自然语言能实现，完成低代码平台页面的生成，同时能低代码平台页面组件元素进行属性调整。</p><p>实际原理： 利用 AI大模型实现用户输入的自然语言与低代码平台特定 DSL语言（JSON Schema）互相转换</p><h2 id="1-1-前期准备"><a href="#1-1-前期准备" class="headerlink" title="1.1 前期准备"></a>1.1 前期准备</h2><ol><li>搭建低代码平台服务，可以参考文档： <a href="https://formilyjs.org/zh-CN/guide/form-builder">Formily 表单设计器</a></li><li>Langchain 和 LangServer环境准备， 参考： <a href="https://qborfy.com/ailearn/ai-learn04.html">04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</a></li></ol><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ol><li>LangChain开发实现大模型理解低代码平台DSL语言的输入，并能输出是低代码平台DSL语言</li><li>通过 LangServer提供大模型 API<ol><li>输入当前页面 json schema</li><li>用户输入自然语言，LangServer调用大模型API，返回结果</li><li>LangServer将返回结果转换成低代码平台DSL语言</li></ol></li><li>低代码平台新增 AI助手 UI，更改低代码页面JSON内容 </li></ol><h1 id="2-实战开发"><a href="#2-实战开发" class="headerlink" title="2. 实战开发"></a>2. 实战开发</h1><h2 id="2-1-LangChain-Agent-Server开发"><a href="#2-1-LangChain-Agent-Server开发" class="headerlink" title="2.1 LangChain Agent + Server开发"></a>2.1 LangChain Agent + Server开发</h2><h2 id="2-2-Formily-插件-AI-助手前端开发"><a href="#2-2-Formily-插件-AI-助手前端开发" class="headerlink" title="2.2 Formily 插件 AI 助手前端开发"></a>2.2 Formily 插件 AI 助手前端开发</h2><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li><li><a href="https://zhuanlan.zhihu.com/p/694458202">Langchain Agent - Agent类型说明</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><p>对 Agent的一些思考， 首先 agent本身的  Prompt很重要， LLM 大模型会依据Prompt+用户输入去判断需要使用哪个工具</p><p>然后创建Agent, Langchain也提供不同的类型，如下：</p><ul><li>Tool Calling Agent (create_tool_calling_agent)​ ： 依赖模型原生工具调用能力，自动将工具描述注入模型上下文， 直接返回工具调用参数对象，部分LLM模型支持</li><li>ReAct Agent (create_react_agent)​ ： 遵循 Thought → Action → Observation 循环，每步根据上下文选择工具，结合自然语言与工具调用</li><li>​​Structured Chat Agent (create_structured_chat_agent)​：必须遵循预定义响应模板，严格匹配工具参数格式，通常一次性完成工具选择</li></ul><p>利用 Agent 开发一个完整的低代码平台 AI 助手，整体实现过程如下：</p><p><a href="https://langchain-ai.github.io/langgraph/agents/agents/#1-install-dependencies">https://langchain-ai.github.io/langgraph/agents/agents/#1-install-dependencies</a></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;经过LangGraph系列文章的学习后， 现在我们需要通过 LangChain + 大模型 + 低代码平台， 开发具备实际功能的 AI 应用：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;低代码平台AI助手&lt;/strong&gt;：通过用户输入自然语言能实现 低代码平台页面生成、编辑等&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>08篇 AI从零开始 - LangChain学习与实战(5) 基于RAG开发问答机器人</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn08.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn08.html</id>
    <published>2025-03-15T07:00:00.000Z</published>
    <updated>2025-06-07T01:58:54.348Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面几篇学习LangChain，基本上完成对 LangChain从开发到上线有一个整体的了解，那么接下来我们就要开始实战了，我们将会使用LangChain开发一个问答机器人，这个问答机器人将会使用到RAG模型，那么接下来我们开始学习RAG。</p><span id="more"></span><h1 id="RAG是什么"><a href="#RAG是什么" class="headerlink" title="RAG是什么"></a>RAG是什么</h1><blockquote><p>RAG是一种用额外数据增强大模型知识的技术，俗称“RAG”（Retrieval-Augmented Generation），中文叫检索增强生成。</p></blockquote><p>RAG是LangChain中一个重要的应用场景，它能够将检索和生成结合起来，从而生成更加精准的答案。</p><p>RAG模型由两个部分组成：Retriever和Generator。</p><ul><li><code>Generator</code> 生成索引向量，根据文档中问题和答案生成索引向量数据库。</li><li><code>Retriever</code> 检索对比类似，根据用户的问题，从生成的知识库中检索召回最相关的问题和答案。</li></ul><p>RAG技术是通过检索和生成相结合的方式找最相关的知识内容， 加入到大模型的提示语中，通过大模型推理得到用户问题在知识库中最合适的答案。</p><p>下面是我个人依据网上相关资料整理的通用RAG模型架构图：</p><p><img src="/assets/img/ailearn/ai-learn08-1.png" alt=""></p><h2 id="生成向量索引（Indexing）"><a href="#生成向量索引（Indexing）" class="headerlink" title="生成向量索引（Indexing）"></a>生成向量索引（Indexing）</h2><p>生成向量索引有三个步骤，分别如下：</p><ol><li>加载(load)，加载所需数据，LangChain中提供各种加载器，如：PDFLoader、TextLoader、ImageLoader等。</li><li>分割(Split)，将加载的数据进行分割成一个个块，LangChain中提供各种分割器，如：TextSplitter、ImageSplitter等。</li><li>存储(Store)，得到分割的Chunks，需要将Chunk转成向量索引并存储，这里我们会依赖<code>Embeddings</code>模型进行生成索引，然后存储到向量数据库<code>VectorStore</code>。</li></ol><h2 id="Embeddings嵌入模型"><a href="#Embeddings嵌入模型" class="headerlink" title="Embeddings嵌入模型"></a>Embeddings嵌入模型</h2><p>RAG模型使用<code>Embeddings</code>模型将问题和答案进行编码，生成向量数据，这里我们必不可免需要对<code>Embeddings</code>模型进行初步了解。</p><blockquote><p>Embeddings模型，也叫嵌入模型，是一种将高维度的数据，如：自然语言、图片、视频等，转换成低维度的向量数据，如：多维矩阵数组等，方便后续进行相似度对比。</p></blockquote><p>或者我们可以更加直观的理解，<code>Embeddings</code>模型可以把我们人类能够理解的内容，转换成计算机能够计算理解的数据，从而实现更多的算法对比逻辑。</p><h2 id="检索和生成"><a href="#检索和生成" class="headerlink" title="检索和生成"></a>检索和生成</h2><ol><li>检索：通过用户输入的内容，使用检索器将内容转换为向量，然后从向量数据库中检索最相关的向量数据。</li><li>生成：通过检索器检索到的向量数据，使用生成器生成新的向量数据，然后存储到向量数据库中。</li></ol><p>这两个步骤一般都是同时进行，一般也是 通过Embeddings嵌入模型去转换搜索内容为向量，然后通过检索到最后生成内容。</p><h1 id="实战：做一个问答机器人"><a href="#实战：做一个问答机器人" class="headerlink" title="实战：做一个问答机器人"></a>实战：做一个问答机器人</h1><h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><ol><li>用户上传问题知识内容上传文件</li><li>服务端对上传文件进行解析，拆分chunk</li><li>将 chunk 传给 Embeddings模型，生成向量索引</li><li>将 向量索引存储到向量数据库中</li><li>用户输入问题，通过检索器检索到最相关的向量数据</li><li>然后将最相关向量数据传给对话大模型，组织推理得到答案，返回给用户</li></ol><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>Ollama安装模型：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对话大模型</span></span><br><span class="line">ollama install deepseek-r1:7b</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">embeddings模型</span></span><br><span class="line">ollama install shaw/dmeta-embedding-zh:latest</span><br></pre></td></tr></table></figure><p>LangChain和  Streamlit安装</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python环境 3.12.4</span></span><br><span class="line"><span class="comment"># streamlit 1.39.0</span></span><br><span class="line"><span class="comment"># toml</span></span><br><span class="line"></span><br><span class="line">pip install langchain</span><br><span class="line">pip install streamlit</span><br></pre></td></tr></table></figure><p><code>requirements.txt</code>文件内容如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">streamlit==1.39.0</span><br><span class="line">langchain==0.3.21</span><br><span class="line">langchain-chroma==0.2.2</span><br><span class="line">langchain-community==0.3.20</span><br><span class="line">langchain-ollama==0.2.3</span><br></pre></td></tr></table></figure><blockquote><p>streamlit是构建和共享数据应用程序的更快方法， 几分钟内将您的数据脚本转换为可共享的网络应用程序，全部采用纯 Python 编写，无需前端经验。<br>官方文档：<a href="https://docs.streamlit.io/get-started/installation">https://docs.streamlit.io/get-started/installation</a></p></blockquote><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>新建一个文件<code>bot_chat.py</code>， 分步骤实现。</p><h3 id="1-stremlit页面搭建"><a href="#1-stremlit页面搭建" class="headerlink" title="1. stremlit页面搭建"></a>1. stremlit页面搭建</h3><p>代码参考如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 st 的标题和布局</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;RAG测试问答&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置应用标题</span></span><br><span class="line">st.title(<span class="string">&quot;RAG测试问答&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持上传 txt 文件</span></span><br><span class="line">upload_file = st.sidebar.file_uploader(label=<span class="string">&quot;上传文件&quot;</span>, <span class="built_in">type</span>=[<span class="string">&quot;txt&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> upload_file:</span><br><span class="line">    st.info(<span class="string">&quot;请上传 txt 文件&quot;</span>)</span><br><span class="line">    st.stop()</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><p><img src="/assets/img/ailearn/ai-learn08-2.png" alt=""></p><h3 id="2-解析文档并生成知识库检索器"><a href="#2-解析文档并生成知识库检索器" class="headerlink" title="2. 解析文档并生成知识库检索器"></a>2. 解析文档并生成知识库检索器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> tempfile</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory <span class="comment"># 会话记录到内存</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> StreamlitChatMessageHistory <span class="comment">#  Streamlit聊天记录存储</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader <span class="comment"># 文本加载器</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.embeddings <span class="keyword">import</span> OllamaEmbeddings <span class="comment"># Ollama Eembeddings 语言模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma <span class="comment"># Chroma 向量数据库</span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter <span class="comment"># 文本分割器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 st 的标题和布局</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;RAG测试问答&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置应用标题</span></span><br><span class="line">st.title(<span class="string">&quot;RAG测试问答&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持上传 txt 文件</span></span><br><span class="line">upload_file = st.sidebar.file_uploader(label=<span class="string">&quot;上传文件&quot;</span>, <span class="built_in">type</span>=[<span class="string">&quot;txt&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> upload_file:</span><br><span class="line">    st.info(<span class="string">&quot;请上传 txt 文件&quot;</span>)</span><br><span class="line">    st.stop()</span><br><span class="line"></span><br><span class="line"><span class="comment"># step1 实现知识库生成</span></span><br><span class="line"><span class="meta">@st.cache_resource(<span class="params">ttl=<span class="string">&quot;1h&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_knowledge_base</span>(<span class="params">uploaded_file</span>):</span><br><span class="line">    <span class="comment"># 读取上传的文档</span></span><br><span class="line">    docs = []</span><br><span class="line">    <span class="comment"># 将 uploaded_file 存到 /tmp</span></span><br><span class="line">    temp_dir = tempfile.TemporaryDirectory(<span class="built_in">dir</span>=<span class="string">r&quot;/tmp&quot;</span>)</span><br><span class="line">    tempfilepath = os.path.join(temp_dir.name, uploaded_file.name)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(tempfilepath, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(uploaded_file.getvalue())</span><br><span class="line">    <span class="comment"># 使用 TextLoader 加载文档</span></span><br><span class="line">    docs = TextLoader(tempfilepath, encoding=<span class="string">&quot;utf-8&quot;</span>).load()</span><br><span class="line">    <span class="comment"># 使用 RecursiveCharacterTextSplitter 分割文档</span></span><br><span class="line">    splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">200</span>)</span><br><span class="line">    splits = splitter.split_documents(docs)</span><br><span class="line">    <span class="comment"># 使用 OllamaEmbeddings 生成文档向量</span></span><br><span class="line">    embeddings = OllamaEmbeddings(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;shaw/dmeta-embedding-zh&quot;</span>)</span><br><span class="line">    <span class="comment"># 使用 Chroma 向量数据库存储文档向量</span></span><br><span class="line">    chroma_db = Chroma.from_documents(splits, embeddings)</span><br><span class="line">    <span class="comment"># 创建文档检索器 约等于 知识库</span></span><br><span class="line">    retriever = chroma_db.as_retriever()</span><br><span class="line">    <span class="keyword">return</span> retriever</span><br><span class="line">    </span><br><span class="line">retriever = get_knowledge_base(upload_file) </span><br></pre></td></tr></table></figure><p>上文件后， 执行效果如下：</p><p><img src="/assets/img/ailearn/ai-learn08-4.png" alt=""></p><p><img src="/assets/img/ailearn/ai-learn08-3.png" alt=""></p><h3 id="3-初始化聊天消息界面"><a href="#3-初始化聊天消息界面" class="headerlink" title="3. 初始化聊天消息界面"></a>3. 初始化聊天消息界面</h3><p>聊天功能主要几点：</p><ul><li>记录聊天内容</li><li>显示聊天内容</li><li>用户输入框</li></ul><p>具体实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step2 初始化聊天消息界面</span></span><br><span class="line"><span class="comment"># 如果用户输入&quot;清空聊天记录&quot;，则重新初始化界面</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state <span class="keyword">or</span> st.sidebar.button(<span class="string">&quot;清空聊天记录&quot;</span>):</span><br><span class="line">    st.session_state[<span class="string">&quot;messages&quot;</span>] = [&#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;你好&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;我是测试 RAG 问答小助手&quot;</span></span><br><span class="line">    &#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示历史聊天记录</span></span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> st.session_state[<span class="string">&quot;messages&quot;</span>]:</span><br><span class="line">    st.chat_message(msg[<span class="string">&quot;role&quot;</span>], msg[<span class="string">&quot;content&quot;</span>])  <span class="comment"># </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建历史聊天记录</span></span><br><span class="line">msgs = StreamlitChatMessageHistory()</span><br><span class="line"><span class="comment"># 创建对话缓存</span></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    chat_memory=msgs,</span><br><span class="line">    return_messages=<span class="literal">True</span>,</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    output_key=<span class="string">&quot;out&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建 UI 输入框</span></span><br><span class="line">user_query = st.chat_input(placeholder=<span class="string">&quot;请输入要测试的问题&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="4-创建LLM-检索-agent执行"><a href="#4-创建LLM-检索-agent执行" class="headerlink" title="4. 创建LLM 检索 agent执行"></a>4. 创建LLM 检索 agent执行</h3><p>这里实现一个Agent， 过程是 去调用一个检索工具，支持模板和用户输入，调用大模型进行检索，然后返回结果。</p><p>具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step3 创建检索 agent </span></span><br><span class="line"><span class="keyword">from</span> langchain.tools.retriever <span class="keyword">import</span> create_retriever_tool</span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-1 用于创建文档检索的工具</span></span><br><span class="line">tool = create_retriever_tool(</span><br><span class="line">    retriever=retriever,</span><br><span class="line">    name=<span class="string">&quot;文档检索&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;根据输入的关键词，检索相关文档&quot;</span>,</span><br><span class="line">)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-2 创建 LLM对话模型</span></span><br><span class="line"><span class="comment"># 创建指令 Prompt</span></span><br><span class="line">instruction = <span class="string">&quot;&quot;&quot;你是一个设计用于查询文档回答问题的代理</span></span><br><span class="line"><span class="string">您可以使用文档检索工具，并基于检索内容来回答问题。</span></span><br><span class="line"><span class="string">可能你不查询文档就知道答案，但是仍然要去查询文档来获得答案。</span></span><br><span class="line"><span class="string">如果从文档找不到任何信息和答案来回答问题，则需要返回“非常抱歉，这个问题暂时没有录入到知识库中。”作为答案。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">base_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#123;instruction&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">TOOLS:</span></span><br><span class="line"><span class="string">----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你可以使用以下工具：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;tools&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">使用工具中，你可以参考这样子：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string">思考：我是否需要使用工具？ 是的</span></span><br><span class="line"><span class="string">动作：我需要使用工具：[&#123;tool_names&#125;]</span></span><br><span class="line"><span class="string">动作：输入:&#123;input&#125;</span></span><br><span class="line"><span class="string">动作执行后： 返回动作执行后的结果</span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当你需要返回一个答案，且这个答案不需要使用工具时，你可以参考这样子：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string">思考：我是否需要使用工具？ 不是</span></span><br><span class="line"><span class="string">答案： [你的答案]</span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">开始！</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">上一次历史对话内容如下：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">新的问题是：&#123;input&#125;</span></span><br><span class="line"><span class="string">&#123;agent_scratchpad&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># agent_scratchpad 是 agent 的 scratchpad，用于存储 agent 的状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基础模板</span></span><br><span class="line">base_prompt = PromptTemplate.from_template(base_template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充基础模板</span></span><br><span class="line">prompt = base_prompt.partial(instruction=instruction)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 LLM 模型</span></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:7b&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-3 创建 agent</span></span><br><span class="line">agent = create_react_agent(llm=llm, prompt=prompt, tools=tools)</span><br><span class="line"></span><br><span class="line">agent_excutor = AgentExecutor(</span><br><span class="line">    agent=agent,</span><br><span class="line">    tools=tools,</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    handle_parsing_errors=<span class="string">&quot;从知识库没找到对应内容或者答案&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="5-用户输入与-Agent返回"><a href="#5-用户输入与-Agent返回" class="headerlink" title="5. 用户输入与 Agent返回"></a>5. 用户输入与 Agent返回</h3><p>这一步基本上就是解决用户输入显示与 Agent返回结果，同时通过 streamlit的 callbank函数去 展示 Agent的执行过程，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step5 用户输入查询与返回</span></span><br><span class="line"><span class="keyword">if</span>  user_query:</span><br><span class="line">    <span class="comment"># 添加到 session 历史记录</span></span><br><span class="line">    st.session_state[<span class="string">&quot;messages&quot;</span>].append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_query&#125;)</span><br><span class="line">    <span class="comment"># 显示用户信息</span></span><br><span class="line">    st.chat_message(<span class="string">&quot;user&quot;</span>).write(user_query)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">        <span class="comment"># 创建回调</span></span><br><span class="line">        callback = StreamlitCallbackHandler(st.container())</span><br><span class="line">        <span class="comment"># 将 agent执行过程 显示在 streamlit中，如：思考、选择工具、执行查询等等</span></span><br><span class="line">        config = &#123;<span class="string">&quot;callbacks&quot;</span>: [callback]&#125;</span><br><span class="line">        <span class="comment"># agent 执行</span></span><br><span class="line">        response = agent_excutor.invoke(&#123;<span class="string">&quot;input&quot;</span>: user_query&#125;, config=config)</span><br><span class="line">        <span class="comment"># 保存agent 执行结果到聊天记录 </span></span><br><span class="line">        st.session_state[<span class="string">&quot;messages&quot;</span>].append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response[<span class="string">&quot;output&quot;</span>]&#125;)</span><br><span class="line">        <span class="comment"># 显示在 streamlit中</span></span><br><span class="line">        st.write(response[<span class="string">&quot;output&quot;</span>])</span><br></pre></td></tr></table></figure><h3 id="最终运行"><a href="#最终运行" class="headerlink" title="最终运行"></a>最终运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamlit run bot_chat.py</span><br></pre></td></tr></table></figure><p>执行效果如下：<br>对话中：<br><img src="/assets/img/ailearn/ai-learn08-5.png" alt=""></p><p>返回答案：<br><img src="/assets/img/ailearn/ai-learn08-6.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文我们主要学习了LangChain的去实现一个RAG智能问答客服，通过Streamlit框架快速搭建一个UI界面，上传知识库文件，利用RAG技术加强大模型的企业内部特有的知识。回顾一下，我们主要学习了以下内容：</p><ul><li>RAG技术原理，加载(load)、训练(train)、推理(inference)三个步骤</li><li>Embeddings嵌入模型的具体作用，将文本、图片转换为向量</li><li>利用LangChain+Streamlit+Chroma(向量数据库)快速搭建一个企业内部的智能客服问答系统</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面几篇学习LangChain，基本上完成对 LangChain从开发到上线有一个整体的了解，那么接下来我们就要开始实战了，我们将会使用LangChain开发一个问答机器人，这个问答机器人将会使用到RAG模型，那么接下来我们开始学习RAG。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>07篇 AI从零开始 - LangChain学习与实战(4) LangServer部署</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn07.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn07.html</id>
    <published>2025-03-12T07:00:00.000Z</published>
    <updated>2025-04-07T12:04:38.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>从 LangChain系列文章开始到现在，我们学习 LangChain的基础知识和实战撸代码，现在我们假设已经开发好一个 LangChain链式任务，那么如何部署以及如何与 web服务进行互相调用呢？</p><p>那么接下来我们应该就学习LangServer与LangSmith，如何让 LangChain进行企业级开发。</p><blockquote><p>LangServer: 帮开发者将  LangChain 部署一个 Restful 服务。</p><p>LangSmith: 监控 LangChain调用链路服务和提供更加友好的可视化界面。</p></blockquote><span id="more"></span><h1 id="认识-LangServer"><a href="#认识-LangServer" class="headerlink" title="认识 LangServer"></a>认识 LangServer</h1><p>LangServer是集成了FastApi + Pydantic的Restful框架。它提供了一些特性：</p><ul><li>每次 API调用都会返回丰富的错误信息</li><li>自带 JSON Schema和   Swagger API文档</li><li>高效的<code>/invoke</code>、 <code>batch</code>和 <code>/stream</code>接口服务，支持单个服务器多个并发请求</li><li>支持调用<code>/stream_log</code>接口，实现链式任务中间态步骤返回</li><li><code>/stream_events</code>更加清晰任务事件状态信息</li><li>提供LangServer SDK，调用 Restful 和 直接调用大模型一样简单</li></ul><h1 id="实战教程"><a href="#实战教程" class="headerlink" title="实战教程"></a>实战教程</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>安装<code>langchain-cli</code>全局命令，方便快速启动 Lang Server项目</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U langchain-cli </span><br></pre></td></tr></table></figure><p>安装<code>poetry</code>管理项目的依赖，更好管理服务依赖 pip包。</p><blockquote><p><code>poetry</code> Python packaging and dependency management made easy， 翻译过来就是更加轻松管理 python项目和依赖</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 pipx</span></span><br><span class="line">pip install pipx</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pipx添加到环境变量</span></span><br><span class="line">pipx ensurepath</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 poetry</span></span><br><span class="line">pipx install poetry</span><br></pre></td></tr></table></figure><h2 id="初始化和运行项目"><a href="#初始化和运行项目" class="headerlink" title="初始化和运行项目"></a>初始化和运行项目</h2><ol><li>项目初始化<br>利用langchain-cli 脚手架， 初始化一个 langserver项目</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化一个langserver的项目</span></span><br><span class="line">langchain app new mylangserver</span><br><span class="line"></span><br><span class="line">pipx run langchain app new mylangserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入项目目录</span></span><br><span class="line">cd mylangserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装项目依赖</span></span><br><span class="line">poetry install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装后续依赖的包</span></span><br><span class="line">poetry add langchain</span><br><span class="line">poetry add langchain_ollama</span><br></pre></td></tr></table></figure><ol start="2"><li>项目结构说明<br>生成的目录结构与说明如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mylangserver # 项目名</span><br><span class="line">├─.gitignore</span><br><span class="line">├─Dockerfile </span><br><span class="line">├─README.md</span><br><span class="line">├─pyproject.toml # 项目结构说明文件</span><br><span class="line">├─poetry.lock # poetry依赖锁文件 类似前端的yarn.lock</span><br><span class="line">├─packages</span><br><span class="line">|    └README.md</span><br><span class="line">├─app</span><br><span class="line">|  ├─__init__.py</span><br><span class="line">|  ├─server.py  # 服务主入口 后续开发都在这里</span><br></pre></td></tr></table></figure><ol start="3"><li>运行项目</li></ol><p>在根目录下运行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">langchain server</span><br></pre></td></tr></table></figure><p>就可以直接访问 <code>http://localhost:8080</code>，效果具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-1.png" alt=""></p><h2 id="接口开发"><a href="#接口开发" class="headerlink" title="接口开发"></a>接口开发</h2><ol><li><code>server.py</code>文件<br>在接口开发之前我们先看看 <code>server.py</code>文件，具体如下：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> RedirectResponse</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里是定义路由和对应路由实现的方法</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">redirect_root_to_docs</span>():</span><br><span class="line">    <span class="keyword">return</span> RedirectResponse(<span class="string">&quot;/docs&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们可以添加路由</span></span><br><span class="line"><span class="comment"># add_routes(app, NotImplemented)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    <span class="comment"># 这里通过 uvicorn启动服务，端口为8000</span></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure><ol start="2"><li>添加一个调用<code>DeepSeek-R1</code>模型的接口</li></ol><p>通过 <code>add_routes</code>新增一个模型对象，会自动封装成对应的 Restful接口，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> RedirectResponse</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"></span><br><span class="line">deepseek = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"></span><br><span class="line">app = FastAPI(</span><br><span class="line">    title=<span class="string">&quot;Qborfy个人 LangServer&quot;</span>,</span><br><span class="line">    version=<span class="string">&quot;0.1.0&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Qborfy个人 LangServer，学习测试使用&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">redirect_root_to_docs</span>():</span><br><span class="line">    <span class="keyword">return</span> RedirectResponse(<span class="string">&quot;/docs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 deepseek路由</span></span><br><span class="line">add_routes(app, deepseek, path=<span class="string">&quot;/deepseek&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>接下来我们访问 <code>http://localhost:8000/</code>，就会出现和<code>/deepseek</code>相关的文档，具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-2.png" alt=""></p><h2 id="接口测试"><a href="#接口测试" class="headerlink" title="接口测试"></a>接口测试</h2><p>接口测试我们可以通过<a href="https://apifox.com/">ApiFox</a> (一个和 Postman类似  API 测试工具)进行测试，具体如下.</p><ol><li><code>/invoke</code> 发起一个对话请求, 具体如下图：</li></ol><p><img src="/assets/img/ailearn/ai-learn07-3.png" alt=""></p><ol start="2"><li><code>/stream</code> 流式调用，具体如下图：</li></ol><p><img src="/assets/img/ailearn/ai-learn07-4.png" alt=""></p><h2 id="SDK调用"><a href="#SDK调用" class="headerlink" title="SDK调用"></a>SDK调用</h2><p>在LangChain中是可以通过 LangServe提供的 <code>RemoteRunable</code> 进行远程调用，和原来的调用大模型的使用方式其实是一样的， 具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用远端调用 LangServer</span></span><br><span class="line"><span class="keyword">from</span> langchain.schema.runnable <span class="keyword">import</span> RunnableMap</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> RemoteRunnable</span><br><span class="line"></span><br><span class="line">llm = RemoteRunnable(<span class="string">&quot;http://127.0.0.1:8000/deepseek&quot;</span>)</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;你是世界级的 AI 技术专家, &#123;input&#125;&quot;</span></span><br><span class="line"><span class="comment"># 这里我们使用一个简单的模板</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    template=template</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建一个简单的链式调用</span></span><br><span class="line">chain = prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行链式调用</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> llm.stream(<span class="string">&quot;海洋是什么颜色&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(chunk, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样子我们不仅可以在本地调用大模型，还能调用其他人提供 LangChain服务，从而实现更加复杂的功能。</p><h2 id="生产部署"><a href="#生产部署" class="headerlink" title="生产部署"></a>生产部署</h2><p>LangServer生产部署，按照 LangChain官方推荐是通过<code>Dockerfile</code>打包进行部署，其中也比较简单，具体执行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打包镜像</span></span><br><span class="line">docker build . -t my-langserve-app</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行镜像</span></span><br><span class="line">docker run -p 8080:8080 my-langserve-app</span><br></pre></td></tr></table></figure><p>或者是通过 docker-compose启动 docker服务，具体如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">langserver:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">my-langserve-app</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8080</span><span class="string">:8080</span></span><br></pre></td></tr></table></figure><p>最终执行<code>docker-compose up -d</code>启动服务后，就可以通过<code>http://localhost:8080/docs</code>访问到服务了。</p><h1 id="监控与日志"><a href="#监控与日志" class="headerlink" title="监控与日志"></a>监控与日志</h1><h2 id="LangSmith监控"><a href="#LangSmith监控" class="headerlink" title="LangSmith监控"></a>LangSmith监控</h2><p>LangSmith是 LangChain官方提供的监控工具，可以监控模型运行情况，一个 SASS服务需要我们将服务相关信息注册到 LangSmith网站上，因此可以按个人或公司需要判断是否允许使用。</p><blockquote><p>LangSmith是一个用于构建生产级应用的平台。它允许您密切监控和评估您的应用，以便您可以快速而自信地发布应用。</p><p>传统软件应用程序是通过编写代码来构建的，而 AI 应用程序则需要编写提示来指导应用程序执行哪些操作。</p><p>LangSmith 提供了一套旨在实现和促进提示工程的工具，以帮助您找到适合您的应用程序的完美提示。</p></blockquote><p><strong>PS：LangSmith这里提示未来编程开发者的思维转变，我们实现功能的思路不再是针对一些实现逻辑，而是面向不同的 AI 模型，优化提示语实现我们想要的功能。</strong></p><p>在 LangServer 中使用 LangSmith，需要先注册一个账号，然后获取 api key 添加到 LangServer中，具体使用代码如下： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置LangSimth 环境变量</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_TRACING&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_ENDPOINT&quot;</span>] = <span class="string">&quot;https://api.smith.langchain.com&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_API_KEY&quot;</span>] = <span class="string">&quot;&lt;LANG_SIMTH_KEY&gt;&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_PROJECT&quot;</span>] = <span class="string">&quot;mylangserver&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>具体使用教程可以参考<a href="https://docs.smith.langchain.com/">LangSmith官方文档</a></p><p>LangSmith主要作用是监控 链路任务节点调用和扭转情况，可以更加清晰的分析链的运行情况和日志，具体效果如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn07-5.png" alt=""></p><h2 id="Verbose关键日志"><a href="#Verbose关键日志" class="headerlink" title="Verbose关键日志"></a>Verbose关键日志</h2><p>如果我们不想把自己的服务相关的日志信息暴露给 LangSmith， 我们还可以通过设置<code>set_verbose</code>设置详细日志开关， 从而实现我们调用 LangChain链路的完整日志，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.<span class="built_in">globals</span> <span class="keyword">import</span> set_verbose</span><br><span class="line"><span class="comment"># 全局 verbose配置开关</span></span><br><span class="line">set_verbose(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 针对部分链接调用设置详细日志开关</span></span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>打开开关后，我们再调用<code>helloworld.py</code>大模型，可以看到关键的日志信息，但是verbose只会输出关键日志，下面我们还可以 <code>debug</code>查看更加详细的日志信息。</p><h2 id="Debug日志"><a href="#Debug日志" class="headerlink" title="Debug日志"></a>Debug日志</h2><p>我们可以通过<code>debug</code>设置日志级别，从而查看更加详细的日志信息，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.<span class="built_in">globals</span> <span class="keyword">import</span> set_debug</span><br><span class="line"><span class="comment"># 全局 debug配置开关</span></span><br><span class="line">set_debug(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>打开开关后，我们再调用<code>helloworld.py</code>大模型，可以看到更加详细的日志信息，具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-7.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文我们主要学习了LangServer的去部署一个 LangChain链，通过 LangServe对于第三方就能加友好的访问我们的提供 LangChain服务，从而实现更加复杂的功能。回顾一下，我们主要学习了以下内容：</p><ul><li>LangServer 安装与运行：通过 LangChain-Cli脚手架创建项目和<code>langchain serve</code>运行项目</li><li>LangServer 接口开发：<code>add_routes</code>添加接口，可以直接把一个 LangChain添加到 LangServer中且自动生成 Swagger文档  </li><li>LangServer监控与日志：LangSmith是LangChain官方提供的监控工具，但是会上报我们服务相关的日志信息，因此我们可以设置<code>set_verbose</code>或者<code>set_debug</code>设置详细日志开关， 从而实现我们调用 LangChain链路的完整日志</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从 LangChain系列文章开始到现在，我们学习 LangChain的基础知识和实战撸代码，现在我们假设已经开发好一个 LangChain链式任务，那么如何部署以及如何与 web服务进行互相调用呢？&lt;/p&gt;
&lt;p&gt;那么接下来我们应该就学习LangServer与LangSmith，如何让 LangChain进行企业级开发。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LangServer: 帮开发者将  LangChain 部署一个 Restful 服务。&lt;/p&gt;
&lt;p&gt;LangSmith: 监控 LangChain调用链路服务和提供更加友好的可视化界面。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
