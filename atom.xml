<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qborfy知识库</title>
  
  
  <link href="https://www.qborfy.com/atom.xml" rel="self"/>
  
  <link href="https://www.qborfy.com/"/>
  <updated>2025-05-22T11:45:34.661Z</updated>
  <id>https://www.qborfy.com/</id>
  
  <author>
    <name>Qborfy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>09篇 AI从零开始 - LangChain学习与实战(6) Agent开发</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn09.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn09.html</id>
    <published>2025-03-31T07:00:00.000Z</published>
    <updated>2025-05-22T11:45:34.661Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面</p><h1 id="Agent智能体"><a href="#Agent智能体" class="headerlink" title="Agent智能体"></a>Agent智能体</h1><blockquote></blockquote><p>Agent的一些思考， 首先 Agent本身的  Prompt很重要， LLM 大模型会依据Prompt+用户输入去判断需要使用哪个工具</p><p>然后创建Agent, Langchain也提供不同的类型，如下：</p><ul><li>Tool Calling Agent (create_tool_calling_agent)​ ： 依赖模型原生工具调用能力，自动将工具描述注入模型上下文， 直接返回工具调用参数对象，部分LLM模型支持</li><li>ReAct Agent (create_react_agent)​ ： 遵循 Thought → Action → Observation 循环，每步根据上下文选择工具，结合自然语言与工具调用</li><li>​​Structured Chat Agent (create_structured_chat_agent)​：必须遵循预定义响应模板，严格匹配工具参数格式，通常一次性完成工具选择</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li><li><a href="https://zhuanlan.zhihu.com/p/694458202">Langchain Agent - Agent类型说明</a></li><li><a href="https://tushare.pro/">Tushare</a><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote></li></ul><p><a href="https://langchain-ai.github.io/langgraph/agents/agents/#1-install-dependencies">https://langchain-ai.github.io/langgraph/agents/agents/#1-install-dependencies</a></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面&lt;/p&gt;
&lt;h1 id=&quot;Agent智能体&quot;&gt;&lt;a href=&quot;#Agent智能</summary>
      
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>10篇 AI从零开始 - LangChain学习与实战(5) 低代码平台AI助手 开发</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn10.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn10.html</id>
    <published>2025-03-31T07:00:00.000Z</published>
    <updated>2025-05-14T13:16:28.140Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>回顾一下LangChain系列学习文章：</p><ul><li><a href="https://qborfy.com/ailearn/ai-learn04.html">04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</a></li><li><a href="https://qborfy.com/ailearn/ai-learn05.html">05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉</a></li><li><a href="https://qborfy.com/ailearn/ai-learn06.html">06篇 AI从零开始 - LangChain学习与实战(3) LCEL工作流编排原理与实战</a></li><li><a href="https://qborfy.com/ailearn/ai-learn07.html">07篇 AI从零开始 - LangChain学习与实战(4) LangServer部署</a></li><li><a href="https://qborfy.com/ailearn/ai-learn08.html">08篇 AI从零开始 - LangChain学习与实战(5) 基于RAG开发问答机器人</a></li></ul><p>经过LangChain系列文章的学习后， 现在我们需要通过 LangChain + 大模型 + 低代码平台， 开发具备实际功能的 AI 应用：</p><blockquote><p><strong>低代码平台AI助手</strong>：通过用户输入自然语言能实现 低代码平台页面生成、编辑等</p></blockquote><span id="more"></span><h1 id="1-前期与实现方案"><a href="#1-前期与实现方案" class="headerlink" title="1. 前期与实现方案"></a>1. 前期与实现方案</h1><p>目标：通过用户输入自然语言能实现，完成低代码平台页面的生成，同时能低代码平台页面组件元素进行属性调整。</p><p>实际原理： 利用 AI大模型实现用户输入的自然语言与低代码平台特定 DSL语言（JSON Schema）互相转换</p><h2 id="1-1-前期准备"><a href="#1-1-前期准备" class="headerlink" title="1.1 前期准备"></a>1.1 前期准备</h2><ol><li>搭建低代码平台服务，可以参考文档： <a href="https://formilyjs.org/zh-CN/guide/form-builder">Formily 表单设计器</a></li><li>Langchain 和 LangServer环境准备， 参考： <a href="https://qborfy.com/ailearn/ai-learn04.html">04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</a></li></ol><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ol><li>LangChain开发实现大模型理解低代码平台DSL语言的输入，并能输出是低代码平台DSL语言</li><li>通过 LangServer提供大模型 API<ol><li>输入当前页面 json schema</li><li>用户输入自然语言，LangServer调用大模型API，返回结果</li><li>LangServer将返回结果转换成低代码平台DSL语言</li></ol></li><li>低代码平台新增 AI助手 UI，更改低代码页面JSON内容 </li></ol><h1 id="2-实战开发"><a href="#2-实战开发" class="headerlink" title="2. 实战开发"></a>2. 实战开发</h1><h2 id="2-1-LangChain-Agent-Server开发"><a href="#2-1-LangChain-Agent-Server开发" class="headerlink" title="2.1 LangChain Agent + Server开发"></a>2.1 LangChain Agent + Server开发</h2><h2 id="2-2-Formily-插件-AI-助手前端开发"><a href="#2-2-Formily-插件-AI-助手前端开发" class="headerlink" title="2.2 Formily 插件 AI 助手前端开发"></a>2.2 Formily 插件 AI 助手前端开发</h2><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li><li><a href="https://zhuanlan.zhihu.com/p/694458202">Langchain Agent - Agent类型说明</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><p>对 Agent的一些思考， 首先 agent本身的  Prompt很重要， LLM 大模型会依据Prompt+用户输入去判断需要使用哪个工具</p><p>然后创建Agent, Langchain也提供不同的类型，如下：</p><ul><li>Tool Calling Agent (create_tool_calling_agent)​ ： 依赖模型原生工具调用能力，自动将工具描述注入模型上下文， 直接返回工具调用参数对象，部分LLM模型支持</li><li>ReAct Agent (create_react_agent)​ ： 遵循 Thought → Action → Observation 循环，每步根据上下文选择工具，结合自然语言与工具调用</li><li>​​Structured Chat Agent (create_structured_chat_agent)​：必须遵循预定义响应模板，严格匹配工具参数格式，通常一次性完成工具选择</li></ul><p>利用 Agent 开发一个完整的低代码平台 AI 助手，整体实现过程如下：</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;回顾一下LangChain系列学习文章：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn04.html&quot;&gt;04篇 AI从零开始 - LangChain学习与实战(1) 基础知识&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn05.html&quot;&gt;05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn06.html&quot;&gt;06篇 AI从零开始 - LangChain学习与实战(3) LCEL工作流编排原理与实战&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn07.html&quot;&gt;07篇 AI从零开始 - LangChain学习与实战(4) LangServer部署&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn08.html&quot;&gt;08篇 AI从零开始 - LangChain学习与实战(5) 基于RAG开发问答机器人&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;经过LangChain系列文章的学习后， 现在我们需要通过 LangChain + 大模型 + 低代码平台， 开发具备实际功能的 AI 应用：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;低代码平台AI助手&lt;/strong&gt;：通过用户输入自然语言能实现 低代码平台页面生成、编辑等&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>08篇 AI从零开始 - LangChain学习与实战(5) 基于RAG开发问答机器人</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn08.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn08.html</id>
    <published>2025-03-15T07:00:00.000Z</published>
    <updated>2025-03-21T13:29:47.774Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面几篇学习LangChain，基本上完成对 LangChain从开发到上线有一个整体的了解，那么接下来我们就要开始实战了，我们将会使用LangChain开发一个问答机器人，这个问答机器人将会使用到RAG模型，那么接下来我们开始学习RAG。</p><span id="more"></span><h1 id="RAG是什么"><a href="#RAG是什么" class="headerlink" title="RAG是什么"></a>RAG是什么</h1><blockquote><p>RAG是一种用额外数据增强大模型知识的技术，俗称“RAG”（Retrieval-Augmented Generation），中文叫检索增强生成。</p></blockquote><p>RAG是LangChain中一个重要的应用场景，它能够将检索和生成结合起来，从而生成更加精准的答案。</p><p>RAG模型由两个部分组成：Retriever和Generator。</p><ul><li><code>Generator</code> 生成索引向量，根据文档中问题和答案生成索引向量数据库。</li><li><code>Retriever</code> 检索对比类似，根据用户的问题，从生成的知识库中检索召回最相关的问题和答案。</li></ul><p>RAG技术是通过检索和生成相结合的方式找最相关的知识内容， 加入到大模型的提示语中，通过大模型推理得到用户问题在知识库中最合适的答案。</p><p>下面是我个人依据网上相关资料整理的通用RAG模型架构图：</p><p><img src="/assets/img/ailearn/ai-learn08-1.png" alt=""></p><h2 id="生成向量索引（Indexing）"><a href="#生成向量索引（Indexing）" class="headerlink" title="生成向量索引（Indexing）"></a>生成向量索引（Indexing）</h2><p>生成向量索引有三个步骤，分别如下：</p><ol><li>加载(load)，加载所需数据，LangChain中提供各种加载器，如：PDFLoader、TextLoader、ImageLoader等。</li><li>分割(Split)，将加载的数据进行分割成一个个块，LangChain中提供各种分割器，如：TextSplitter、ImageSplitter等。</li><li>存储(Store)，得到分割的Chunks，需要将Chunk转成向量索引并存储，这里我们会依赖<code>Embeddings</code>模型进行生成索引，然后存储到向量数据库<code>VectorStore</code>。</li></ol><h2 id="Embeddings嵌入模型"><a href="#Embeddings嵌入模型" class="headerlink" title="Embeddings嵌入模型"></a>Embeddings嵌入模型</h2><p>RAG模型使用<code>Embeddings</code>模型将问题和答案进行编码，生成向量数据，这里我们必不可免需要对<code>Embeddings</code>模型进行初步了解。</p><blockquote><p>Embeddings模型，也叫嵌入模型，是一种将高维度的数据，如：自然语言、图片、视频等，转换成低维度的向量数据，如：多维矩阵数组等，方便后续进行相似度对比。</p></blockquote><p>或者我们可以更加直观的理解，<code>Embeddings</code>模型可以把我们人类能够理解的内容，转换成计算机能够计算理解的数据，从而实现更多的算法对比逻辑。</p><h2 id="检索和生成"><a href="#检索和生成" class="headerlink" title="检索和生成"></a>检索和生成</h2><ol><li>检索：通过用户输入的内容，使用检索器将内容转换为向量，然后从向量数据库中检索最相关的向量数据。</li><li>生成：通过检索器检索到的向量数据，使用生成器生成新的向量数据，然后存储到向量数据库中。</li></ol><p>这两个步骤一般都是同时进行，一般也是 通过Embeddings嵌入模型去转换搜索内容为向量，然后通过检索到最后生成内容。</p><h1 id="实战：做一个问答机器人"><a href="#实战：做一个问答机器人" class="headerlink" title="实战：做一个问答机器人"></a>实战：做一个问答机器人</h1><h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><ol><li>用户上传问题知识内容上传文件</li><li>服务端对上传文件进行解析，拆分chunk</li><li>将 chunk 传给 Embeddings模型，生成向量索引</li><li>将 向量索引存储到向量数据库中</li><li>用户输入问题，通过检索器检索到最相关的向量数据</li><li>然后将最相关向量数据传给对话大模型，组织推理得到答案，返回给用户</li></ol><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>Ollama安装模型：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对话大模型</span></span><br><span class="line">ollama install deepseek-r1:7b</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">embeddings模型</span></span><br><span class="line">ollama install shaw/dmeta-embedding-zh:latest</span><br></pre></td></tr></table></figure><p>LangChain和  Streamlit安装</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python环境 3.12.4</span></span><br><span class="line"><span class="comment"># streamlit 1.39.0</span></span><br><span class="line"><span class="comment"># toml</span></span><br><span class="line"></span><br><span class="line">pip install langchain</span><br><span class="line">pip install streamlit</span><br></pre></td></tr></table></figure><p><code>requirements.txt</code>文件内容如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">streamlit==1.39.0</span><br><span class="line">langchain==0.3.21</span><br><span class="line">langchain-chroma==0.2.2</span><br><span class="line">langchain-community==0.3.20</span><br><span class="line">langchain-ollama==0.2.3</span><br></pre></td></tr></table></figure><blockquote><p>streamlit是构建和共享数据应用程序的更快方法， 几分钟内将您的数据脚本转换为可共享的网络应用程序，全部采用纯 Python 编写，无需前端经验。<br>官方文档：<a href="https://docs.streamlit.io/get-started/installation">https://docs.streamlit.io/get-started/installation</a></p></blockquote><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>新建一个文件<code>bot_chat.py</code>， 分步骤实现。</p><h3 id="1-stremlit页面搭建"><a href="#1-stremlit页面搭建" class="headerlink" title="1. stremlit页面搭建"></a>1. stremlit页面搭建</h3><p>代码参考如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 st 的标题和布局</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;RAG测试问答&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置应用标题</span></span><br><span class="line">st.title(<span class="string">&quot;RAG测试问答&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持上传 txt 文件</span></span><br><span class="line">upload_file = st.sidebar.file_uploader(label=<span class="string">&quot;上传文件&quot;</span>, <span class="built_in">type</span>=[<span class="string">&quot;txt&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> upload_file:</span><br><span class="line">    st.info(<span class="string">&quot;请上传 txt 文件&quot;</span>)</span><br><span class="line">    st.stop()</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><p><img src="/assets/img/ailearn/ai-learn08-2.png" alt=""></p><h3 id="2-解析文档并生成知识库检索器"><a href="#2-解析文档并生成知识库检索器" class="headerlink" title="2. 解析文档并生成知识库检索器"></a>2. 解析文档并生成知识库检索器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> tempfile</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory <span class="comment"># 会话记录到内存</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> StreamlitChatMessageHistory <span class="comment">#  Streamlit聊天记录存储</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader <span class="comment"># 文本加载器</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.embeddings <span class="keyword">import</span> OllamaEmbeddings <span class="comment"># Ollama Eembeddings 语言模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma <span class="comment"># Chroma 向量数据库</span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter <span class="comment"># 文本分割器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 st 的标题和布局</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;RAG测试问答&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置应用标题</span></span><br><span class="line">st.title(<span class="string">&quot;RAG测试问答&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持上传 txt 文件</span></span><br><span class="line">upload_file = st.sidebar.file_uploader(label=<span class="string">&quot;上传文件&quot;</span>, <span class="built_in">type</span>=[<span class="string">&quot;txt&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> upload_file:</span><br><span class="line">    st.info(<span class="string">&quot;请上传 txt 文件&quot;</span>)</span><br><span class="line">    st.stop()</span><br><span class="line"></span><br><span class="line"><span class="comment"># step1 实现知识库生成</span></span><br><span class="line"><span class="meta">@st.cache_resource(<span class="params">ttl=<span class="string">&quot;1h&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_knowledge_base</span>(<span class="params">uploaded_file</span>):</span><br><span class="line">    <span class="comment"># 读取上传的文档</span></span><br><span class="line">    docs = []</span><br><span class="line">    <span class="comment"># 将 uploaded_file 存到 /tmp</span></span><br><span class="line">    temp_dir = tempfile.TemporaryDirectory(<span class="built_in">dir</span>=<span class="string">r&quot;/tmp&quot;</span>)</span><br><span class="line">    tempfilepath = os.path.join(temp_dir.name, uploaded_file.name)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(tempfilepath, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(uploaded_file.getvalue())</span><br><span class="line">    <span class="comment"># 使用 TextLoader 加载文档</span></span><br><span class="line">    docs = TextLoader(tempfilepath, encoding=<span class="string">&quot;utf-8&quot;</span>).load()</span><br><span class="line">    <span class="comment"># 使用 RecursiveCharacterTextSplitter 分割文档</span></span><br><span class="line">    splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">200</span>)</span><br><span class="line">    splits = splitter.split_documents(docs)</span><br><span class="line">    <span class="comment"># 使用 OllamaEmbeddings 生成文档向量</span></span><br><span class="line">    embeddings = OllamaEmbeddings(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;shaw/dmeta-embedding-zh&quot;</span>)</span><br><span class="line">    <span class="comment"># 使用 Chroma 向量数据库存储文档向量</span></span><br><span class="line">    chroma_db = Chroma.from_documents(splits, embeddings)</span><br><span class="line">    <span class="comment"># 创建文档检索器 约等于 知识库</span></span><br><span class="line">    retriever = chroma_db.as_retriever()</span><br><span class="line">    <span class="keyword">return</span> retriever</span><br><span class="line">    </span><br><span class="line">retriever = get_knowledge_base(upload_file) </span><br></pre></td></tr></table></figure><p>上文件后， 执行效果如下：</p><p><img src="/assets/img/ailearn/ai-learn08-4.png" alt=""></p><p><img src="/assets/img/ailearn/ai-learn08-3.png" alt=""></p><h3 id="3-初始化聊天消息界面"><a href="#3-初始化聊天消息界面" class="headerlink" title="3. 初始化聊天消息界面"></a>3. 初始化聊天消息界面</h3><p>聊天功能主要几点：</p><ul><li>记录聊天内容</li><li>显示聊天内容</li><li>用户输入框</li></ul><p>具体实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step2 初始化聊天消息界面</span></span><br><span class="line"><span class="comment"># 如果用户输入&quot;清空聊天记录&quot;，则重新初始化界面</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state <span class="keyword">or</span> st.sidebar.button(<span class="string">&quot;清空聊天记录&quot;</span>):</span><br><span class="line">    st.session_state[<span class="string">&quot;messages&quot;</span>] = [&#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;你好&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;我是测试 RAG 问答小助手&quot;</span></span><br><span class="line">    &#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示历史聊天记录</span></span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> st.session_state[<span class="string">&quot;messages&quot;</span>]:</span><br><span class="line">    st.chat_message(msg[<span class="string">&quot;role&quot;</span>], msg[<span class="string">&quot;content&quot;</span>])  <span class="comment"># </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建历史聊天记录</span></span><br><span class="line">msgs = StreamlitChatMessageHistory()</span><br><span class="line"><span class="comment"># 创建对话缓存</span></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    chat_memory=msgs,</span><br><span class="line">    return_messages=<span class="literal">True</span>,</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    output_key=<span class="string">&quot;out&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建 UI 输入框</span></span><br><span class="line">user_query = st.chat_input(placeholder=<span class="string">&quot;请输入要测试的问题&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="4-创建LLM-检索-agent执行"><a href="#4-创建LLM-检索-agent执行" class="headerlink" title="4. 创建LLM 检索 agent执行"></a>4. 创建LLM 检索 agent执行</h3><p>这里实现一个Agent， 过程是 去调用一个检索工具，支持模板和用户输入，调用大模型进行检索，然后返回结果。</p><p>具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step3 创建检索 agent </span></span><br><span class="line"><span class="keyword">from</span> langchain.tools.retriever <span class="keyword">import</span> create_retriever_tool</span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-1 用于创建文档检索的工具</span></span><br><span class="line">tool = create_retriever_tool(</span><br><span class="line">    retriever=retriever,</span><br><span class="line">    name=<span class="string">&quot;文档检索&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;根据输入的关键词，检索相关文档&quot;</span>,</span><br><span class="line">)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-2 创建 LLM对话模型</span></span><br><span class="line"><span class="comment"># 创建指令 Prompt</span></span><br><span class="line">instruction = <span class="string">&quot;&quot;&quot;你是一个设计用于查询文档回答问题的代理</span></span><br><span class="line"><span class="string">您可以使用文档检索工具，并基于检索内容来回答问题。</span></span><br><span class="line"><span class="string">可能你不查询文档就知道答案，但是仍然要去查询文档来获得答案。</span></span><br><span class="line"><span class="string">如果从文档找不到任何信息和答案来回答问题，则需要返回“非常抱歉，这个问题暂时没有录入到知识库中。”作为答案。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">base_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#123;instruction&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">TOOLS:</span></span><br><span class="line"><span class="string">----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你可以使用以下工具：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;tools&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">使用工具中，你可以参考这样子：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string">思考：我是否需要使用工具？ 是的</span></span><br><span class="line"><span class="string">动作：我需要使用工具：[&#123;tool_names&#125;]</span></span><br><span class="line"><span class="string">动作：输入:&#123;input&#125;</span></span><br><span class="line"><span class="string">动作执行后： 返回动作执行后的结果</span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当你需要返回一个答案，且这个答案不需要使用工具时，你可以参考这样子：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string">思考：我是否需要使用工具？ 不是</span></span><br><span class="line"><span class="string">答案： [你的答案]</span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">开始！</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">上一次历史对话内容如下：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">新的问题是：&#123;input&#125;</span></span><br><span class="line"><span class="string">&#123;agent_scratchpad&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># agent_scratchpad 是 agent 的 scratchpad，用于存储 agent 的状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基础模板</span></span><br><span class="line">base_prompt = PromptTemplate.from_template(base_template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充基础模板</span></span><br><span class="line">prompt = base_prompt.partial(instruction=instruction)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 LLM 模型</span></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:7b&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-3 创建 agent</span></span><br><span class="line">agent = create_react_agent(llm=llm, prompt=prompt, tools=tools)</span><br><span class="line"></span><br><span class="line">agent_excutor = AgentExecutor(</span><br><span class="line">    agent=agent,</span><br><span class="line">    tools=tools,</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    handle_parsing_errors=<span class="string">&quot;从知识库没找到对应内容或者答案&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="5-用户输入与-Agent返回"><a href="#5-用户输入与-Agent返回" class="headerlink" title="5. 用户输入与 Agent返回"></a>5. 用户输入与 Agent返回</h3><p>这一步基本上就是解决用户输入显示与 Agent返回结果，同时通过 streamlit的 callbank函数去 展示 Agent的执行过程，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step5 用户输入查询与返回</span></span><br><span class="line"><span class="keyword">if</span>  user_query:</span><br><span class="line">    <span class="comment"># 添加到 session 历史记录</span></span><br><span class="line">    st.session_state[<span class="string">&quot;messages&quot;</span>].append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_query&#125;)</span><br><span class="line">    <span class="comment"># 显示用户信息</span></span><br><span class="line">    st.chat_message(<span class="string">&quot;user&quot;</span>).write(user_query)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">        <span class="comment"># 创建回调</span></span><br><span class="line">        callback = StreamlitCallbackHandler(st.container())</span><br><span class="line">        <span class="comment"># 将 agent执行过程 显示在 streamlit中，如：思考、选择工具、执行查询等等</span></span><br><span class="line">        config = &#123;<span class="string">&quot;callbacks&quot;</span>: [callback]&#125;</span><br><span class="line">        <span class="comment"># agent 执行</span></span><br><span class="line">        response = agent_excutor.invoke(&#123;<span class="string">&quot;input&quot;</span>: user_query&#125;, config=config)</span><br><span class="line">        <span class="comment"># 保存agent 执行结果到聊天记录 </span></span><br><span class="line">        st.session_state[<span class="string">&quot;messages&quot;</span>].append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response[<span class="string">&quot;output&quot;</span>]&#125;)</span><br><span class="line">        <span class="comment"># 显示在 streamlit中</span></span><br><span class="line">        st.write(response[<span class="string">&quot;output&quot;</span>])</span><br></pre></td></tr></table></figure><h3 id="最终运行"><a href="#最终运行" class="headerlink" title="最终运行"></a>最终运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamlit run bot_chat.py</span><br></pre></td></tr></table></figure><p>执行效果如下：<br>对话中：<br><img src="/assets/img/ailearn/ai-learn08-5.png" alt=""></p><p>返回答案：<br><img src="/assets/img/ailearn/ai-learn08-6.png" alt=""></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面几篇学习LangChain，基本上完成对 LangChain从开发到上线有一个整体的了解，那么接下来我们就要开始实战了，我们将会使用LangChain开发一个问答机器人，这个问答机器人将会使用到RAG模型，那么接下来我们开始学习RAG。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>07篇 AI从零开始 - LangChain学习与实战(4) LangServer部署</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn07.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn07.html</id>
    <published>2025-03-12T07:00:00.000Z</published>
    <updated>2025-04-07T12:04:38.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>从 LangChain系列文章开始到现在，我们学习 LangChain的基础知识和实战撸代码，现在我们假设已经开发好一个 LangChain链式任务，那么如何部署以及如何与 web服务进行互相调用呢？</p><p>那么接下来我们应该就学习LangServer与LangSmith，如何让 LangChain进行企业级开发。</p><blockquote><p>LangServer: 帮开发者将  LangChain 部署一个 Restful 服务。</p><p>LangSmith: 监控 LangChain调用链路服务和提供更加友好的可视化界面。</p></blockquote><span id="more"></span><h1 id="认识-LangServer"><a href="#认识-LangServer" class="headerlink" title="认识 LangServer"></a>认识 LangServer</h1><p>LangServer是集成了FastApi + Pydantic的Restful框架。它提供了一些特性：</p><ul><li>每次 API调用都会返回丰富的错误信息</li><li>自带 JSON Schema和   Swagger API文档</li><li>高效的<code>/invoke</code>、 <code>batch</code>和 <code>/stream</code>接口服务，支持单个服务器多个并发请求</li><li>支持调用<code>/stream_log</code>接口，实现链式任务中间态步骤返回</li><li><code>/stream_events</code>更加清晰任务事件状态信息</li><li>提供LangServer SDK，调用 Restful 和 直接调用大模型一样简单</li></ul><h1 id="实战教程"><a href="#实战教程" class="headerlink" title="实战教程"></a>实战教程</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>安装<code>langchain-cli</code>全局命令，方便快速启动 Lang Server项目</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U langchain-cli </span><br></pre></td></tr></table></figure><p>安装<code>poetry</code>管理项目的依赖，更好管理服务依赖 pip包。</p><blockquote><p><code>poetry</code> Python packaging and dependency management made easy， 翻译过来就是更加轻松管理 python项目和依赖</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 pipx</span></span><br><span class="line">pip install pipx</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pipx添加到环境变量</span></span><br><span class="line">pipx ensurepath</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 poetry</span></span><br><span class="line">pipx install poetry</span><br></pre></td></tr></table></figure><h2 id="初始化和运行项目"><a href="#初始化和运行项目" class="headerlink" title="初始化和运行项目"></a>初始化和运行项目</h2><ol><li>项目初始化<br>利用langchain-cli 脚手架， 初始化一个 langserver项目</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化一个langserver的项目</span></span><br><span class="line">langchain app new mylangserver</span><br><span class="line"></span><br><span class="line">pipx run langchain app new mylangserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入项目目录</span></span><br><span class="line">cd mylangserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装项目依赖</span></span><br><span class="line">poetry install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装后续依赖的包</span></span><br><span class="line">poetry add langchain</span><br><span class="line">poetry add langchain_ollama</span><br></pre></td></tr></table></figure><ol start="2"><li>项目结构说明<br>生成的目录结构与说明如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mylangserver # 项目名</span><br><span class="line">├─.gitignore</span><br><span class="line">├─Dockerfile </span><br><span class="line">├─README.md</span><br><span class="line">├─pyproject.toml # 项目结构说明文件</span><br><span class="line">├─poetry.lock # poetry依赖锁文件 类似前端的yarn.lock</span><br><span class="line">├─packages</span><br><span class="line">|    └README.md</span><br><span class="line">├─app</span><br><span class="line">|  ├─__init__.py</span><br><span class="line">|  ├─server.py  # 服务主入口 后续开发都在这里</span><br></pre></td></tr></table></figure><ol start="3"><li>运行项目</li></ol><p>在根目录下运行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">langchain server</span><br></pre></td></tr></table></figure><p>就可以直接访问 <code>http://localhost:8080</code>，效果具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-1.png" alt=""></p><h2 id="接口开发"><a href="#接口开发" class="headerlink" title="接口开发"></a>接口开发</h2><ol><li><code>server.py</code>文件<br>在接口开发之前我们先看看 <code>server.py</code>文件，具体如下：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> RedirectResponse</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里是定义路由和对应路由实现的方法</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">redirect_root_to_docs</span>():</span><br><span class="line">    <span class="keyword">return</span> RedirectResponse(<span class="string">&quot;/docs&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们可以添加路由</span></span><br><span class="line"><span class="comment"># add_routes(app, NotImplemented)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    <span class="comment"># 这里通过 uvicorn启动服务，端口为8000</span></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure><ol start="2"><li>添加一个调用<code>DeepSeek-R1</code>模型的接口</li></ol><p>通过 <code>add_routes</code>新增一个模型对象，会自动封装成对应的 Restful接口，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> RedirectResponse</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"></span><br><span class="line">deepseek = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"></span><br><span class="line">app = FastAPI(</span><br><span class="line">    title=<span class="string">&quot;Qborfy个人 LangServer&quot;</span>,</span><br><span class="line">    version=<span class="string">&quot;0.1.0&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Qborfy个人 LangServer，学习测试使用&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">redirect_root_to_docs</span>():</span><br><span class="line">    <span class="keyword">return</span> RedirectResponse(<span class="string">&quot;/docs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 deepseek路由</span></span><br><span class="line">add_routes(app, deepseek, path=<span class="string">&quot;/deepseek&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>接下来我们访问 <code>http://localhost:8000/</code>，就会出现和<code>/deepseek</code>相关的文档，具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-2.png" alt=""></p><h2 id="接口测试"><a href="#接口测试" class="headerlink" title="接口测试"></a>接口测试</h2><p>接口测试我们可以通过<a href="https://apifox.com/">ApiFox</a> (一个和 Postman类似  API 测试工具)进行测试，具体如下.</p><ol><li><code>/invoke</code> 发起一个对话请求, 具体如下图：</li></ol><p><img src="/assets/img/ailearn/ai-learn07-3.png" alt=""></p><ol start="2"><li><code>/stream</code> 流式调用，具体如下图：</li></ol><p><img src="/assets/img/ailearn/ai-learn07-4.png" alt=""></p><h2 id="SDK调用"><a href="#SDK调用" class="headerlink" title="SDK调用"></a>SDK调用</h2><p>在LangChain中是可以通过 LangServe提供的 <code>RemoteRunable</code> 进行远程调用，和原来的调用大模型的使用方式其实是一样的， 具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用远端调用 LangServer</span></span><br><span class="line"><span class="keyword">from</span> langchain.schema.runnable <span class="keyword">import</span> RunnableMap</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> RemoteRunnable</span><br><span class="line"></span><br><span class="line">llm = RemoteRunnable(<span class="string">&quot;http://127.0.0.1:8000/deepseek&quot;</span>)</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;你是世界级的 AI 技术专家, &#123;input&#125;&quot;</span></span><br><span class="line"><span class="comment"># 这里我们使用一个简单的模板</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    template=template</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建一个简单的链式调用</span></span><br><span class="line">chain = prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行链式调用</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> llm.stream(<span class="string">&quot;海洋是什么颜色&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(chunk, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样子我们不仅可以在本地调用大模型，还能调用其他人提供 LangChain服务，从而实现更加复杂的功能。</p><h2 id="生产部署"><a href="#生产部署" class="headerlink" title="生产部署"></a>生产部署</h2><p>LangServer生产部署，按照 LangChain官方推荐是通过<code>Dockerfile</code>打包进行部署，其中也比较简单，具体执行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打包镜像</span></span><br><span class="line">docker build . -t my-langserve-app</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行镜像</span></span><br><span class="line">docker run -p 8080:8080 my-langserve-app</span><br></pre></td></tr></table></figure><p>或者是通过 docker-compose启动 docker服务，具体如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">langserver:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">my-langserve-app</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8080</span><span class="string">:8080</span></span><br></pre></td></tr></table></figure><p>最终执行<code>docker-compose up -d</code>启动服务后，就可以通过<code>http://localhost:8080/docs</code>访问到服务了。</p><h1 id="监控与日志"><a href="#监控与日志" class="headerlink" title="监控与日志"></a>监控与日志</h1><h2 id="LangSmith监控"><a href="#LangSmith监控" class="headerlink" title="LangSmith监控"></a>LangSmith监控</h2><p>LangSmith是 LangChain官方提供的监控工具，可以监控模型运行情况，一个 SASS服务需要我们将服务相关信息注册到 LangSmith网站上，因此可以按个人或公司需要判断是否允许使用。</p><blockquote><p>LangSmith是一个用于构建生产级应用的平台。它允许您密切监控和评估您的应用，以便您可以快速而自信地发布应用。</p><p>传统软件应用程序是通过编写代码来构建的，而 AI 应用程序则需要编写提示来指导应用程序执行哪些操作。</p><p>LangSmith 提供了一套旨在实现和促进提示工程的工具，以帮助您找到适合您的应用程序的完美提示。</p></blockquote><p><strong>PS：LangSmith这里提示未来编程开发者的思维转变，我们实现功能的思路不再是针对一些实现逻辑，而是面向不同的 AI 模型，优化提示语实现我们想要的功能。</strong></p><p>在 LangServer 中使用 LangSmith，需要先注册一个账号，然后获取 api key 添加到 LangServer中，具体使用代码如下： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置LangSimth 环境变量</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_TRACING&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_ENDPOINT&quot;</span>] = <span class="string">&quot;https://api.smith.langchain.com&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_API_KEY&quot;</span>] = <span class="string">&quot;&lt;LANG_SIMTH_KEY&gt;&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_PROJECT&quot;</span>] = <span class="string">&quot;mylangserver&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>具体使用教程可以参考<a href="https://docs.smith.langchain.com/">LangSmith官方文档</a></p><p>LangSmith主要作用是监控 链路任务节点调用和扭转情况，可以更加清晰的分析链的运行情况和日志，具体效果如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn07-5.png" alt=""></p><h2 id="Verbose关键日志"><a href="#Verbose关键日志" class="headerlink" title="Verbose关键日志"></a>Verbose关键日志</h2><p>如果我们不想把自己的服务相关的日志信息暴露给 LangSmith， 我们还可以通过设置<code>set_verbose</code>设置详细日志开关， 从而实现我们调用 LangChain链路的完整日志，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.<span class="built_in">globals</span> <span class="keyword">import</span> set_verbose</span><br><span class="line"><span class="comment"># 全局 verbose配置开关</span></span><br><span class="line">set_verbose(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 针对部分链接调用设置详细日志开关</span></span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>打开开关后，我们再调用<code>helloworld.py</code>大模型，可以看到关键的日志信息，但是verbose只会输出关键日志，下面我们还可以 <code>debug</code>查看更加详细的日志信息。</p><h2 id="Debug日志"><a href="#Debug日志" class="headerlink" title="Debug日志"></a>Debug日志</h2><p>我们可以通过<code>debug</code>设置日志级别，从而查看更加详细的日志信息，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.<span class="built_in">globals</span> <span class="keyword">import</span> set_debug</span><br><span class="line"><span class="comment"># 全局 debug配置开关</span></span><br><span class="line">set_debug(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>打开开关后，我们再调用<code>helloworld.py</code>大模型，可以看到更加详细的日志信息，具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-7.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文我们主要学习了LangServer的去部署一个 LangChain链，通过 LangServe对于第三方就能加友好的访问我们的提供 LangChain服务，从而实现更加复杂的功能。回顾一下，我们主要学习了以下内容：</p><ul><li>LangServer 安装与运行：通过 LangChain-Cli脚手架创建项目和<code>langchain serve</code>运行项目</li><li>LangServer 接口开发：<code>add_routes</code>添加接口，可以直接把一个 LangChain添加到 LangServer中且自动生成 Swagger文档  </li><li>LangServer监控与日志：LangSmith是LangChain官方提供的监控工具，但是会上报我们服务相关的日志信息，因此我们可以设置<code>set_verbose</code>或者<code>set_debug</code>设置详细日志开关， 从而实现我们调用 LangChain链路的完整日志</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从 LangChain系列文章开始到现在，我们学习 LangChain的基础知识和实战撸代码，现在我们假设已经开发好一个 LangChain链式任务，那么如何部署以及如何与 web服务进行互相调用呢？&lt;/p&gt;
&lt;p&gt;那么接下来我们应该就学习LangServer与LangSmith，如何让 LangChain进行企业级开发。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LangServer: 帮开发者将  LangChain 部署一个 Restful 服务。&lt;/p&gt;
&lt;p&gt;LangSmith: 监控 LangChain调用链路服务和提供更加友好的可视化界面。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>06篇 AI从零开始 - LangChain学习与实战(3) LCEL工作流编排原理与实战</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn06.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn06.html</id>
    <published>2025-03-03T07:00:00.000Z</published>
    <updated>2025-03-03T13:13:47.467Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>上一篇文章我们学习<a href="ttps://qborfy.com/ailearn/ai-learn05.html">05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉</a>，对 LangChain实际应用有了基本的了解，接下我们会进入 LangChain最重要的一次学习，就是 LangChain工作流编排原理与实战(LCEL), 学了本文基本上后续 LangChain实际开发都可以独立完成，本文内容较多，建议大家收藏，慢慢学习。</p><span id="more"></span><h1 id="1-LCEL介绍"><a href="#1-LCEL介绍" class="headerlink" title="1. LCEL介绍"></a>1. LCEL介绍</h1><p>LCEL(LangChain Expression Language) 是 LangChain提出来一种强大的工作流编排模式，可以通过基础组件去构建复杂任务链条式，包括但不限于：</p><ul><li>流式处理</li><li>并行处理</li><li>日志记录</li><li>…等等</li></ul><h2 id="1-1-LCEL的特性"><a href="#1-1-LCEL的特性" class="headerlink" title="1.1 LCEL的特性"></a>1.1 LCEL的特性</h2><ul><li><strong>一流的流式支持</strong>： 通过 LCEL 构建链时， 可以获得链式最佳时间（从第一个任务到最后一个输出所经历的时间），如：你通过不同链路调用 LLM 大模型到输出 ≈ 直接调用 LLM 大模型输出</li><li><strong>异步支持</strong>：LCEL链路中任何一个任务都可以异步执行，如：你可以在一个任务中调用另一个任务，而无需等待该任务完成</li><li><strong>优化的并行任务处理</strong>：针对多个并行步骤时候，LCEL会自动优化并行任务，达到最小延迟</li><li><strong>重试和回退</strong>：LCEL 链路中的任何任务都可以重试，如果失败，可以回退到上一个任务</li><li><strong>访问中间结果</strong>：可以访问 LCEL 链中的任何任务的结果，可以给用户提供实时结果和方便开发调试</li><li><strong>标准化的输入和输出模式</strong>：每个 LCEL链都可以直接使用 <code>Pydantic</code>对象和 <code>JSON</code>对象作为输入和输出，从而更好验证链路的正确性，并且LangServer的重要组成部分</li></ul><h1 id="2-LCEL原理设计-——-Runable-Interface"><a href="#2-LCEL原理设计-——-Runable-Interface" class="headerlink" title="2. LCEL原理设计 —— Runable Interface"></a>2. LCEL原理设计 —— Runable Interface</h1><p>LCEL之所以有如此强大的功能，离不开它的设计理念 —— Runable Interface，LangChain一套标准且强大的接口设计规范，让所有的组件都按照这个去实现，从而实现 LCEL 工作流编排。</p><p>Runable Interface接口设计有以下几个方面“</p><h2 id="2-1-标准调用方法"><a href="#2-1-标准调用方法" class="headerlink" title="2.1 标准调用方法"></a>2.1 标准调用方法</h2><p>同步调用方法：</p><ul><li>stream: 支持按照 stream流式返回</li><li>invoke: 支持同步调用</li><li>batch: 批量调用，等于多个invoke调用</li></ul><p>结合<code>await</code>实现异步调用的方法：</p><ul><li>astream: 异步调用stream流式返回</li><li>ainvoke: 异步调用</li><li>abatch: 异步调用批量调用，等于多个ainvoke调用</li><li>astream_log: 异步返回中间步骤，可以监控异步调用，最终会返回最后的结果</li><li>astream_envent: stream的异步事件监听，如：开始调用和结束调用触发</li></ul><h2 id="2-2-输入和输出"><a href="#2-2-输入和输出" class="headerlink" title="2.2 输入和输出"></a>2.2 输入和输出</h2><p>LangChain的输入和输出都是遵循<code>schema</code>规范，从可运行对象结构自动生成对应的<code>Pydantic</code>模型。</p><blockquote><p><code>Pydantic</code>是用于数据建模/解析的Python库，它允许您定义一个数据模型，然后使用该模型验证输入和输出。<br>它可以帮助您确保输入和输出数据符合预期的格式和类型，从而提高代码的健壮性和可维护性。<br>同时 <code>Pydantic</code> 内置了对JSON编码和解码的支持。</p></blockquote><p>不过不同组件输入类型和输出类型是不同的，下面常用 LangChain组件输入和输出类型：</p><table><thead><tr><th>组件</th><th>输入类型</th><th>输出类型</th></tr></thead><tbody><tr><td>提示 Prompt</td><td>string</td><td>PromptTemplate提示值</td></tr><tr><td>聊天模型</td><td>string、聊天信息列表、提示值</td><td>string</td></tr><tr><td>LLM</td><td>string、聊天信息列表、提示值</td><td>string</td></tr><tr><td>输出解析器</td><td>LLM、 LLM的输出</td><td>取决于解析器的类型，如 <code>jsonparser</code>输出的是 json格式</td></tr></tbody></table><p>流式运行对于基于 LLM 开发的应用会对用户使用体验上有更好的体验，所以目前LangChain中重要的组件都实现 LangChain Runable Interface中的 <code>stream</code>和<code>astream</code>，如：<code>PromptTemplate</code>、<code>ChatModel</code>、<code>LLM</code>、<code>OutputParser</code>等。</p><h2 id="2-3-Stream流"><a href="#2-3-Stream流" class="headerlink" title="2.3 Stream流"></a>2.3 Stream流</h2><p>上面弄清楚 LCEL的运行原理，我们还需要了解 <code>Stream</code>这一概念，才能更好的理解 LCEL工作流编排。</p><blockquote><p><code>Stream</code> 指的是一个数据流，它表示一个连续的数据序列，可以是一个数据块、一个文件、一个数据库表、一个网络连接等。在计算机科学中，流通常用于表示实时数据传输，例如从网络连接中接收的数据、从文件中读取的数据等。流数据具有连续性、实时性和不可预测性等特点，因此处理流数据需要特殊的算法和数据结构。</p></blockquote><p>在 LangChain中所有 Runable对象都实现了 <code>stream(同步)</code> 和 <code>astream(异步)</code>接口，通过 <code>stream</code> 和 <code>astream</code>接口，LangChain链式中的每个任务步骤都可以按照流式输入与输出。<br>从简单的任务，如发起一个 LLM调用，到复杂的任务，如：传输json数据等。</p><h1 id="3-LCEL工作流编排实战"><a href="#3-LCEL工作流编排实战" class="headerlink" title="3. LCEL工作流编排实战"></a>3. LCEL工作流编排实战</h1><p>了解完 LCEL工作流编排原理，我们开始实战，下面我们通过几个的例子，来更好理解 LCEL工作流编排。</p><h2 id="3-1-一次基础的流式调用"><a href="#3-1-一次基础的流式调用" class="headerlink" title="3.1 一次基础的流式调用"></a>3.1 一次基础的流式调用</h2><p>我们去调用一个 Ollama 大模型，然后调用 <code>stream</code>方法，看看最终会输出什么？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"></span><br><span class="line">chunks = []</span><br><span class="line"><span class="comment"># llm.stream 会返回一个流</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> llm.stream(<span class="string">&quot;海洋是什么颜色&quot;</span>):</span><br><span class="line">    chunks.append(chunk)</span><br><span class="line">    <span class="built_in">print</span>(chunk, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>最终输出效果，按照一块块输出，如下图：</p><p><img src="/assets/img/ailearn/ai-learn06-1.png" alt=""></p><h2 id="3-2-astream-异步调用"><a href="#3-2-astream-异步调用" class="headerlink" title="3.2 astream 异步调用"></a>3.2 astream 异步调用</h2><p>进一步看看<code>astream</code>调用和<code>stream</code>调用有什么区别？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line">propmt = ChatPromptTemplate.from_template(<span class="string">&quot;给我讲一个关于&#123;input&#125;的笑话&quot;</span>)</span><br><span class="line">parser = StrOutputParser()</span><br><span class="line">chain = propmt | llm | parser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步调用需要定义 async 方法</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> chain.astream(<span class="string">&quot;公鸡&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(chunk, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用的话需要通过  asyncio.run() 方法       </span></span><br><span class="line">asyncio.run(async_stream())</span><br></pre></td></tr></table></figure><p>异步调用需要定义 async 方法，调用的话需要通过  asyncio.run() 方法，最终效果和<code>stream</code>调用效果一样，不过在并行任务较多的情况下，<code>astream</code>调用会利用更多的CPU资源，从而提高并行任务处理效率。</p><h2 id="3-3-json输出格式"><a href="#3-3-json输出格式" class="headerlink" title="3.3 json输出格式"></a>3.3 json输出格式</h2><p>在实际应用中，我们很多场景其实 web服务通过 http协议传输，而且希望能被其他服务调用因此<code>json</code>格式输出会更好，下面我们看看如何实现？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line">propmt = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    以 JSON格式返回&#123;x&#125;的人口列表</span></span><br><span class="line"><span class="string">    使用一个`省份`作为字段列表返回</span></span><br><span class="line"><span class="string">    每个省份都应有有字段`省份名`+`人口`字段                                  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>)</span><br><span class="line">parser = JsonOutputParser() <span class="comment"># 保证每次输出都是json格式</span></span><br><span class="line">chain = propmt | llm | parser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步调用需要定义 async 方法</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> chain.astream(<span class="string">&quot;广东省、福建省、广西省&quot;</span>):</span><br><span class="line">        <span class="comment"># 可以看到每次 chunk都是一个完整的 json 格式</span></span><br><span class="line">        <span class="built_in">print</span>(chunk, end=<span class="string">&quot;\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用的话需要通过  asyncio.run() 方法       </span></span><br><span class="line">asyncio.run(async_stream())</span><br></pre></td></tr></table></figure><p>上文我们可以看到用到<code>JsonOutputParser</code>，它保证每次输出都是json格式，所以最终输出效果如下：<br><img src="/assets/img/ailearn/ai-learn06-2.png" alt=""></p><h2 id="3-4-stream-event监听"><a href="#3-4-stream-event监听" class="headerlink" title="3.4 stream_event监听"></a>3.4 stream_event监听</h2><p>我们先看调用一个 LLM模型会产生哪些事件？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> event <span class="keyword">in</span> llm.astream_events(<span class="string">&quot;你好&quot;</span>, version=<span class="string">&quot;v2&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(event)</span><br><span class="line"><span class="comment"># 调用的话需要通过  asyncio.run() 方法       </span></span><br><span class="line">asyncio.run(async_stream())</span><br></pre></td></tr></table></figure><p>输出如下图：</p><p><img src="/assets/img/ailearn/ai-learn06-3.png" alt=""></p><p>返回<code>event</code>数据结构如下：</p><ul><li><code>event</code>事件类型，如：<code>stream_start</code>、<code>stream_end</code>、<code>stream_chunk</code>等</li><li><code>data</code>事件数据，如：<code>stream_chunk</code>事件数据为<code>chunk</code>，<code>stream_end</code>事件数据为<code>end</code>等</li><li><code>run_id</code>本次调用id，当多次任务并发的时候可以找到对应任务</li><li><code>metadata</code>事件元数据，包括模型版本、模型名称、模型参数等</li><li>其他一些其他信息，如：<code>tags</code>、<code>name</code>、<code>parent_ids</code>等</li></ul><p>完整的事件类型我们可以到 LangChain官方文档去查看，地址为<a href="https://python.langchain.com/docs/how_to/streaming/#using-stream-events">如何使用 Stream Events</a></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过本文我们完整了解 LangChain LCEL流式调用和工作原理，从而为后续使用LangChain进入实际开发提供基础知识。 LCEL主要包含以下内容：</p><ul><li>流式调用方法 <code>stream</code>、<code>astream</code></li><li>调用事件监听 <code>astream_events</code></li><li>输出格式要求 <code>JsonOutputParser</code>等</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一篇文章我们学习&lt;a href=&quot;ttps://qborfy.com/ailearn/ai-learn05.html&quot;&gt;05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉&lt;/a&gt;，对 LangChain实际应用有了基本的了解，接下我们会进入 LangChain最重要的一次学习，就是 LangChain工作流编排原理与实战(LCEL), 学了本文基本上后续 LangChain实际开发都可以独立完成，本文内容较多，建议大家收藏，慢慢学习。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn05.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn05.html</id>
    <published>2025-02-20T07:00:00.000Z</published>
    <updated>2025-03-13T07:58:03.922Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>上一节学习了<a href="https://qborfy.com/ailearn/ai-learn04.html">04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</a>，对Langchain有了基础的认知和简单应用，其中我们使用<code>PromptTemplate</code>去实现一次大模型对话。</p><p>同时我们在<a href="https://qborfy.com/ailearn/ai-learn03.html">03篇 AI从零开始 - Prompt提示语学习与应用</a>也学习了提示语生成规范，但是在结合 LangChain中我们应该如何利用<code>PromptTemplate</code>提示模板+提示语规范去降低 AI幻觉呢？</p><blockquote><p><strong>AI幻觉</strong>, 指人工智能（尤其是大语言模型）生成看似合理但实际错误、虚构或与现实不符的内容的现象。本质是模型在缺乏真实理解能力的情况下，基于统计模式生成的「自信错误」。</p></blockquote><span id="more"></span><p>下面是 Langchain执行一次 LLM 调用的流程图：</p><p><img src="/assets/img/ailearn/ai-learn05-1.png" alt=""></p><h1 id="1-什么是PromptTemplate"><a href="#1-什么是PromptTemplate" class="headerlink" title="1. 什么是PromptTemplate"></a>1. 什么是PromptTemplate</h1><p>提示词模板跟平时大家使用邮件模板、短信模板类型，本质上是一个字符串模板，模板里包含了模板参数，可以通过输入参数来生成最终的提示词。</p><p>一个提示词模板包括以下内容：</p><ul><li>发送给大模型的指令</li><li>一个问答示例，提醒大模型用什么格式返回</li><li>发给大模型的问题</li></ul><h1 id="2-创建提示词模板"><a href="#2-创建提示词模板" class="headerlink" title="2. 创建提示词模板"></a>2. 创建提示词模板</h1><p>可以使用<code>PromptTemplate</code>类来创建一个提示词模板，它接收一个<code>prompt</code>参数，这个参数是一个字符串，用于指定提示词模板。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过一个消息数组创建聊天消息模板</span></span><br><span class="line"><span class="comment"># 数组每一个元素代表一条消息</span></span><br><span class="line"><span class="comment"># 第一个参数是消息角色  system 代表系统消息， 第二个参数代表消息内容</span></span><br><span class="line"><span class="comment"># 消息角色 system 代表系统消息</span></span><br><span class="line"><span class="comment"># 消息角色 human 代表系统消息代表人类</span></span><br><span class="line"><span class="comment"># 消息角色 ai 代表LLM大模型返回的消息内容</span></span><br><span class="line"><span class="comment"># &#123;xxx&#125; 定义 模板参数，如下定义两个模板参数  name代表人工智能名字 user_input 代表用户输入的文本 </span></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是人工智能助手， 你的名字是&#123;name&#125;&quot;</span>), </span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你好&quot;</span>), </span><br><span class="line">        (<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;你好，我是人工智能助手&#123;name&#125;，很高兴为您服务&quot;</span>), </span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过模板参数格式化模板内容</span></span><br><span class="line">message = chat_template.format_messages(name=<span class="string">&quot;小爱同学&quot;</span>, user_input=<span class="string">&quot;你的名字叫什么？&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(message)</span><br></pre></td></tr></table></figure><p>这样子我们就可以得到一个正确的<code>Message</code>了， 如上代码执行结果如下：</p><p><img src="/assets/img/ailearn/ai-learn05-2.png" alt=""></p><p>返回的内容如下说明：</p><ul><li>SystemMessage: 系统设定，设定大模型的角色</li><li>HumanMessage: 人类消息，代表用户输入的消息</li><li>AIMessage: 人工智能消息，代表大模型返回的消息</li></ul><p>LangChain还抽象了其他提示语模版，具体如下：</p><ul><li>PromptTemplate: 普通提示词模板，返回一个字符串</li><li>ChatPromptTemplate: 聊天消息模板，返回一个<code>ChatPromptTemplate</code>对象，可以设定大模型角色和示例</li></ul><h1 id="3-上下文-MessagesPlaceHolder"><a href="#3-上下文-MessagesPlaceHolder" class="headerlink" title="3. 上下文 MessagesPlaceHolder"></a>3. 上下文 MessagesPlaceHolder</h1><p><code>MessagesPlaceHolder</code>主要作用在特定位置添加消息列表(等于占位符)， 可以集中管理消息列表，更好聊天过程注入上下文。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage, AIMessage</span><br><span class="line"></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是人工智能助手&quot;</span>), </span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;msgs&quot;</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 这里我们可以之前的定义的消息列表放在一起</span></span><br><span class="line">msgs=[SystemMessage(content=<span class="string">&#x27;你的名字是小爱同学&#x27;</span>), HumanMessage(content=<span class="string">&#x27;你好&#x27;</span>), AIMessage(content=<span class="string">&#x27;你好，我是人工智能助手，很高兴为您服务&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(chat_template.invoke(msgs))</span><br></pre></td></tr></table></figure><h1 id="4-提示词示例-FewShot"><a href="#4-提示词示例-FewShot" class="headerlink" title="4.提示词示例 FewShot"></a>4.提示词示例 FewShot</h1><p>在之前<a href="https://qborfy.com/ailearn/ai-learn03.html">03篇 AI从零开始 - Prompt提示语学习与应用</a>中也提到过示例的重要性， 这里我们不在说示例对应大模型应用中的重要性了。</p><p>我们看看 在 LangChain中如何讲示例集 给到大模型中，其中<code>FewShot</code>主要作用是给大模型提供示例，让大模型更好的理解用户输入，从而生成更符合用户预期的结果，从而降低 AI 幻觉。</p><blockquote><p>这里可以理解成模型的微小型训练，让大模型能依据我们提供少量示例（有点类似小RAG知识库），从而更加更加准确的答案。</p></blockquote><p>在 LangChain 创建一个示例集，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts.few_shot <span class="keyword">import</span> FewShotPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;谁的寿命更长， 穆罕默德二世还是爱因斯坦？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>: </span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        爱因斯坦活了 76 岁。</span></span><br><span class="line"><span class="string">        穆罕默德二世活了 89 岁。</span></span><br><span class="line"><span class="string">        因此，穆罕默德二世比爱因斯坦活得更长。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;目前电影票房第一名是谁？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        《阿凡达》的票房是 27.9 亿美元。</span></span><br><span class="line"><span class="string">        《复仇者联盟 4：终局之战》的票房是 27.8 亿美元。</span></span><br><span class="line"><span class="string">        因此，《阿凡达》的票房更高。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 这里我们创建一个简单示例模板，用来分析解析示例的 question 和 answer</span></span><br><span class="line">example_prompt = PromptTemplate(input_variables=[<span class="string">&quot;question&quot;</span>, <span class="string">&quot;answer&quot;</span>], template=<span class="string">&quot;问题：&#123;question&#125;\\n答案：&#123;answer&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用 FewShotPromptTemplate 可以根据模板+示例去生成一个拥有示例集的提示语模板</span></span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">    examples=examples,</span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    suffix=<span class="string">&quot;问题：&#123;input&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">&quot;谁的寿命更长， 穆罕默德二世还是爱因斯坦？&quot;</span>))</span><br></pre></td></tr></table></figure><p>输出结果如下：</p><p><img src="/assets/img/ailearn/ai-learn05-2.png" alt=""></p><h1 id="5-示例选择器-ExampleSelector"><a href="#5-示例选择器-ExampleSelector" class="headerlink" title="5. 示例选择器 ExampleSelector"></a>5. 示例选择器 ExampleSelector</h1><p>示例集合等同于一个知识库，在正式环境中我们不可能把完整的知识库都给到模型，因此我们需要去分析用户输入，从而选择合适的示例，LangChain 提供了<code>ExampleSelector</code>类来帮助我们实现这个功能。</p><p>LangChain 提供了不同的<code>ExampleSelector</code>，具体如下：</p><ul><li><code>SemanticSimilarityExampleSelector</code>: 语义相似性示例选择， 会根据用户输入，然后通过嵌入模型计算输入与示例之间的相似性，然后使用向量数据库进行相似搜索，从示例集合中选择最相似的示例。</li><li><code>MaxMarginalRelevanceExampleSelector</code>: 基于 最大边际相关性（MMR） 的示例选择器,  希望在从示例集中选择与输入 既相关又多样化 的示例， 通过平衡 相关性 与 多样性 来优化示例选择效果。</li></ul><p>通常情况下，我们使用<code>SemanticSimilarityExampleSelector</code>， 根据上面示例集合，我们根据问题去选择示例，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ExapleSelector 示例筛选器</span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts.example_selector <span class="keyword">import</span> SemanticSimilarityExampleSelector</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain_ollama.embeddings <span class="keyword">import</span> OllamaEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> FewShotPromptTemplate, PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 引用 shaw/dmeta-embedding-zh 模型做为嵌入模型，其对中文支持度更加友好</span></span><br><span class="line">ollama_emb = OllamaEmbeddings(</span><br><span class="line">    base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, </span><br><span class="line">    model=<span class="string">&quot;shaw/dmeta-embedding-zh&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;谁的寿命更长， 穆罕默德二世还是爱因斯坦？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>: </span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        爱因斯坦活了 76 岁。</span></span><br><span class="line"><span class="string">        穆罕默德二世活了 89 岁。</span></span><br><span class="line"><span class="string">        因此，穆罕默德二世比爱因斯坦活得更长。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;目前电影票房第一名是谁？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        《阿凡达》的票房是 27.9 亿美元。</span></span><br><span class="line"><span class="string">        《复仇者联盟 4：终局之战》的票房是 27.8 亿美元。</span></span><br><span class="line"><span class="string">        因此，《阿凡达》的票房更高。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;深圳第一高楼是哪个？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        深圳平安国际金融中心（平安中心）的楼高是 593米。</span></span><br><span class="line"><span class="string">        深圳京基100的楼高是441.8米。</span></span><br><span class="line"><span class="string">        所以深圳第一高楼是平安国际金融中心。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">example_selector = SemanticSimilarityExampleSelector.from_examples(</span><br><span class="line">    <span class="comment"># 这里是示例集合</span></span><br><span class="line">    examples=examples,</span><br><span class="line">    <span class="comment"># 用户生成嵌入的嵌入类，用于衡量语义的相似度</span></span><br><span class="line">    embeddings=ollama_emb,</span><br><span class="line">    <span class="comment"># 用于计算相似性的向量存储库，这里使用的是 Chroma， 一个保存在内容的向量存储库</span></span><br><span class="line">    vectorstore_cls=Chroma(),</span><br><span class="line">    <span class="comment"># 选择前 k 个最相似的示例 这里设置为 1</span></span><br><span class="line">    k=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">question = <span class="string">&quot;穆罕默德二世？&quot;</span></span><br><span class="line"><span class="comment"># 选择最相似的示例</span></span><br><span class="line">selected_examples = example_selector.select_examples(&#123;<span class="string">&quot;question&quot;</span>: question&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来结合 FewShotPromptTemplate 我们就可以得到更加准备且少量的示例 PromptTemplate</span></span><br><span class="line">example_prompt = PromptTemplate(input_variables=[<span class="string">&quot;question&quot;</span>, <span class="string">&quot;answer&quot;</span>], template=<span class="string">&quot;问题：&#123;question&#125;\\n答案：&#123;answer&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">    <span class="comment"># 这里调整完最相似的示例集合</span></span><br><span class="line">    examples=selected_examples, </span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    suffix=<span class="string">&quot;问题：&#123;input&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=question))</span><br></pre></td></tr></table></figure><p>具体输出效果如下图：</p><p><img src="/assets/img/ailearn/ai-learn05-4.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文我们完整学习了 LangChain 中如何使用 PromptTemplate去更好的创建一个提示语模板，从而降低 大模型的自我创新性（降低AI 幻觉）。</p><p>这里总结一下整个实现过程 约等于 后续 RAG知识库训练过程，如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn05-5.png" alt=""></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一节学习了&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn04.html&quot;&gt;04篇 AI从零开始 - LangChain学习与实战(1) 基础知识&lt;/a&gt;，对Langchain有了基础的认知和简单应用，其中我们使用&lt;code&gt;PromptTemplate&lt;/code&gt;去实现一次大模型对话。&lt;/p&gt;
&lt;p&gt;同时我们在&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn03.html&quot;&gt;03篇 AI从零开始 - Prompt提示语学习与应用&lt;/a&gt;也学习了提示语生成规范，但是在结合 LangChain中我们应该如何利用&lt;code&gt;PromptTemplate&lt;/code&gt;提示模板+提示语规范去降低 AI幻觉呢？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;AI幻觉&lt;/strong&gt;, 指人工智能（尤其是大语言模型）生成看似合理但实际错误、虚构或与现实不符的内容的现象。本质是模型在缺乏真实理解能力的情况下，基于统计模式生成的「自信错误」。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn04.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn04.html</id>
    <published>2025-02-18T07:00:00.000Z</published>
    <updated>2025-02-21T02:19:22.461Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>上一节学习了<a href="https://qborfy.com/ailearn/ai-learn03.html">03篇 AI从零开始 - AI从零开始 - Prompt提示语学习与应用</a>，但是我们发现，Prompt提示语虽然可以让我们得到想要的答案，但是它也有缺点，比如：</p><ul><li>只调用单个大模型的对话提示语来生成答案，且无法验证答案的正确性；</li><li>大模型是没有记忆能力，且有token上下对话长度限制，无法实现多轮对话；</li><li>多步骤推理任务，需要多次调用大模型，效率低下</li></ul><p>如果要开发一个完整 LLM应用，开发者需要手动处理：</p><ul><li>多组件集成：模型调用、外部数据源、记忆存储、业务逻辑等模块的拼接</li><li>上下文管理：对话历史、长期记忆、知识库检索的复杂交互</li><li>流程编排：多步骤推理、条件分支、循环控制等逻辑</li></ul><p>接下来，我们学习一下LangChain，它是一个基于链式调用的LLM框架，可以让我们更加方便地使用大模型，实现多轮对话、多步骤推理等复杂功能。</p><span id="more"></span><h1 id="1-是什么"><a href="#1-是什么" class="headerlink" title="1. 是什么"></a>1. 是什么</h1><blockquote><p>Langchain是开发由大型语言模型（LLMS）提供支持的应用程序的框架。</p></blockquote><p>从我理解的是， LangChain 是一个用于开发大语言模型（LLM）应用的框架，它的核心价值在于简化复杂语言模型应用的开发流程，并提供标准化的工具链。</p><h2 id="1-1-基础功能"><a href="#1-1-基础功能" class="headerlink" title="1.1  基础功能"></a>1.1  基础功能</h2><p>Langchain 提供了以下基础功能：</p><ul><li>LLM调用: 支持调用 OpenAI、Hugging Face、Azure 等主流的 LLM 服务， 同时支持缓存。</li><li>Prompt管理: 拥有大量的文档加载器，比如 PDF、Markdown等</li><li>对索引的支持: 文档分割器，向量化，对接向量存储与搜索，比如 Chroma、Pinecone、Qdrand等 </li><li>Chains链路调用: LLMChain、各种工具Chain等</li></ul><h2 id="1-2-必知概念"><a href="#1-2-必知概念" class="headerlink" title="1.2 必知概念"></a>1.2 必知概念</h2><h3 id="LLM模型和Prompt提示语"><a href="#LLM模型和Prompt提示语" class="headerlink" title="LLM模型和Prompt提示语"></a>LLM模型和Prompt提示语</h3><p>Langchain 针对所有的LLM大模型的 API 进行抽象，统一了大模型访问API，同时也提供了 Prompt 模板管理机制。</p><h3 id="Chain-链"><a href="#Chain-链" class="headerlink" title="Chain 链"></a>Chain 链</h3><p>可以把 Chain 理解为任务。一个 Chain 就是一个任务，当然也可以像链条一样，一个一个的执行多个链。</p><h3 id="LCEL-表达式"><a href="#LCEL-表达式" class="headerlink" title="LCEL 表达式"></a>LCEL 表达式</h3><p>LCEL: LangChain Expression Language，通过表达式解决工作流编排问题，可以灵活自定义 AI任务处理流程，也就是自定义链。</p><h3 id="数据增强生成-RAG"><a href="#数据增强生成-RAG" class="headerlink" title="数据增强生成 RAG"></a>数据增强生成 RAG</h3><p>RAG: Retrieval Augmented Generation，用于增强大模型的知识内容，录入新的信息到大模型中的一种模式。</p><h3 id="Agents-智能体"><a href="#Agents-智能体" class="headerlink" title="Agents 智能体"></a>Agents 智能体</h3><p>Agent其实是大模型的一种应用设计模式，利用 LLM自然语言理解能力和推理能力，去实现用户输入需求自动调用外部系统、设置去共同完成任务。</p><p><img src="/assets/img/ailearn/ai-learn04-1.png" alt=""></p><p>常见的智能体：</p><ul><li>对话机器人，值班客服，智能客服等</li><li>知识库问答，基于某个知识库进行回答</li><li>智能写作，如：创意写作，文本摘要等</li></ul><h3 id="Memory-模型记忆"><a href="#Memory-模型记忆" class="headerlink" title="Memory 模型记忆"></a>Memory 模型记忆</h3><p>LangChain提供一套内存机制，让LLM可以记住对话上下文内容，从而实现模型记忆。</p><h3 id="OutParsesr-输出解释器"><a href="#OutParsesr-输出解释器" class="headerlink" title="OutParsesr 输出解释器"></a>OutParsesr 输出解释器</h3><p>Langchain接收大模型返回文本内容（原始数据基本上是 markdown格式）后，可以使用专门的输出解析器转换数据结果，比如转成 json， 或者转换为 python对象等。</p><h3 id="Vectorstores-向量数据库"><a href="#Vectorstores-向量数据库" class="headerlink" title="Vectorstores 向量数据库"></a>Vectorstores 向量数据库</h3><p>将 Document 文档转换成向量存储，才能进行向量存储。因为大模型只能处理向量，所以需要将文本转换成向量。</p><p>转换成向量也很简单，只需要我们把数据存储到对应的向量数据库中即可完成向量的转换。</p><p>官方也提供了很多的向量数据库供我们使用。</p><blockquote><p><a href="https://python.langchain.com/en/latest/modules/indexes/vectorstores.html">https://python.langchain.com/en/latest/modules/indexes/vectorstores.html</a></p></blockquote><h3 id="Embedding-嵌入"><a href="#Embedding-嵌入" class="headerlink" title="Embedding 嵌入"></a>Embedding 嵌入</h3><p>Embedding（嵌入） 是将文本转化为数值向量（vector）的核心技术，用于捕捉语义信息并实现机器可理解的表示。</p><p>Langchain 提供了多种 Embedding 模型调用，具体可以到官网查看，<a href="https://python.langchain.com/docs/integrations/text_embedding/">Embedding models  嵌入模型</a>。</p><p>更多概念可以到官方文档查看：<a href="https://python.langchain.com/docs/concepts/#concepts">LangChain官方概念指南</a>。</p><h2 id="1-3-基础框架"><a href="#1-3-基础框架" class="headerlink" title="1.3 基础框架"></a>1.3 基础框架</h2><p>LangChain(v0.3版本)的框架图如下：</p><p><img src="/assets/img/ailearn/ai-learn04-2.png" alt="langchain-architecture"></p><p>更加详细说明</p><ul><li>LangChain-Core: 抽象了不同组件和组合在一起的方法，包括：聊天模型、向量存储、工具等核心组件的接口，尽量不依赖其他库。</li><li>LangChain: LangChain对外提供主要入口框架，集成绝大部分功能点。</li><li>Integration packages: 主流库的集成，比如：langchain-openai、langchain-anthropic，这里他们可以自主控制版本，这里可以看到<a href="https://python.langchain.com/docs/integrations/providers/">集成包的信息</a>。</li><li>LangChain-community: Langchain社区提供的工具包，比如：langchain-ollama、langchain-duckduckgo、langchain-google、langchain-bing等。</li><li>LangGraph: 提供给 Langchain 链中更多可扩展性，用于创建常见代理类型的高级接口，以及用于组成自定义流程的底层应用程序接口。</li><li>langServe: 可以让你的链转换为Restful服务暴露给外部系统</li><li>LangSmith: 一个开发人员平台，可让您调试，测试，评估和监视LLM应用程序。</li></ul><h1 id="2-怎么做"><a href="#2-怎么做" class="headerlink" title="2. 怎么做"></a>2. 怎么做</h1><p>为了更好地使用 LangChain，我们先来写一个简单的例子，来了解下 LangChain 的使用流程。</p><h2 id="2-1-安装和初始化项目"><a href="#2-1-安装和初始化项目" class="headerlink" title="2.1 安装和初始化项目"></a>2.1 安装和初始化项目</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">新建目录</span></span><br><span class="line">mkdir ai-learn04-langchain &amp;&amp; cd ai-learn04-langchain</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化venv环境</span></span><br><span class="line">python -m venv venv</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">激活venv环境</span></span><br><span class="line">. venv/bin/activate</span><br></pre></td></tr></table></figure><p>安装后续依赖pip 新建文件<code>requirements.txt</code>，写入以下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">langchain==0.3.19</span><br><span class="line">langchain-community==0.3.17</span><br><span class="line">langchain-ollama==0.2.3</span><br></pre></td></tr></table></figure><p>执行<code>pip install -r requirements.txt</code>安装依赖。</p><h2 id="2-2-第一次调用大模型问答"><a href="#2-2-第一次调用大模型问答" class="headerlink" title="2.2 第一次调用大模型问答"></a>2.2 第一次调用大模型问答</h2><p>新建一个<code>demo1.py</code>文件，写入以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;你是世界级的 AI 技术专家, &#123;input&#125;&quot;</span></span><br><span class="line"><span class="comment"># 这里我们使用一个简单的模板</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    template=template</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建一个简单的链式调用</span></span><br><span class="line">chain = prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行链式调用</span></span><br><span class="line">response = chain.invoke(&#123;</span><br><span class="line">    <span class="string">&quot;input&quot;</span>:<span class="string">&quot;请写一篇关于 AI 的文章，字数不大于 100&quot;</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure><p>输出结果如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn04-3.png" alt="langchain-1"></p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><p>Langchain让我们实现调用一个大模型API 变得更加简单，只需要几行代码就会实现一个简单对话。主要实现逻辑为：</p><ul><li>引入 Langchain 封装好的大模型的库</li><li>创建一个 PromptTemplate 模板</li><li>创建一个链式调用，包括：PromptTemplate | 大模型 | StrOutputParser</li><li>执行链式调用并输出结果</li></ul><blockquote><p>记录问题： 如果我部署的大模型 Langchain 没有找到对应的模型，应该怎么做？</p></blockquote><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一节学习了&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn03.html&quot;&gt;03篇 AI从零开始 - AI从零开始 - Prompt提示语学习与应用&lt;/a&gt;，但是我们发现，Prompt提示语虽然可以让我们得到想要的答案，但是它也有缺点，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只调用单个大模型的对话提示语来生成答案，且无法验证答案的正确性；&lt;/li&gt;
&lt;li&gt;大模型是没有记忆能力，且有token上下对话长度限制，无法实现多轮对话；&lt;/li&gt;
&lt;li&gt;多步骤推理任务，需要多次调用大模型，效率低下&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果要开发一个完整 LLM应用，开发者需要手动处理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多组件集成：模型调用、外部数据源、记忆存储、业务逻辑等模块的拼接&lt;/li&gt;
&lt;li&gt;上下文管理：对话历史、长期记忆、知识库检索的复杂交互&lt;/li&gt;
&lt;li&gt;流程编排：多步骤推理、条件分支、循环控制等逻辑&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来，我们学习一下LangChain，它是一个基于链式调用的LLM框架，可以让我们更加方便地使用大模型，实现多轮对话、多步骤推理等复杂功能。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>03篇 AI从零开始 - Prompt提示语学习与应用</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn03.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn03.html</id>
    <published>2025-02-12T07:00:00.000Z</published>
    <updated>2025-02-13T12:40:45.204Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面我们在<a href="https://qborfy.com/ailearn/ai-learn02.html#more">02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1</a>中学习如何搭建本地大模型，本篇我们学习如何使用Prompt提示语，来让 AI 返回结果更加有符合我们所需要的效果。</p><h1 id="1-Prompt提示语基础学习"><a href="#1-Prompt提示语基础学习" class="headerlink" title="1. Prompt提示语基础学习"></a>1. Prompt提示语基础学习</h1><p>在很多AI学习的文章中，我们都会看到Prompt提示语，那么Prompt提示语是什么，有什么作用呢？</p><p>在OpenAI的官方文档中，对Prompt提示语的解释是：</p><blockquote><p>Prompt: A prompt is a short text that is used to guide the model’s output. It can be used to provide context, specify the desired output format, or even to control the model’s behavior.<br>翻译中文则是“Prompt: Prompt是一种用于指导模型输出的短文本。它可以用于提供上下文、指定所需的输出格式，甚至可以用于控制模型的行为。”</p></blockquote><p>我们简单理解一下，Prompt提示语就是，我们给模型输入一段文本，告诉模型，我们想要什么结果，模型就会按照我们的要求，生成我们想要的结果。</p><span id="more"></span><p>一个规范的提示语，有几个关键的组成部分: </p><ul><li><strong>角色</strong>: 是指希望 AI 在完成任务时所扮演的身份或视角。通过定义角色，可以让 AI 的输出更具专业性、针对性或特定风格。</li><li><strong>上下文</strong>: 是提供给模型的背景信息或对话历史，它像一条线索链，帮助 AI 更好地理解当前任务的关联性和具体要求。</li><li><strong>指令/任务</strong>:  是希望 AI 执行的具体操作的核心陈述。它是提示语的“行动命令”，直接影响输出的方向和形式。</li><li><strong>范例</strong>: 是提示语中最直观的示范材料，它能像教学案例一样具象化你的需求，降低沟通歧义。</li><li><strong>输出格式</strong>: 就像为AI搭建一个展示成果的舞台框架，它决定了信息的组织方式和最终呈现形态。合理设置格式可以提升信息传达效率，尤其适用于需要结构化数据的场景。</li></ul><p>接下来，我们针对不同的提示语分别了解一下提示语不同组成部分的作用。</p><h2 id="1-1-角色"><a href="#1-1-角色" class="headerlink" title="1.1 角色"></a>1.1 角色</h2><h3 id="为什么需要设置角色？"><a href="#为什么需要设置角色？" class="headerlink" title="为什么需要设置角色？"></a><strong>为什么需要设置角色？</strong></h3><p>想象你要拍一部电影：</p><ul><li><strong>无指定角色</strong>：演员自由发挥，可能不符合剧情需求；</li><li><strong>明确角色</strong>：导演指定演员演医生、侦探或喜剧人，表演会更贴合剧本。</li></ul><p>同样，<strong>赋予 AI 角色</strong>相当于让它戴上不同的“职业帽子”，输出效果会有显著差异！</p><hr><h3 id="如何通过角色优化提示语？"><a href="#如何通过角色优化提示语？" class="headerlink" title="如何通过角色优化提示语？"></a><strong>如何通过角色优化提示语？</strong></h3><h4 id="1️⃣-专业型角色"><a href="#1️⃣-专业型角色" class="headerlink" title="1️⃣ 专业型角色"></a>1️⃣ <strong>专业型角色</strong></h4><p>当需要权威性或技术性内容时，可指定专家身份：</p><ul><li>❌ 普通提问：<br>“告诉我如何减肥。”  </li><li>✅ 角色限定：<br>“假如你是营养学教授，为一名BMI超标的上班族制定安全减重方案，需包含饮食、运动和心理调节建议。”</li></ul><h4 id="2️⃣-创意型角色"><a href="#2️⃣-创意型角色" class="headerlink" title="2️⃣ 创意型角色"></a>2️⃣ <strong>创意型角色</strong></h4><p>激发 AI 的故事力或艺术性表达：</p><ul><li>❌ 通用请求：<br>“写一首诗。”  </li><li>✅ 角色+风格：<br>“模仿李白的浪漫主义风格，以‘人工智能与月亮’为主题，写一首七言绝句。”</li></ul><h4 id="3️⃣-中介型角色"><a href="#3️⃣-中介型角色" class="headerlink" title="3️⃣ 中介型角色"></a>3️⃣ <strong>中介型角色</strong></h4><p>让 AI 模拟特定对象的口吻：</p><ul><li>❌ 直白需求：<br>“教孩子刷牙。”  </li><li>✅ 角色转换：<br>“你是一只爱干净的卡通兔子，用儿歌和拟声词教3岁小朋友正确的刷牙步骤。”</li></ul><hr><h3 id="角色的进阶用法"><a href="#角色的进阶用法" class="headerlink" title="角色的进阶用法"></a><strong>角色的进阶用法</strong></h3><ul><li><strong>多重角色协作</strong>：<br>“你既是编剧又是影评人。先为科幻短片《火星幼儿园》写一个大纲，再从观众角度分析它的创新点和风险。”  </li><li><strong>反向角色训练</strong>：<br>“你现在是小学生，我来教你勾股定理。如果我讲解不清楚，请随时提出幼稚的问题。”  </li></ul><hr><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a><strong>注意事项</strong></h3><ul><li>🎯 <strong>角色与目标一致</strong>：避免让诗人写代码，或程序员作抒情诗（除非刻意制造反差）；  </li><li>📝 <strong>细化角色特征</strong>：年龄、行业、性格等描述越具体，输出越生动；  </li><li>🔄 <strong>动态调整角色</strong>：同一对话中可通过指令如“现在切换为经济学家身份”改变 AI 应答模式。</li></ul><hr><h3 id="小练习✨"><a href="#小练习✨" class="headerlink" title="小练习✨"></a><strong>小练习✨</strong></h3><p>优化以下提示语，加入角色设定：<br>❌ 原句：”介绍一下太阳能的好处。”<br>✅ 参考答案：”假设你是环保机构的科普讲师，用通俗易懂的语言向农村老人列举太阳能的3个实际优点，避免使用专业术语。”</p><hr><p>通过角色设定，你能像导演指挥演员一样，精准调动 AI 的能力边界和表达风格🎭。试试给你的下一个提示语“发一张工作证”吧！</p><h2 id="1-2-上下文"><a href="#1-2-上下文" class="headerlink" title="1.2 上下文"></a>1.2 上下文</h2><h3 id="为什么要关注上下文？"><a href="#为什么要关注上下文？" class="headerlink" title="为什么要关注上下文？"></a><strong>为什么要关注上下文？</strong></h3><p>假设你和朋友聊天：</p><ul><li><p><strong>没有上下文：</strong><br>你突然说：”好的，明天见！”<br>朋友会困惑：”明天要见面吗？约在哪里？”</p></li><li><p><strong>有上下文：</strong><br>你先说：”周末想去看电影吗？” → 朋友回复：”好啊，看哪部？” → 你再答：”《奥本海默》怎么样？明晚7点万达影院。” → 最后说：”没问题，明天见！”<br>（通过多轮对话建立清晰的情境）</p></li></ul><p>同理，<strong>AI 需要足够的上下文才能精准回应你的需求。</strong></p><hr><h3 id="如何在提示语中添加上下文？"><a href="#如何在提示语中添加上下文？" class="headerlink" title="如何在提示语中添加上下文？"></a><strong>如何在提示语中添加上下文？</strong></h3><h4 id="1️⃣-单次提问中提供背景"><a href="#1️⃣-单次提问中提供背景" class="headerlink" title="1️⃣ 单次提问中提供背景"></a>1️⃣ <strong>单次提问中提供背景</strong></h4><ul><li><p>❌ 模糊提问：<br>“这段话翻译成英文。”<br>（AI 不知道原文用途、语气或专业术语是否需要调整）</p></li><li><p>✅ 带上下文的提问：<br>“这是一份医疗器械说明书的技术参数部分，请用专业学术英语翻译以下中文段落，保留术语缩写：[附上原文]”  </p></li></ul><h4 id="2️⃣-多轮对话中延续上下文"><a href="#2️⃣-多轮对话中延续上下文" class="headerlink" title="2️⃣ 多轮对话中延续上下文"></a>2️⃣ <strong>多轮对话中延续上下文</strong></h4><ul><li><p>第一轮：<br>“我想写一封辞职信，模板太正式了，能帮我改得温和一些吗？”<br>AI 生成初稿。</p></li><li><p>第二轮：<br>“谢谢！请在结尾加一句‘感谢团队过去三年的支持’，并用口语化词汇替换‘因个人职业规划’这句。”<br>（AI 会根据前文调整，而不是重新生成无关内容）</p></li></ul><h4 id="3️⃣-隐式上下文的利用"><a href="#3️⃣-隐式上下文的利用" class="headerlink" title="3️⃣ 隐式上下文的利用"></a>3️⃣ <strong>隐式上下文的利用</strong></h4><p>即使不主动说明，AI 也会根据输入内容自动推断隐含信息。例如：  </p><ul><li>你输入：”李白是谁？” → AI 默认回答诗人身份。  </li><li>若你输入：”王者荣耀里的李白技能怎么用？” → AI 会自动切换到游戏角色解析。</li></ul><hr><h3 id="上下文的常见误区"><a href="#上下文的常见误区" class="headerlink" title="上下文的常见误区"></a><strong>上下文的常见误区</strong></h3><ul><li><p>🚫 <strong>信息过载</strong>：堆砌无关细节会让 AI 迷失重点。<br>✅ 技巧：只保留与任务强相关的背景。</p></li><li><p>🚫 <strong>断层跳跃</strong>：在多轮对话中突然切换话题而不重置上下文。<br>✅ 技巧：新任务开始时可以说”现在我们需要讨论另一个问题……”</p></li></ul><hr><h3 id="小练习✍️"><a href="#小练习✍️" class="headerlink" title="小练习✍️"></a><strong>小练习✍️</strong></h3><p>优化以下缺乏上下文的 Prompt：<br>❌ 原句：”解释一下量子力学。”<br>✅ 优化后：”我是一名高中生，刚学完原子结构章节，请用比喻和日常例子简单解释量子力学中的‘叠加态’概念。”</p><hr><p>通过合理控制上下文，你可以让 AI 的输出更贴近真实需求，就像给导航软件设定起点和终点一样重要 🌟</p><h2 id="1-3-指令-任务"><a href="#1-3-指令-任务" class="headerlink" title="1.3 指令/任务"></a>1.3 指令/任务</h2><h3 id="指令的本质是什么？"><a href="#指令的本质是什么？" class="headerlink" title="指令的本质是什么？"></a><strong>指令的本质是什么？</strong></h3><p>如果把 AI 比作员工，那么指令就是你布置的工作任务。<br>-<strong>模糊指令</strong> = “整理这份资料”（员工不确定按什么标准分类或呈现）<br>-<strong>清晰指令</strong> = “将会议纪要中的待办事项提取出来，按优先级排序，标记负责人和截止时间”（明确动作、规则、交付形态）</p><h3 id="如何设计有效指令？"><a href="#如何设计有效指令？" class="headerlink" title="如何设计有效指令？"></a><strong>如何设计有效指令？</strong></h3><h4 id="1️⃣-动词先行-结果导向"><a href="#1️⃣-动词先行-结果导向" class="headerlink" title="1️⃣ 动词先行 + 结果导向"></a>1️⃣ <strong>动词先行 + 结果导向</strong></h4><p>直接用动词开头，声明核心任务类型：</p><ul><li>❌ 笼统请求：<br>“关于气候变化的数据。”  </li><li>✅ 明确指令：<br>“对比近十年全球碳排放量变化趋势，用柱状图数据表格展示，标注主要国家增减幅度。”</li></ul><h4 id="2️⃣-区分任务层级"><a href="#2️⃣-区分任务层级" class="headerlink" title="2️⃣ 区分任务层级"></a>2️⃣ <strong>区分任务层级</strong></h4><ul><li><strong>基础操作类</strong>（单一动作）：<br>“将以下英文论文摘要翻译成简体中文。”  </li><li><strong>综合分析类</strong>（多步骤处理）：<br>“阅读这三篇社会学的田野调查报告，总结研究方法共性，批判性分析其样本选择偏差风险。”</li></ul><h4 id="3️⃣-约束条件绑定"><a href="#3️⃣-约束条件绑定" class="headerlink" title="3️⃣ 约束条件绑定"></a>3️⃣ <strong>约束条件绑定</strong></h4><p>附加限制条件缩小任务范围：<br>-“用小学生能理解的比喻，解释区块链原理（不超过100字）”<br>-“生成5条七夕节珠宝促销朋友圈文案，要求押韵，每条附带表情符号🌹💎”</p><h3 id="典型错误与修正"><a href="#典型错误与修正" class="headerlink" title="典型错误与修正"></a><strong>典型错误与修正</strong></h3><table><thead><tr><th><strong>问题类型</strong></th><th>❌ 低效示例</th><th>✅ 优化思路</th></tr></thead><tbody><tr><td><strong>缺少主指令</strong></td><td>“我觉得最近经济形势不太好……”</td><td>➡️ 补全动作：”分析当前CPI上涨对普通人消费的影响，并提出3条省钱建议。”</td></tr><tr><td><strong>多指令混杂</strong></td><td>“总结这本书并推荐类似书籍再写个书评”</td><td>➡️ 分步拆解：<br>1. 用三句话概括《人类简史》核心观点<br>2. 推荐3本同主题著作并说明理由<br>3. 撰写200字幽默风格短评</td></tr><tr><td><strong>指令过泛</strong></td><td>“写一篇关于人工智能的文章”</td><td>➡️ 精准聚焦：<br>1. 用一句话概括人工智能技术发展现状<br>2. 介绍人工智能在医疗、金融、教育等领域的应用<br>3. 分析人工智能对人类社会的影响</td></tr><tr><td><strong>指令过细</strong></td><td>“用表格展示2023年Q4各品类销售数据”</td><td>➡️ 精简概括：<br>1. 用柱状图展示各品类销售额占比<br>2. 用折线图展示销售额变化趋势<br>3. 用饼图展示各品类销售额占比变化趋势</td></tr></tbody></table><h3 id="高阶技巧"><a href="#高阶技巧" class="headerlink" title="高阶技巧"></a><strong>高阶技巧</strong></h3><ul><li><strong>隐性指令传递</strong>：<br>通过示例暗示任务要求（如提供已排版文本让 AI 模仿格式）  </li><li><strong>元指令调控</strong>：<br>预先约定响应规则（例：”所有回答先用一句话总结结论，再用分点论述”）</li></ul><h3 id="小练习"><a href="#小练习" class="headerlink" title="小练习"></a><strong>小练习</strong></h3><p>改写以下模糊指令：<br>❌ 原句：”处理这些客户反馈。”<br>✅ 参考方案：”从2023年Q4投诉邮件中统计出现频率最高的前5类质量问题，用饼图可视化占比，并提出改进措施关键词。”</p><p>清晰的指令如同GPS坐标，能让 AI 准确抵达目的地📍。记住：<strong>不要问AI能做什么，而是告诉TA该怎么做</strong>。</p><h2 id="1-4-范例"><a href="#1-4-范例" class="headerlink" title="1.4 范例"></a>1.4 范例</h2><h3 id="为什么需要提供范例？"><a href="#为什么需要提供范例？" class="headerlink" title="为什么需要提供范例？"></a><strong>为什么需要提供范例？</strong></h3><p>试想两种学习方式：</p><ul><li><strong>纯文字描述</strong>：<br>“画一只猫，要有科技感”</li><li><strong>图文对照</strong>：<br>“参考这张赛博朋克风格的机械猫设计图（附图），保持齿轮关节和荧光线条的特征，但把瞳孔改成三角形”</li></ul><p>显然第二种方式更能锁定预期效果。<strong>范例就是给AI的视觉锚点或样式模板</strong>。</p><h3 id="何时需要使用范例？"><a href="#何时需要使用范例？" class="headerlink" title="何时需要使用范例？"></a><strong>何时需要使用范例？</strong></h3><h4 id="1️⃣-风格迁移"><a href="#1️⃣-风格迁移" class="headerlink" title="1️⃣ 风格迁移"></a>1️⃣ <strong>风格迁移</strong></h4><p>当涉及抽象审美或文体要求时：  </p><ul><li>❌ 语言描述困难：<br>“我想要复古的海报字体”  </li><li>✅ 图片+文字说明：<br>“参照这张1950年代电影海报的字体风格（附图），为咖啡馆店名’旧时光’设计LOGO，保留斑驳纹理但不做褪色处理”</li></ul><h4 id="2️⃣-复杂格式规范"><a href="#2️⃣-复杂格式规范" class="headerlink" title="2️⃣ 复杂格式规范"></a>2️⃣ <strong>复杂格式规范</strong></h4><p>需要结构化输出时：  </p><ul><li>❌ 纯文本要求易出错：<br>“按照学术期刊格式调整参考文献”  </li><li>✅ 提供模板示例：  <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># 目标格式示例：</span></span><br><span class="line">[1] Author A, Author B. Title[J]. Journal Name, 2023, 10(2): 25-30. DOI:xxxx  </span><br><span class="line"><span class="section"># 待处理的原始文献：  </span></span><br><span class="line">Smith J et al. Climate Change Impacts... (后续略)</span><br></pre></td></tr></table></figure></li></ul><h4 id="3️⃣-语义校准"><a href="#3️⃣-语义校准" class="headerlink" title="3️⃣ 语义校准"></a>3️⃣ <strong>语义校准</strong></h4><p>防止专业领域用词偏差：  </p><ul><li>❌ 泛化表述：<br>“写芯片制造工艺的创新点”  </li><li>✅ 对标样例：<br>“仿照下面这段光刻技术突破的描述（附范例），用相同技术文档结构说明3D封装工艺的优势：<br>【范例】极紫外光刻(EUV)通过…实现了线宽微缩至7nm以下…(下略)”</li></ul><h3 id="范例的使用技巧"><a href="#范例的使用技巧" class="headerlink" title="范例的使用技巧"></a><strong>范例的使用技巧</strong></h3><table><thead><tr><th><strong>方法</strong></th><th><strong>应用场景</strong></th><th><strong>实例</strong></th></tr></thead><tbody><tr><td><strong>正反例对比</strong></td><td>明确质量红线</td><td>“广告标语要像例句A这样突出产品功能，避免例句B空洞的情感词”</td></tr><tr><td><strong>渐进迭代</strong></td><td>持续优化输出</td><td>首轮提供基础范例→收到初稿后追加修改意见：”请参考新范例增加数据对比模块”</td></tr><tr><td><strong>跨模态引导</strong></td><td>打通不同表现形式</td><td>上传手绘流程图草图并要求：”将此逻辑转化为PPT图示，配色参考附件企业VI手册”</td></tr></tbody></table><h3 id="注意事项-1"><a href="#注意事项-1" class="headerlink" title="注意事项"></a><strong>注意事项</strong></h3><ul><li>⚠️ <strong>版权风险</strong>：避免直接复制受保护的内容作为范例  </li><li>💡 <strong>适度精简</strong>：关键片段优于完整长文（特殊需求除外）  </li><li>🔄 <strong>动态更新</strong>：长期使用时定期刷新范例以防模型过拟合陈旧模式</li></ul><h3 id="小练习🔧"><a href="#小练习🔧" class="headerlink" title="小练习🔧"></a><strong>小练习🔧</strong></h3><p>优化以下提示语：<br>❌ 原句：”帮我想几句婚礼祝福语”<br>✅ 升级版：  </p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">请模仿这个获奖贺词的排比句式（附范例），创作3句适合长辈致辞的中式婚礼祝福语，每句以&quot;一愿&quot;开头，融入梅兰竹菊意象：</span><br><span class="line"></span><br><span class="line">【范例】</span><br><span class="line">&quot;一愿你策马山河，青春不改凌云志  </span><br><span class="line">二愿你执笔星辰，热血常存赤子心  </span><br><span class="line">三愿你回望征途，笑颜永似少年时&quot;</span><br></pre></td></tr></table></figure><p>用好范例就如同给AI配备了「临摹字帖」，能大幅提升输出质量的稳定性和精确度✨ 下次遇到抽象需求时，记得问自己：<strong>能否找到一个具体参照物来示范？</strong></p><h2 id="1-5-输出格式"><a href="#1-5-输出格式" class="headerlink" title="1.5 输出格式"></a>1.5 输出格式</h2><h3 id="为什么要规定输出格式？"><a href="#为什么要规定输出格式？" class="headerlink" title="为什么要规定输出格式？"></a><strong>为什么要规定输出格式？</strong></h3><p>设想你需要一份报告：</p><ul><li><strong>无格式要求</strong>：<br>AI可能返回杂乱的长段落，关键信息被淹没  </li><li><strong>有格式约束**</strong>:<br>“用Markdown表格对比iPhone14/15参数，分为屏幕、摄像头、电池三列，最后添加优缺点总结栏”</li></ul><p>后者不仅便于快速扫描比较，还能直接复制到文档中使用，节省二次编辑时间。</p><hr><h3 id="常见格式类型及应用"><a href="#常见格式类型及应用" class="headerlink" title="常见格式类型及应用"></a><strong>常见格式类型及应用</strong></h3><table><thead><tr><th><strong>格式类别</strong></th><th><strong>适用场景</strong></th><th><strong>示例指令</strong></th></tr></thead><tbody><tr><td><strong>自然段落</strong></td><td>故事创作、观点阐述</td><td>“用三个连贯段落描述未来城市交通，每段以设问句开头”</td></tr><tr><td><strong>结构化列表</strong></td><td>要点罗列、步骤说明</td><td>“列出5种提高记忆力的科学方法，每个方法含①原理简述②实操步骤③每日耗时”</td></tr><tr><td><strong>表格/图表</strong></td><td>数据对比、参数分析</td><td>“创建对比表显示各省GDP增速，包含排名、省份名称、2022vs2023增长率、变化幅度”</td></tr><tr><td><strong>代码块</strong></td><td>编程辅助、公式展示</td><td>“用Python代码演示线性回归预测房价，要求包含注释和matplotlib可视化部分”</td></tr><tr><td><strong>对话体</strong></td><td>情景模拟、访谈记录</td><td>“编写客服与顾客关于退换货政策的对话，体现专业性与共情力，交替发言至少8轮”</td></tr></tbody></table><hr><h3 id="格式设计四要素"><a href="#格式设计四要素" class="headerlink" title="格式设计四要素"></a><strong>格式设计四要素</strong></h3><h4 id="1️⃣-层次分明"><a href="#1️⃣-层次分明" class="headerlink" title="1️⃣ 层次分明"></a>1️⃣ <strong>层次分明</strong></h4><ul><li>使用标题分级：<br>“# 年度总结\n## 业绩亮点\n### 客户增长”</li><li>添加序号标识：<br>“解决方案分三点呈现：⑴…⑵…⑶…”</li></ul><h4 id="2️⃣-留白控制"><a href="#2️⃣-留白控制" class="headerlink" title="2️⃣ 留白控制"></a>2️⃣ <strong>留白控制</strong></h4><ul><li>限制长度：<br>“每个论点阐述不超过50字”</li><li>空行分隔：<br>“章节之间用—分割”</li></ul><h4 id="3️⃣-标记强化"><a href="#3️⃣-标记强化" class="headerlink" title="3️⃣ 标记强化"></a>3️⃣ <strong>标记强化</strong></h4><ul><li>重点标注：<br>“关键技术名词用<strong>粗体</strong>表示”</li><li>颜色提示（支持渲染的平台）：<br>“盈利数据标为绿色，亏损标红色”</li></ul><h4 id="4️⃣-交互适配"><a href="#4️⃣-交互适配" class="headerlink" title="4️⃣ 交互适配"></a>4️⃣ <strong>交互适配</strong></h4><ul><li>平台兼容：<br>“输出格式兼容微信排版，无需Markdown语法”</li><li>设备优化：<br>“生成适合手机竖屏浏览的信息图文案”</li></ul><hr><h3 id="经典组合技"><a href="#经典组合技" class="headerlink" title="经典组合技"></a><strong>经典组合技</strong></h3><ul><li><strong>格式嵌套</strong>：<br>“先以时间轴形式梳理辛亥革命大事件（年份+事件+影响），再用SWOT分析法总结历史意义”  </li><li><strong>动态格式</strong>：<br>“根据输入内容自动选择最佳呈现方式：争议话题用正反方辩论体，客观知识用问答体”</li></ul><hr><h3 id="避坑指南"><a href="#避坑指南" class="headerlink" title="避坑指南"></a><strong>避坑指南</strong></h3><ul><li>🚫 <strong>过度格式化</strong>：简单的天气查询不需要五级目录  </li><li>✔️ <strong>格式验证</strong>：添加自检指令如”请确保JSON格式有效”  </li><li>🌐 <strong>编码统一</strong>：跨境使用注明”所有计量单位采用公制”</li></ul><hr><h3 id="实训练习📝"><a href="#实训练习📝" class="headerlink" title="实训练习📝"></a><strong>实训练习📝</strong></h3><p>优化下列提示语：<br>❌ 原句：”说说新能源汽车的优点”<br>✅ 格式增强版：  </p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">请按以下框架组织内容：</span><br><span class="line"><span class="section"># 新能源汽车优势分析</span></span><br><span class="line"><span class="section">## 环境效益</span></span><br><span class="line"><span class="bullet">-</span> 减排表现 ▸ 量化数据对比燃油车</span><br><span class="line"><span class="bullet">-</span> 噪音控制 ▸ 城市道路实测分贝值</span><br><span class="line"><span class="section">## 经济效益 </span></span><br><span class="line"><span class="bullet">-</span> 补贴政策 ▸ 2023最新购置税减免额度</span><br><span class="line"><span class="bullet">-</span> 维保成本 ▸ 三年周期预估费用表</span><br><span class="line">► 最后用[❗]符号标注最具颠覆性的创新点</span><br></pre></td></tr></table></figure><p>掌握格式设计就相当于获得了<strong>信息整形术</strong>——同样的内容经过精心排版，价值感知度可提升300%以上。记住：<strong>好的格式不是束缚，而是专业的可视化表达！</strong></p><h1 id="2-Prompt实践应用"><a href="#2-Prompt实践应用" class="headerlink" title="2. Prompt实践应用"></a>2. Prompt实践应用</h1><p>通过上面的讲解，相信大家对Prompt已经有了初步了解，那么接下来，我们通过一个具体的例子， 利用 5 大核心要素去构建一个系统工程化的 Prompt，来帮助大家更好的理解 Prompt 的应用。</p><p>目标： <strong>根据用户输入的关键词， 生成用户所需要的 SQL 语句。</strong></p><h2 id="2-1-角色定位"><a href="#2-1-角色定位" class="headerlink" title="2.1  角色定位"></a>2.1  角色定位</h2><p>对模型的角色定位越精准越好，ta 就越容易理解用户的意图，从而生成更符合用户需求的答案。</p><p>比如这里我们需要生成 SQL 语句，那么我们就可以将模型的角色定位为 <code>SQL 语句生成器</code>，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">您是具有以下能力的专业数据库工程师：</span><br><span class="line">- 准确解析用户业务场景关键词</span><br><span class="line">- 掌握ANSI SQL标准及主流数据库方言</span><br><span class="line">- 熟悉数据库设计范式与性能优化原则</span><br><span class="line">- 具备多表关联查询设计能力</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-2-上下文"><a href="#2-2-上下文" class="headerlink" title="2.2  上下文"></a>2.2  上下文</h2><p>上下文包括用户所操作的数据库的结构信息，如表名、字段等，以及用户的查询意图，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">用户需要快速生成准确SQL语句但可能面临：</span><br><span class="line">1. 不熟悉复杂表关联结构</span><br><span class="line">2. 对特定函数用法不明确(如时间处理函数)</span><br><span class="line">3. 多条件组合逻辑易混淆</span><br><span class="line">4. 需要兼顾查询性能优化</span><br></pre></td></tr></table></figure><h2 id="2-3-指令-任务"><a href="#2-3-指令-任务" class="headerlink" title="2.3 指令/任务"></a>2.3 指令/任务</h2><p>用户将提供一些关键词或者简短的描述，描述他们想从数据库中查询什么信息。系统需要根据这些信息生成正确的SQL查询语句。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">按以下步骤处理用户输入的关键词：</span><br><span class="line">1. 语义解析：识别关键词中的核心要素</span><br><span class="line">   - 操作类型(SELECT/INSERT/UPDATE/DELETE)</span><br><span class="line">   - 目标表/字段</span><br><span class="line">   - 过滤条件(时间范围、状态值等)</span><br><span class="line">   - 排序/分组需求</span><br><span class="line">   - 分页参数</span><br><span class="line"></span><br><span class="line">2. 结构映射：</span><br><span class="line">   a. 自动关联相关表的JOIN条件</span><br><span class="line">   b. 识别VARCHAR字段自动添加引号</span><br><span class="line">   c. 数值型字段保持原生格式</span><br><span class="line">   d. 日期字段转换处理(如STR_TO_DATE)</span><br><span class="line"></span><br><span class="line">3. 逻辑校验：</span><br><span class="line">   - 当检测到危险操作时(如无条件的DELETE)添加警示</span><br><span class="line">   - 对超过3表关联的查询建议索引优化</span><br><span class="line">   - 为模糊查询(%value%)提示性能影响</span><br></pre></td></tr></table></figure><h2 id="2-4-范例"><a href="#2-4-范例" class="headerlink" title="2.4  范例"></a>2.4  范例</h2><p>提供一些示例输入和对应的SQL输出，帮助系统理解任务，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[输入关键词] </span><br><span class="line">&quot;需要最近三个月上海地区单价超过5000元的电子产品订单，按金额降序排&quot;</span><br><span class="line"></span><br><span class="line">[生成SQL]</span><br><span class="line">SELECT </span><br><span class="line">    o.order_id,</span><br><span class="line">    u.user_name,</span><br><span class="line">    p.product_name,</span><br><span class="line">    o.order_amount,</span><br><span class="line">    o.create_time</span><br><span class="line">FROM </span><br><span class="line">    orders o</span><br><span class="line">    JOIN users u ON o.user_id = u.user_id</span><br><span class="line">    JOIN products p ON o.product_id = p.product_id</span><br><span class="line">WHERE </span><br><span class="line">    o.region = &#x27;上海&#x27;</span><br><span class="line">    AND p.category = &#x27;电子产品&#x27;</span><br><span class="line">    AND o.order_amount &gt; 5000</span><br><span class="line">    AND o.create_time &gt;= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)</span><br><span class="line">ORDER BY </span><br><span class="line">    o.order_amount DESC</span><br><span class="line">LIMIT 100;</span><br><span class="line"></span><br><span class="line">[说明]</span><br><span class="line">1. 自动关联三表JOIN</span><br><span class="line">2. 数值条件未加引号</span><br><span class="line">3. 添加LIMIT防止结果集过大</span><br><span class="line">4. 时间条件使用函数动态计算</span><br></pre></td></tr></table></figure><h2 id="2-5-输出格式"><a href="#2-5-输出格式" class="headerlink" title="2.5 输出格式"></a>2.5 输出格式</h2><p>输出格式是对输出数据结构的描述，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[仅返回SQL语句，无需任何额外说明]</span><br></pre></td></tr></table></figure><h2 id="2-6-完整的应用示例"><a href="#2-6-完整的应用示例" class="headerlink" title="2.6 完整的应用示例"></a>2.6 完整的应用示例</h2><p>最终我们得到的 Prompt 如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">您是具有以下能力的专业数据库工程师：</span><br><span class="line">- 准确解析用户业务场景关键词</span><br><span class="line">- 掌握ANSI SQL标准及主流数据库方言</span><br><span class="line">- 熟悉数据库设计范式与性能优化原则</span><br><span class="line">- 具备多表关联查询设计能力</span><br><span class="line"></span><br><span class="line">用户需要快速生成准确SQL语句但可能面临：</span><br><span class="line">1. 不熟悉复杂表关联结构</span><br><span class="line">2. 对特定函数用法不明确(如时间处理函数)</span><br><span class="line">3. 多条件组合逻辑易混淆</span><br><span class="line">4. 需要兼顾查询性能优化</span><br><span class="line"></span><br><span class="line">按以下步骤处理用户输入的关键词：</span><br><span class="line">1. 语义解析：识别关键词中的核心要素</span><br><span class="line">   - 操作类型(SELECT/INSERT/UPDATE/DELETE)</span><br><span class="line">   - 目标表/字段</span><br><span class="line">   - 过滤条件(时间范围、状态值等)</span><br><span class="line">   - 排序/分组需求</span><br><span class="line">   - 分页参数</span><br><span class="line"></span><br><span class="line">2. 结构映射：</span><br><span class="line">   a. 自动关联相关表的JOIN条件</span><br><span class="line">   b. 识别VARCHAR字段自动添加引号</span><br><span class="line">   c. 数值型字段保持原生格式</span><br><span class="line">   d. 日期字段转换处理(如STR_TO_DATE)</span><br><span class="line"></span><br><span class="line">3. 逻辑校验：</span><br><span class="line">   - 当检测到危险操作时(如无条件的DELETE)添加警示</span><br><span class="line">   - 对超过3表关联的查询建议索引优化</span><br><span class="line">   - 为模糊查询(%value%)提示性能影响</span><br><span class="line"></span><br><span class="line">[输入关键词] </span><br><span class="line">&quot;需要最近三个月上海地区单价超过5000元的电子产品订单，按金额降序排&quot;</span><br><span class="line"></span><br><span class="line">[输出]</span><br><span class="line">SELECT</span><br><span class="line">    o.order_id,</span><br><span class="line">    u.user_name,</span><br><span class="line">    p.product_name,</span><br><span class="line">    o.order_amount,</span><br><span class="line">    o.create_time</span><br><span class="line">FROM</span><br><span class="line">    orders o</span><br><span class="line">    JOIN users u ON o.user_id = u.user_id</span><br><span class="line">    JOIN products p ON o.product_id = p.product_id</span><br><span class="line">WHERE</span><br><span class="line">    o.region = &#x27;上海&#x27;</span><br><span class="line">    AND p.category = &#x27;电子产品&#x27;</span><br><span class="line">    AND o.order_amount &gt; 5000</span><br><span class="line">    AND o.create_time &gt;= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)</span><br><span class="line">ORDER BY</span><br><span class="line">    o.order_amount DESC</span><br><span class="line">LIMIT 100;</span><br><span class="line"></span><br><span class="line">[说明]</span><br><span class="line">1. 自动关联三表JOIN</span><br><span class="line">2. 数值条件未加引号</span><br><span class="line">3. 添加LIMIT防止结果集过大</span><br><span class="line">4. 时间条件使用函数动态计算</span><br><span class="line"></span><br><span class="line">[仅返回SQL语句，无需任何额外说明]</span><br><span class="line"></span><br><span class="line">如果你已理解上述要求，请回答是的。</span><br></pre></td></tr></table></figure><p>通过 DeepSeek 输入后我们可以如下所示的结果：</p><p><img src="/assets/img/ailearn/ai-learn03-1.png" alt=""></p><p>当然这个只是 Prompt 的一个简单示例，实际应用中，Prompt 可以包含更复杂的逻辑，比如问题的分类，对答案的二次确认等等，以及结合知识库进行一定范围回答，甚至可以给出多个答案，然后评估答案的可信度，降低 AI 幻觉，后面就涉及到模型微调相关内容。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://www.promptingguide.ai/zh">提示工程指南</a></li><li><a href="https://github.com/dair-ai/Prompt-Engineering-Guide">Prompt-Engineering-Guide 英文原版</a></li><li><a href="https://platform.openai.com/docs/guides/prompt-engineering">OpenAI Prompt工程化</a></li><li><a href="https://platform.openai.com/docs/guides/prompt-generation">OpenAI Prompt生成器</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们在&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn02.html#more&quot;&gt;02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1&lt;/a&gt;中学习如何搭建本地大模型，本篇我们学习如何使用Prompt提示语，来让 AI 返回结果更加有符合我们所需要的效果。&lt;/p&gt;
&lt;h1 id=&quot;1-Prompt提示语基础学习&quot;&gt;&lt;a href=&quot;#1-Prompt提示语基础学习&quot; class=&quot;headerlink&quot; title=&quot;1. Prompt提示语基础学习&quot;&gt;&lt;/a&gt;1. Prompt提示语基础学习&lt;/h1&gt;&lt;p&gt;在很多AI学习的文章中，我们都会看到Prompt提示语，那么Prompt提示语是什么，有什么作用呢？&lt;/p&gt;
&lt;p&gt;在OpenAI的官方文档中，对Prompt提示语的解释是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prompt: A prompt is a short text that is used to guide the model’s output. It can be used to provide context, specify the desired output format, or even to control the model’s behavior.&lt;br&gt;翻译中文则是“Prompt: Prompt是一种用于指导模型输出的短文本。它可以用于提供上下文、指定所需的输出格式，甚至可以用于控制模型的行为。”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们简单理解一下，Prompt提示语就是，我们给模型输入一段文本，告诉模型，我们想要什么结果，模型就会按照我们的要求，生成我们想要的结果。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn02.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn02.html</id>
    <published>2025-02-08T07:00:00.000Z</published>
    <updated>2025-02-12T14:28:19.043Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>之前两篇文章对于 AI 有了初步的了解，但是如何应用 AI 技术呢？去调用 openai 的接口，或者国内的接口都需要付费，而且接口调用次数有限，所以我们需要部署一个本地的大模型，这样就可以自己使用，而且可以自己控制调用次数。正好最近 DeepSeek比较火热，所以我们就在本地尝试部署一下 DeepSeek-R1大模型吧。</p><h1 id="1-了解DeepSeek-R1"><a href="#1-了解DeepSeek-R1" class="headerlink" title="1. 了解DeepSeek-R1"></a>1. 了解DeepSeek-R1</h1><p>在开始之前，我们需要先了解一下 <a href="https://www.deepseek.com/">DeepSeek</a>, 官网介绍是这么写的：</p><blockquote><p>探索未至之境，DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。<br>在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。</p></blockquote><p>同时它开源了几个大模型，主要如下：</p><ul><li><a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1</a>，总参数671B，上下文长度最大支持128K，是在性能对齐 OpenAI-o1 正式版。</li><li><a href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3</a>，DeepSeek 上一代开源大模型。</li></ul><p>因此，作为最新的大模型，DeepSeek-R1 是我们部署的首选。接下来我们继续了解 DeepSeek-R1。</p><span id="more"></span><blockquote><p>2025.01.20 DeepSeek-R1 发布，DeepSeek R1 是 DeepSeek AI 开发的第一代推理模型，擅长复杂的推理任务，官方对标OpenAI o1正式版。适用于多种复杂任务，如数学推理、代码生成和逻辑推理等。<br>根据官方信息DeepSeek R1 可以看到提供多个版本，包括完整版（671B 参数）和蒸馏版（1.5B 到 70B 参数）。完整版性能强大，但需要极高的硬件配置；蒸馏版则更适合普通用户，硬件要求较低</p></blockquote><p>** 蒸馏版：”老师教学生“ 让一个庞大的、复杂的模型（老师）教会一个小巧的模型（学生）如何像自己一样聪明地完成任务。 **</p><p>因此，我们选择部署 DeepSeek-R1 蒸馏版（由于硬件有限，下面部署会使用  32B 的模型），因为这个版本比较适合我们普通用户，而且部署起来比较简单。</p><h1 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2. 准备工作"></a>2. 准备工作</h1><h2 id="2-1-硬件准备"><a href="#2-1-硬件准备" class="headerlink" title="2.1  硬件准备"></a>2.1  硬件准备</h2><p>下面是个人硬件配置，大家可以用来参考即可：</p><ul><li>内存：32GB</li><li>GPU：Tesla T4 16GB</li><li>CPU：32核</li><li>操作系统： tLinux 3.1 </li><li>硬盘：1TB SSD</li></ul><p>网上有很多硬件和模型对比资料， 这里我就不详细介绍了，大家可以自行搜索。不过最低要求是：</p><ul><li>Windows: NVIDIA GTX 1650 4GB 或 AMD RX 5500 4GB，16GB 内存，50GB 存储空间</li><li>Linux: NVIDIA GTX 1660 6GB 或 AMD RX 5500 4GB，16GB 内存，50GB 存储空间</li><li>Mac: M2 MacBook Air（8GB 内存）</li></ul><h2 id="2-2-软件下载-模型下载"><a href="#2-2-软件下载-模型下载" class="headerlink" title="2.2  软件下载+模型下载"></a>2.2  软件下载+模型下载</h2><h3 id="2-2-1-Ollama安装"><a href="#2-2-1-Ollama安装" class="headerlink" title="2.2.1 Ollama安装"></a>2.2.1 Ollama安装</h3><p>主要依赖<code>Ollama</code>本地部署,这里再简单介绍一下  Ollama， 官网介绍如下：</p><blockquote><p>Ollama 是一个开源的本地大语言模型运行框架，专为在本地机器上便捷部署和运行大型语言模型（LLM）而设计。 官网地址为：<a href="https://ollama.com/">https://ollama.com/</a><br>Ollama 是一个基于 Go 语言开发的简单易用的本地大语言模型运行框架。可以将其类比为 docker（同基于 cobra (opens new window)包实现命令行交互中的 list,pull,push,run 等命令），事实上它也的确制定了类 docker 的一种模型应用标准。</p></blockquote><p>后面写一篇文章详细介绍一下其使用方法，目前我们先保持现状即可。</p><p>Linux安装 Ollama命令很简单： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure><p>等待安装完成即可，执行下面命令查看是否安装成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama -h</span><br></pre></td></tr></table></figure><h3 id="2-2-2-模型下载"><a href="#2-2-2-模型下载" class="headerlink" title="2.2.2 模型下载"></a>2.2.2 模型下载</h3><p>可以在 Ollama 官网下载模型，也可以通过 Ollama 命令下载模型，这里我们使用命令下载：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载模型</span></span><br><span class="line">ollama pull deepseek-r1:32b</span><br></pre></td></tr></table></figure><p>这里需要等待一段下载，看网速，一般至少需要几个小时。<br><img src="/assets/img/ailearn/ai-learn02-1.png" alt="alt text"></p><h2 id="2-3-docker安装"><a href="#2-3-docker安装" class="headerlink" title="2.3 docker安装"></a>2.3 docker安装</h2><p>Docker是一个开源的应用容器引擎，可以方便的将应用打包成容器，然后部署到不同的机器上，实现应用的跨平台部署。</p><p>后面大模型 Web UI应用部署会使用到 Docker，因此这里也简单介绍一下 Docker 的安装。</p><p>具体安装步骤可以参考官方教程：<a href="https://docs.docker.com/get-started/get-docker/">https://docs.docker.com/get-started/get-docker/</a></p><p>国内安装可以参考：<a href="https://www.runoob.com/docker/ubuntu-docker-install.html">https://www.runoob.com/docker/ubuntu-docker-install.html</a></p><h1 id="3-部署模型"><a href="#3-部署模型" class="headerlink" title="3. 部署模型"></a>3. 部署模型</h1><p>其实在上一个步骤已经完成模型下载，想要让其运行，则需要进行以下操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动  ollama api服务</span></span><br><span class="line">ollama serve --</span><br><span class="line"><span class="comment"># </span></span><br><span class="line">ollama run deepseek-r1:32b</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="3-1-测试模型服务"><a href="#3-1-测试模型服务" class="headerlink" title="3.1 测试模型服务"></a>3.1 测试模型服务</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:11434/api/generate -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;deepseek-r1:32b&quot;,</span></span><br><span class="line"><span class="string">  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型会返回相关结果</span></span><br></pre></td></tr></table></figure><h2 id="3-2-设置允许其他机器访问"><a href="#3-2-设置允许其他机器访问" class="headerlink" title="3.2 设置允许其他机器访问"></a>3.2 设置允许其他机器访问</h2><p>经过上面的设置，ollama服务已经启动，但是其他机器无法访问，因此需要设置允许其他机器访问，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置允许其他机器访问</span></span><br><span class="line">vim /etc/systemd/system/ollama.service</span><br><span class="line"><span class="comment"># 写入如下内容</span></span><br><span class="line">[Service]</span><br><span class="line">Environment=<span class="string">&quot;OLLAMA_HOST=0.0.0.0:11434&quot;</span></span><br><span class="line"><span class="comment"># 重启 ollama api服务</span></span><br><span class="line">systemctl restart ollama</span><br><span class="line"><span class="comment"># 或者如下命令， 关闭或启动 ollama api服务</span></span><br><span class="line">systemctl stop ollama</span><br><span class="line">systemctl start ollama</span><br></pre></td></tr></table></figure><h1 id="4-可视化UI"><a href="#4-可视化UI" class="headerlink" title="4. 可视化UI"></a>4. 可视化UI</h1><p>有了大模型服务，但是只能在命令窗口里输入聊天感觉不行，那么如何可视化呢？这里推荐一个工具：Dify，官方地址：<a href="https://github.com/langgenius/dify。">https://github.com/langgenius/dify。</a></p><h2 id="4-1-部署-Dify"><a href="#4-1-部署-Dify" class="headerlink" title="4.1  部署 Dify"></a>4.1  部署 Dify</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/langgenius/dify.git</span><br><span class="line"><span class="built_in">cd</span> dify</span><br><span class="line"><span class="built_in">cd</span> docker</span><br><span class="line"><span class="built_in">cp</span> .env.example .<span class="built_in">env</span></span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><p>启动成功后就可以访问了：<a href="http://localhost/install">http://localhost/install</a> 进行配置管理员账号。</p><h2 id="4-2-设置模型供应商"><a href="#4-2-设置模型供应商" class="headerlink" title="4.2 设置模型供应商"></a>4.2 设置模型供应商</h2><p>在右上角找我的头像，点击设置，选择模型供应商，选择 <code>Ollama</code>，添加模型命名为<code>DeepSeek-32B</code>，具体如下：</p><p><img src="/assets/img/ailearn/ai-learn02-2.png" alt="alt text"></p><p>配置完后，就可以开始创建应用，并将模型应用到应用中。</p><h2 id="4-3-创建应用"><a href="#4-3-创建应用" class="headerlink" title="4.3  创建应用"></a>4.3  创建应用</h2><p>在首页创建空白应用 -&gt;  选择聊天助手 -&gt; 进入应用后在右上角选择 <code>DeepSeek-32B</code>模型，就可以开始聊天。</p><p><img src="/assets/img/ailearn/ai-learn02-3.png" alt="alt text"><br><img src="/assets/img/ailearn/ai-learn02-4.png" alt="alt text"></p><p>聊天界面如下：</p><p><img src="/assets/img/ailearn/ai-learn02-5.png" alt="alt text"></p><p>具体聊天效果，响应速度还可以可以的。</p><p><img src="/assets/img/ailearn/ai-learn02-6.png" alt="alt text"></p><p>Dify.AI 还支持很多功能，比如：录入知识库，让聊天助手能基于知识库回答用户的问题，这样子就可以变成智能客服了。其他功能大家都可以自己去摸索，后面 AI 系列学习也会继续介绍。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1官方文档</a></li><li><a href="https://www.cnblogs.com/shanren/p/18702244">必看：DeepSeek-R1本地部署！超详细教程~</a></li><li><a href="https://www.cnblogs.com/shanren/p/18702244">手把手带你用DeepSeek-R1和Ollama搭建本地应用，一文搞定！</a></li><li><a href="https://www.cnblogs.com/shook/p/18700561">DeepSeek-R1本地部署简单使用</a></li><li><a href="https://juejin.cn/post/7278244851041189949">从教师到学生：神奇的“知识蒸馏”之旅——原理详解篇</a></li><li><a href="https://wiki.eryajf.net/pages/97047e/">带你认识本地大语言模型框架Ollama(可直接上手)</a></li><li><a href="https://github.com/ollama/ollama/blob/main/docs">Ollama官方文档</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;之前两篇文章对于 AI 有了初步的了解，但是如何应用 AI 技术呢？去调用 openai 的接口，或者国内的接口都需要付费，而且接口调用次数有限，所以我们需要部署一个本地的大模型，这样就可以自己使用，而且可以自己控制调用次数。正好最近 DeepSeek比较火热，所以我们就在本地尝试部署一下 DeepSeek-R1大模型吧。&lt;/p&gt;
&lt;h1 id=&quot;1-了解DeepSeek-R1&quot;&gt;&lt;a href=&quot;#1-了解DeepSeek-R1&quot; class=&quot;headerlink&quot; title=&quot;1. 了解DeepSeek-R1&quot;&gt;&lt;/a&gt;1. 了解DeepSeek-R1&lt;/h1&gt;&lt;p&gt;在开始之前，我们需要先了解一下 &lt;a href=&quot;https://www.deepseek.com/&quot;&gt;DeepSeek&lt;/a&gt;, 官网介绍是这么写的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;探索未至之境，DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。&lt;br&gt;在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同时它开源了几个大模型，主要如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-R1&quot;&gt;DeepSeek-R1&lt;/a&gt;，总参数671B，上下文长度最大支持128K，是在性能对齐 OpenAI-o1 正式版。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V3&quot;&gt;DeepSeek-V3&lt;/a&gt;，DeepSeek 上一代开源大模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，作为最新的大模型，DeepSeek-R1 是我们部署的首选。接下来我们继续了解 DeepSeek-R1。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>赚钱学习系列 01篇 - 重新认识自己</title>
    <link href="https://www.qborfy.com/money/01.html"/>
    <id>https://www.qborfy.com/money/01.html</id>
    <published>2025-02-08T07:00:00.000Z</published>
    <updated>2025-02-11T09:46:06.376Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://juejin.cn/post/7456417337676595212">程序员的出路</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerli</summary>
      
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="赚钱学习" scheme="https://www.qborfy.com/tags/%E8%B5%9A%E9%92%B1%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>01篇 AI从零开始 - 基础知识和环境准备</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn01.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn01.html</id>
    <published>2025-02-06T07:00:00.000Z</published>
    <updated>2025-02-12T14:29:18.352Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="AI-基础知识"><a href="#AI-基础知识" class="headerlink" title="AI 基础知识"></a>AI 基础知识</h1><p>不管学习什么技术，每个技术里面都会包含一些专业术语， 了解这些术语，有助于我们更好的理解技术，以及更好的使用技术。</p><span id="more"></span><p>针对 AI 领域，我们先从网上找到一篇AI技术应用文章《<a href="https://cloud.tencent.com/developer/article/2420057">使用RAG-GPT和Ollama搭建智能客服</a>》，摘取部分精要内容，如下：</p><blockquote><p>智能文档的在线检索流程可以用一张图说明，上图中展示了一个完整的问答流程：</p><ul><li>用户发起query</li><li>结合Bot实际应用场景，评估是否对query进行rewrite</li><li>Retieval模块根据query检索出Indexing中的相关的文档</li><li>将召回的文档进行Reranking</li><li>并且根据relevance score进行过滤，过滤掉低质的文档</li><li>形成合适的Prompt后输入到LLM大模型中，最后生成答案</li></ul></blockquote><h2 id="术语解释"><a href="#术语解释" class="headerlink" title="术语解释"></a>术语解释</h2><ul><li>LLM大模型：指模型参数量特别大，比如 GPT-4 模型参数量达到了 1750 亿，而 GPT-3 模型参数量只有 175 亿。</li><li>GPT：Generative Pre-trained Transformer，生成式预训练Transformer，是 OpenAI 开发的一种语言模型，可以用于文本生成、文本摘要、文本翻译、文本分类、问答系统等任务。</li><li>Transformer：一种基于注意力机制的神经网络结构，可以用于自然语言处理、语音识别、图像识别等任务。</li><li>RAG：Retrieval-Augmented Generation，检索增强生成，是一种基于检索和生成相结合的文本生成方法，可以用于文本摘要、问答系统等任务。</li><li>知识库：指一个存储大量知识的数据集，可以用于问答系统、文本生成等任务。</li><li>召回：指从大规模数据中找到与查询相关的信息的过程，可以用于问答系统、文本生成等任务。</li><li>Prompt：指一个文本或一个问题的描述，可以用于文本生成、问答系统等任务。</li><li>重写：指对用户输入的query进行一定的修改，以更好地匹配模型，可以用于问答系统、文本生成等任务。</li><li>模型训练：指使用大量数据对模型进行训练，以使其能够更好地完成任务的过程，可以用于机器学习、深度学习等任务。</li><li>Agent：智能体，是一种通用问题解决器。从软件工程的角度看来，智能体是一种基于大语言模型的，具备规划思考能力、记忆能力、使用工具函数的能力，能自主完成给定任务的计算机程序。</li><li>Function Calling：是一种实现大型语言模型连接外部工具的机制。通过 API 调用 LLM 时，调用方可以描述函数，包括函数的功能描述、请求参数说明、响应参数说明，让 LLM 根据用户的输入，合适地选择调用哪个函数，同时理解用户的自然语言，并转换为调用函数的请求参数（通过 JSON 格式返回）。调用方使用 LLM 返回的函数名称和参数，调用函数并得到响应。最后，如果需求，把函数的响应传给 LLM，让 LLM 组织成自然语言回复用户。</li></ul><h2 id="技术框架"><a href="#技术框架" class="headerlink" title="技术框架"></a>技术框架</h2><ul><li>Huging Face: 在模型，数据集和应用程序的机器学习社区，提供了一个非常流行的开源库，名为“Transformers”。这个库最初是以提供各种基于 Transformer 架构的预训练模型（如 BERT、GPT-2、RoBERTa 等）为目的而创建的。随着时间的推移，它已经发展成为一个全面的机器学习库，支持多种语言模型和任务。官网站点为：<a href="https://huggingface.com/">https://huggingface.com/</a></li><li>LangChain: 是一个基于大型语言模型（LLM）开发应用程序的框架，简化了LLM应用程序生命周期的每个阶段。 官网站点为：<a href="https://python.langchain.com/docs/introduction/">https://python.langchain.com/docs/introduction/</a></li><li>Ollama: Ollama 是一个开源的本地大语言模型运行框架，专为在本地机器上便捷部署和运行大型语言模型（LLM）而设计。 官网站点为：<a href="https://ollama.com/">https://ollama.com/</a></li></ul><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h2 id="1-安装-Python"><a href="#1-安装-Python" class="headerlink" title="1. 安装 Python"></a>1. 安装 Python</h2><blockquote><p>Python 是一种高级编程语言，它具有简单易学、易于扩展、丰富的库和工具包等优点，被广泛应用于数据科学、机器学习、Web开发、自动化测试等领域。</p></blockquote><h3 id="1-1-普通安装"><a href="#1-1-普通安装" class="headerlink" title="1.1 普通安装"></a>1.1 普通安装</h3><p>Python 的安装非常简单，只需要在官方网站下载安装包，然后按照提示进行安装即可。以下是安装 Python 的步骤：</p><ol><li>打开 Python 官方网站：<a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li><li>点击 “Downloads” 按钮，进入下载页面</li><li>选择适合自己操作系统的 Python 版本，然后点击 “Download” 按钮</li><li>下载完成后，双击安装包，按照提示进行安装</li><li>安装完成后，打开命令行终端，输入 <code>python --version</code> 命令，如果输出了 Python 的版本号，说明 Python 已经安装成功</li></ol><h3 id="1-2-通过-Anaconda-安装"><a href="#1-2-通过-Anaconda-安装" class="headerlink" title="1.2 通过 Anaconda 安装"></a>1.2 通过 Anaconda 安装</h3><p>Anaconda 是一个开源的 Python 发行版，它包含了 Python 和许多常用的科学计算库，可以方便地安装和管理 Python 环境。</p><p>一般国内选择清华源（<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/），国外选择官方源（https://）。">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/），国外选择官方源（https://）。</a></p><p>Mac或 Linux安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 Anaconda</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2021.11-Linux-x86_64.sh</span><br><span class="line">bash Anaconda3-2021.11-Linux-x86_64.sh</span><br><span class="line"><span class="comment"># 激活 Anaconda</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="comment"># 查看 Anaconda 版本</span></span><br><span class="line">conda --version</span><br></pre></td></tr></table></figure><p>Windows安装则参考这个教程： <a href="https://www.cnblogs.com/ajianbeyourself/p/17654155.html">https://www.cnblogs.com/ajianbeyourself/p/17654155.html</a></p><p>正常开发我建议是使用 Anaconda，因为 Anaconda 会自动管理 Python 环境，方便切换和安装不同的 Python 版本。</p><h2 id="2-安装-PyTorch"><a href="#2-安装-PyTorch" class="headerlink" title="2. 安装 PyTorch"></a>2. 安装 PyTorch</h2><p>PyTorch 是一个基于 Python 的深度学习框架，它提供了丰富的工具和库，可以方便地实现深度学习模型和算法。目前如果需要本地部署大模型的话，建议还是在本地环境安装 PyTorch。</p><p>可以通过pip安装，也可以通过conda安装，这里推荐使用conda安装，因为conda安装会自动管理依赖，方便切换和安装不同的 PyTorch 版本。</p><p>安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 PyTorch</span></span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch</span><br><span class="line"><span class="comment"># 查看 PyTorch 版本</span></span><br><span class="line">python -c <span class="string">&quot;import torch; print(torch.__version__)&quot;</span></span><br></pre></td></tr></table></figure><p>关于 PyTorch的教学文档，可以参考这个文档：<a href="https://datawhalechina.github.io/thorough-pytorch/">https://datawhalechina.github.io/thorough-pytorch/</a></p><h2 id="3-安装-Hugging-Face-Transformers"><a href="#3-安装-Hugging-Face-Transformers" class="headerlink" title="3. 安装 Hugging Face Transformers"></a>3. 安装 Hugging Face Transformers</h2><p>Hugging Face Transformers 是由Hugging Face 创建的深度学习开源框架。 它提供API 和工具来下载最先进的预训练模型，并进一步调整它们以最大限度地提高性能。 这些模型支持不同模式下的常见任务，例如自然语言处理、计算机视觉、音频和多模式应用程序。</p><p>安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 Hugging Face Transformers</span></span><br><span class="line">pip install transformers</span><br><span class="line"><span class="comment"># 查看 Hugging Face Transformers 版本</span></span><br><span class="line">python -c <span class="string">&quot;import transformers; print(transformers.__version__)&quot;</span></span><br></pre></td></tr></table></figure><h2 id="4-安装-Langchain"><a href="#4-安装-Langchain" class="headerlink" title="4. 安装 Langchain"></a>4. 安装 Langchain</h2><p>LangChain 是一种软件框架，旨在帮助创建利用大型语言模型 (LLM) 的应用程序。 LangChain 的优势在于其广泛的集成和功能。 它包括 API 包装器、Web 抓取子系统、代码分析工具、文档摘要工具等。 它还支持 OpenAI、Anthropic、HuggingFace 等现成的大型语言模型以及各种数据源和类型。</p><p>安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 LangChain</span></span><br><span class="line">pip install langchain</span><br><span class="line"><span class="comment"># 查看 LangChain 版本</span></span><br><span class="line">python -c <span class="string">&quot;import langchain; print(langchain.__version__)&quot;</span></span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://learn.microsoft.com/zh-cn/azure/databricks/machine-learning/train-model/huggingface/">什么是 Hugging Face Transformers</a></li><li><a href="https://cloud.tencent.com/developer/article/2422923">一文带你了解大模型——智能体（Agent）</a></li><li><a href="https://learn.microsoft.com/zh-cn/azure/databricks/large-language-models/langchain">用于 LLM 开发的 Azure Databricks 上的 LangChain</a></li><li><a href="https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng">LangChain 的中文入门教程</a></li><li><a href="https://www.langchain.asia/get_started/introduction">LangChain 🦜️🔗 中文网</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;AI-基础知识&quot;&gt;&lt;a href=&quot;#AI-基础知识&quot; class=&quot;headerlink&quot; title=&quot;AI 基础知识&quot;&gt;&lt;/a&gt;AI 基础知识&lt;/h1&gt;&lt;p&gt;不管学习什么技术，每个技术里面都会包含一些专业术语， 了解这些术语，有助于我们更好的理解技术，以及更好的使用技术。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ学习</title>
    <link href="https://www.qborfy.com/test.html"/>
    <id>https://www.qborfy.com/test.html</id>
    <published>2024-09-06T08:21:13.000Z</published>
    <updated>2024-09-06T08:21:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>可以源码安装（python环境）<br>service rabbitmq-server start</p><p>也可以docker安装，依赖docker环境</p><p>运行成功后有两个端口：</p><ol><li>5672，其他客户端调用链接使用</li><li>15672，后台管理系统使用</li></ol><p>支持配置文件，参考docker内配置文件路径： /etc/rabbitmq/conf.d/10-defaults.conf</p><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>virtual host<br>类似mysql支持多个用户访问同一个实例（IP+PORT）的不同数据库</p><p>exchange交换机<br>类似一种邮箱或存储队列，支持加入或转发推送能力</p><h1 id="五种消息类型"><a href="#五种消息类型" class="headerlink" title="五种消息类型"></a>五种消息类型</h1><h2 id="HelloWorld"><a href="#HelloWorld" class="headerlink" title="HelloWorld"></a>HelloWorld</h2><p>正常邮箱类型， 生产者往RabbitMQ队列增加消息，但是消费者不一定要及时看</p><h2 id="Worker模型"><a href="#Worker模型" class="headerlink" title="Worker模型"></a>Worker模型</h2><p>对比 邮箱模型， 只要生产消息 就会马上竞争消费掉，可以有效的避免消息堆积</p><h2 id="订阅模型"><a href="#订阅模型" class="headerlink" title="订阅模型"></a>订阅模型</h2><p>Fanout（广播模型）: 将消息发送给绑定给交换机的所有队列(因为他们使用的是同一个RoutingKey)。</p><p>Direct（定向）: 把消息发送给拥有指定Routing Key (路由键)的队列。</p><p>Topic（通配符）: 把消息传递给拥有 符合Routing Patten(路由模式)的队列。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;p&gt;可以源码安装（python环境）&lt;br&gt;service rabbitmq-server start&lt;/p&gt;
&lt;p&gt;也可以docker安装，依</summary>
      
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>翻译-服务器端请求伪造 (SSRF)</title>
    <link href="https://www.qborfy.com/today_2024/20240814.html"/>
    <id>https://www.qborfy.com/today_2024/20240814.html</id>
    <published>2024-09-06T08:20:08.000Z</published>
    <updated>2024-09-06T08:20:13.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近在研究SSR，发现很多服务都会用到SSRF，所以就顺便研究了一下SSRF。</p><p>下面是一篇从网络上翻译过来的文章， 大家简单参考了解。</p><span id="more"></span><h1 id="什么是-SSRF？"><a href="#什么是-SSRF？" class="headerlink" title="什么是 SSRF？"></a>什么是 SSRF？</h1><p>服务器端请求伪造是一种 Web 安全漏洞，允许攻击者导致服务器端，从而发出非法请求。</p><p>在典型的 SSRF 攻击中，攻击者可能会导致服务器连接到仅供内部使用的服务。在其他情况下，他们可能能够强制服务器连接到任意外部系统。这可能会泄露敏感数据，例如授权凭据。</p><img src="/assets/img/server-side request forgery.svg"><h1 id="SSRF攻击的危害"><a href="#SSRF攻击的危害" class="headerlink" title="SSRF攻击的危害"></a>SSRF攻击的危害</h1><p>SSRF 攻击通常会导致未经授权的操作或组织内的数据访问。这可能位于易受攻击的网站中，也可能位于该网站可以与之通信的其他后端系统上。在某些情况下，SSRF 漏洞可能允许攻击者执行任意命令。</p><p>与外部第三方系统连接，如：接入第三方的登录等， 更容易受到SSRF漏洞攻击。</p><h1 id="常见的SSRF攻击"><a href="#常见的SSRF攻击" class="headerlink" title="常见的SSRF攻击"></a>常见的SSRF攻击</h1><p>SSRF 攻击通常利用信任关系， 去攻击的网站， 并执行未经授权的操作。这些信任关系可能与服务器相关，或者与同一组织内的其他后端系统相关。</p><h2 id="针对服务器的-SSRF-攻击"><a href="#针对服务器的-SSRF-攻击" class="headerlink" title="针对服务器的 SSRF 攻击"></a>针对服务器的 SSRF 攻击</h2><p>在针对服务器的 SSRF 攻击中，攻击者会通过内部络接口向网站的服务器发出 HTTP 请求。这通常涉及提供带有主机名的 URL，例如127.0.0.1 或localhost。</p><p>例如，想象一个购物网站，它允许用户查看特定商店中是否有商品的库存。为了提供信息，网站必须查询各种后端 REST API。它通过前端 HTTP 请求将 URL 当成参数传递到后端，然后执行 API 端点来实现此目的。当用户查看商品的库存状态时，他们的浏览器会发出以下请求：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://stock.weliketoshop.net:8080/product/stock/check%3FproductId%3D6%26storeId%3D1</span><br></pre></td></tr></table></figure><p>这会导致服务器向指定的 URL 发出请求，检索库存状态，并将其返回给用户。</p><p>在此示例中，攻击者可以修改请求以指定服务器本地的 URL：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://localhost/admin</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>服务器获取<code>/admin</code> URL 的内容并将其返回给用户。</p><p>攻击者可以访问<code>/admin</code> URL，但管理功能通常只有经过身份验证的用户才能访问。这意味着攻击者不会看到任何感兴趣的内容。但是，如果对/admin URL 的请求来自本地计算机，则会绕过正常的访问控制。应用程序授予对管理功能的完全访问权限，因为请求似乎源自受信任的位置。</p><p>为什么应用程序会以这种方式运行，并隐式信任来自本地计算机的请求？出现这种情况的原因有多种：</p><ul><li>鉴权控制只在前端网关层控制，却没有在服务器上做任何限制。</li><li>出于容灾设计，允许来自本地的任何用户无需登录即可进行管理访问，只有完全信任的用户会直接来自服务器。</li><li>后管系统与用户系统用不同的端口号，并且用户可能无法直接访问。</li></ul><p>这种信任关系（其中源自本地计算机的请求的处理方式与普通请求不同）通常使 SSRF 成为严重漏洞。</p><h2 id="针对其他后端系统的-SSRF-攻击"><a href="#针对其他后端系统的-SSRF-攻击" class="headerlink" title="针对其他后端系统的 SSRF 攻击"></a>针对其他后端系统的 SSRF 攻击</h2><p>在某些情况下，应用程序服务器能够与用户无法直接访问的后端系统进行交互。这些系统通常具有不可访问的专用 IP 地址。后端系统通常受到网络拓扑的保护，因此它们的安全状况通常较弱。在许多情况下，内部后端系统包含敏感功能，任何能够与系统交互的人都可以在无需身份验证的情况下访问这些功能。</p><p>在前面的示例中，假设后端 URL <a href="https://192.168.0.68/admin">https://192.168.0.68/admin</a> 有一个管理界面。攻击者可以提交以下请求来利用SSRF漏洞，并访问管理界面：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://192.168.0.68/admin</span><br></pre></td></tr></table></figure><h1 id="规避常见的-SSRF-防御"><a href="#规避常见的-SSRF-防御" class="headerlink" title="规避常见的 SSRF 防御"></a>规避常见的 SSRF 防御</h1><p>包含 SSRF 行为以及旨在防止恶意利用的防御措施的应用程序很常见。通常，这些防御措施是可以被规避的。</p><h2 id="具有基于黑名单的输入过滤器的-SSRF"><a href="#具有基于黑名单的输入过滤器的-SSRF" class="headerlink" title="具有基于黑名单的输入过滤器的 SSRF"></a>具有基于黑名单的输入过滤器的 SSRF</h2><p>某些应用程序会阻止包含主机名（如127.0.0.1和localhost或敏感 URL（如<code>/admin</code>的输入，可如下设计：</p><ul><li>使用替代 IP 表示形式127.0.0.1 ，例如2130706433 、 017700000001或127.1等，作为超管系统等别名。</li><li>注册您自己的域名，解析为127.0.0.1 。您可以使用spoofed.burpcollaborator.net来实现此目的。</li><li>使用 URL 编码或大小写变化来混淆被阻止的字符串。</li><li>提供您控制的 URL，该 URL 会重定向到目标 URL。尝试对目标 URL 使用不同的重定向代码以及不同的协议。例如，在重定向过程中从http:切换到https: URL 已被证明可以绕过某些反 SSRF 过滤器。</li></ul><h2 id="具有基于白名单的输入过滤器的-SSRF"><a href="#具有基于白名单的输入过滤器的-SSRF" class="headerlink" title="具有基于白名单的输入过滤器的 SSRF"></a>具有基于白名单的输入过滤器的 SSRF</h2><p>某些应用程序仅允许匹配允许值白名单的输入。过滤器可能会在输入的开头或包含在输入中查找匹配项。您可以通过利用 URL 解析中的不一致来绕过此过滤器。</p><p>URL 规范包含许多在 URL 使用此方法实现即席解析和验证时可能会被忽略的功能：</p><ul><li>您可以使用@字符将凭据嵌入到 URL 中的主机名之前。例如： <code>https://expected-host:fakepassword@evil-host</code></li><li>您可以使用#字符来指示 URL 片段。例如： <code>https://evil-host#expected-host</code></li><li>您可以利用 DNS 命名层次结构将所需的输入放入您控制的完全限定的 DNS 名称中。例如：<code>https://expected-host.evil-host</code></li><li>您可以对字符进行 URL 编码以混淆 URL 解析代码。如果实现过滤器的代码处理 URL 编码字符的方式与执行后端 HTTP 请求的代码不同，则这尤其有用。您还可以尝试双编码字符；一些服务器对它们收到的输入进行递归 URL 解码，这可能会导致进一步的差异。</li><li>您可以结合使用这些技术。</li></ul><h2 id="通过开放重定向绕过-SSRF-过滤器"><a href="#通过开放重定向绕过-SSRF-过滤器" class="headerlink" title="通过开放重定向绕过 SSRF 过滤器"></a>通过开放重定向绕过 SSRF 过滤器</h2><p>有时可以通过利用开放重定向漏洞来绕过基于过滤器的防御。</p><p>在前面的示例中，假设用户提交的 URL 经过严格验证，以防止恶意利用 SSRF 行为。但是，允许 URL 的应用程序包含开放重定向漏洞。如果用于发出后端 HTTP 请求的 API 支持重定向，您可以构造一个满足过滤器的 URL，并将请求重定向到所需的后端目标。</p><p>例如，该应用程序包含一个开放重定向漏洞，其中以下 URL：<code>/product/nextProduct?currentProductId=6&amp;path=http://evil-user.net</code></p><p>返回重定向到：<code>http://evil-user.net</code></p><p>您可以利用开放重定向漏洞绕过URL过滤，利用SSRF漏洞，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://weliketoshop.net/product/nextProduct?currentProductId=6&amp;path=http://192.168.0.68/admin</span><br></pre></td></tr></table></figure><p>此 SSRF 漏洞之所以有效，是因为应用程序首先验证提供的stockAPI URL 是否位于允许的域上（事实确实如此）。然后，应用程序请求提供的 URL，这会触发开放重定向。它遵循重定向，并向攻击者选择的内部 URL 发出请求。</p><h2 id="隐藏的SSRF-漏洞"><a href="#隐藏的SSRF-漏洞" class="headerlink" title="隐藏的SSRF 漏洞"></a>隐藏的SSRF 漏洞</h2><p>如果您可以导致应用程序向提供的 URL 发出后端 HTTP 请求，但后端请求的响应未在应用程序的前端响应中返回，则会出现 隐藏的SSRF漏洞。</p><p>隐藏的SSRF更难利用，但有时会导致在服务器或其他后端组件上完全远程执行代码。</p><h2 id="寻找-SSRF-漏洞的隐藏攻击点"><a href="#寻找-SSRF-漏洞的隐藏攻击点" class="headerlink" title="寻找 SSRF 漏洞的隐藏攻击点"></a>寻找 SSRF 漏洞的隐藏攻击点</h2><p>许多服务器端请求伪造漏洞很容易被发现，因为应用程序的正常流量涉及包含完整URL的请求参数。 SSRF 的其他示例更难找到。</p><h3 id="请求中的部分-URL"><a href="#请求中的部分-URL" class="headerlink" title="请求中的部分 URL"></a>请求中的部分 URL</h3><p>有时，应用程序仅将主机名或 URL 路径的一部分放入请求参数中。然后，提交的值会在服务器端合并到所请求的完整 URL 中。如果该值很容易被识别为主机名或 URL 路径，则潜在的攻击面可能是显而易见的。但是，作为完整 SSRF 的可利用性可能会受到限制，因为您无法控制所请求的整个 URL。</p><h3 id="数据格式中的-URL"><a href="#数据格式中的-URL" class="headerlink" title="数据格式中的 URL"></a>数据格式中的 URL</h3><p>某些应用程序以某种规范传输数据，该规范允许包含数据解析器可能请求该格式的 URL。一个明显的例子是 XML 数据格式，它已广泛用于 Web 应用程序中，用于将结构化数据从客户端传输到服务器。当应用程序接受 XML 格式的数据并解析它时，它可能容易受到XXE 注入的攻击。它还可能容易通过 XXE 受到 SSRF 的攻击。当我们研究 XXE 注入漏洞时，我们将更详细地介绍这一点。</p><h3 id="通过-Referer-标头进行-SSRF"><a href="#通过-Referer-标头进行-SSRF" class="headerlink" title="通过 Referer 标头进行 SSRF"></a>通过 Referer 标头进行 SSRF</h3><p>一些应用程序使用服务器端分析软件来跟踪访问者。该软件通常会在请求中记录 Referer 标头，因此它可以跟踪传入链接。通常，分析软件会访问 Referer 标头中出现的任何第三方 URL。这样做通常是为了分析引用站点的内容，包括传入链接中使用的锚文本。因此，Referer 标头通常是 SSRF 漏洞的有用攻击面。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://portswigger.net/web-security/ssrf">原文地址： 《服务器端请求伪造 (SSRF)》</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近在研究SSR，发现很多服务都会用到SSRF，所以就顺便研究了一下SSRF。&lt;/p&gt;
&lt;p&gt;下面是一篇从网络上翻译过来的文章， 大家简单参考了解。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>重新认识一下cookie —— samesite+secure解决跨域请求cookie问题</title>
    <link href="https://www.qborfy.com/today_2024/20240813.html"/>
    <id>https://www.qborfy.com/today_2024/20240813.html</id>
    <published>2024-08-13T10:00:01.000Z</published>
    <updated>2025-02-05T08:27:07.063Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近在开发微软的Teams应用，在开发过程中遇到了一个跨域请求cookie的问题，具体表现是，当我在Teams应用中登录后，然后通过iframe的方式打开一个第三方网站，第三方网站无法获取到cookie，导致无法登录。这个问题困扰了我很久，最后通过Google找到了解决方案，特此记录一下。</p><span id="more"></span><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>Teams应用是在Teams的iframe中打开的，第三方网站是独立于Teams的，所以是跨域的，当我在Teams中登录后，第三方网站无法获取到cookie，导致无法登录。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol><li>在cookie中设置<code>SameSite</code>属性为<code>None</code>，<code>Secure</code>属性为<code>true</code>，具体代码如下：<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 以下配置为express-session</span></span><br><span class="line"><span class="title function_">session</span>(&#123;</span><br><span class="line">    <span class="attr">cookie</span>: &#123;</span><br><span class="line">        <span class="attr">sameSite</span>: <span class="string">&#x27;none&#x27;</span>,</span><br><span class="line">        <span class="attr">secure</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">httpOnly</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">maxAge</span>: <span class="number">86400</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">proxy</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">name</span>: <span class="string">&#x27;xxxx.sid&#x27;</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></li></ol><p>解决途中遇到的问题：</p><ol><li>如果只设置<code>SameSite</code>属性为<code>None</code>，<code>Secure</code>属性为<code>false</code>，则无法在Chrome浏览器中正常工作，具体表现是 Set-Cookie 请求被浏览器拒绝，具体原因可以参考<a href="https://www.chromium.org/updates/same-site/incompatible-clients">这里</a>。</li><li>当<code>Secure</code>属性设置为<code>true</code>，express-session中没有设置<code>proxy</code>属性，那么express不会返回<code>set-cookies</code> header信息，因为express-session默认是关闭的proxy(反向代理)，打开后才支持<code>x-forwarded-for</code>，具体原因 可以参考<a href="https://github.com/expressjs/session/issues/983">这里</a>。</li><li>express还需要设置<code>app.set(&#39;trust proxy&#39;, 1)</code>，否则无法获取到<code>x-forwarded-for</code>信息，具体原因可以参考<a href="https://github.com/expressjs/session/issues/983">这里</a>。</li></ol><h1 id="浏览器Cookie"><a href="#浏览器Cookie" class="headerlink" title="浏览器Cookie"></a>浏览器Cookie</h1><p>Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。Cookie 主要用于以下三个方面：</p><ul><li>会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）</li><li>个性化设置（如用户自定义设置、主题等）</li><li>追踪用户行为（如广告跟踪、网站分析等）</li></ul><h2 id="如何设置Cookie"><a href="#如何设置Cookie" class="headerlink" title="如何设置Cookie"></a>如何设置Cookie</h2><p>Cookie 通常设置在 HTTP 头中，格式为：<code>Set-Cookie: &lt;cookie名&gt;=&lt;cookie值&gt;</code>，例如：<code>Set-Cookie: name=value</code>。</p><p>Cookie 一般是在后端设置，但也可以在前端设置，例如：<code>document.cookie = &#39;name=value&#39;</code>。</p><h2 id="Cookie的属性"><a href="#Cookie的属性" class="headerlink" title="Cookie的属性"></a>Cookie的属性</h2><p>表格如下：</p><table><thead><tr><th>属性</th><th>作用</th><th>默认值</th><th>示例</th></tr></thead><tbody><tr><td>Name</td><td>Cookie 的名称</td><td>无</td><td>name</td></tr><tr><td>Value</td><td>Cookie 的值</td><td>无</td><td>value</td></tr><tr><td>Domain</td><td>Cookie 所属域名</td><td>当前文档所在域名</td><td>example.com</td></tr><tr><td>Path</td><td>Cookie 所在路径</td><td>当前文档所在路径</td><td>/</td></tr><tr><td>Expires</td><td>Cookie 过期时间</td><td>当前会话</td><td>Thu, 01 Jan 1970 00:00:00 GMT</td></tr><tr><td>Max-Age</td><td>Cookie 过期时间（秒）</td><td>当前会话</td><td>86400</td></tr><tr><td>Secure</td><td>Cookie 是否仅通过 HTTPS 发送</td><td>false</td><td>true</td></tr><tr><td>HttpOnly</td><td>Cookie 是否仅允许 HTTP 进行操作，就是说不允许在前端JS中操作</td><td>false</td><td>true</td></tr><tr><td>SameSite</td><td>Cookie 是否仅通过同一站点发送</td><td>None</td><td>Strict、Lax、None</td></tr></tbody></table><h2 id="Cookie的优先级"><a href="#Cookie的优先级" class="headerlink" title="Cookie的优先级"></a>Cookie的优先级</h2><p>当浏览器同时设置多个同名 Cookie 时，它们的优先级如下：</p><ul><li><code>SameSite=None</code> 优先级高于 <code>SameSite=Strict</code>。</li><li><code>Secure</code> 优先级高于 <code>SameSite</code>。</li><li><code>Domain</code> 优先级高于 <code>Path</code>。</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://www.ruanyifeng.com/blog/2019/09/cookie-samesite.html">Cookie 的 SameSite 属性</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近在开发微软的Teams应用，在开发过程中遇到了一个跨域请求cookie的问题，具体表现是，当我在Teams应用中登录后，然后通过iframe的方式打开一个第三方网站，第三方网站无法获取到cookie，导致无法登录。这个问题困扰了我很久，最后通过Google找到了解决方案，特此记录一下。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>如何优雅的修改依赖的第三方npm包代码 —— patch-package npm补丁工具</title>
    <link href="https://www.qborfy.com/today_2024/20240613.html"/>
    <id>https://www.qborfy.com/today_2024/20240613.html</id>
    <published>2024-06-13T10:00:01.000Z</published>
    <updated>2025-02-05T07:54:52.717Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近在项目开发中遇到一个 npm包的一些 bug，但是这个 npm包的作者并没有修复，联系不上作者。 相信大家在开发中或多或少遇到过，我们正常的解决方案是修改这个 npm包的代码，然后重新发布一个 npm包，但是这样会带来一些问题，比如：</p><ul><li>重新发布npm包，后续这个 npm包所有更新我们都无法获取，因为 npm包变成是我们自己私有的</li></ul><p>经过网络搜索，发现了一个 npm包，叫做 <code>patch-package</code>，可以更加优雅的解决这个问题，所以记录一下。</p><h1 id="patch-package-解决方案"><a href="#patch-package-解决方案" class="headerlink" title="patch-package 解决方案"></a>patch-package 解决方案</h1><p>我们先简单了解一下这个<code>patch-package</code>的主要作用：</p><blockquote><p>立刻修复 npm 包的 bug，而无需修改其源代码 - <a href="https://github.com/ds300/patch-package">patch-package</a></p></blockquote><p>使用步骤如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fix a bug in one of your dependencies</span></span><br><span class="line">vim node_modules/some-package/brokenFile.js</span><br><span class="line"></span><br><span class="line"><span class="comment"># run patch-package to create a .patch file</span></span><br><span class="line">npx patch-package some-package</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit the patch file to share the fix with your team</span></span><br><span class="line">git add patches/some-package+3.14.15.patch</span><br><span class="line">git commit -m <span class="string">&quot;fix brokenFile.js in some-package&quot;</span></span><br></pre></td></tr></table></figure><p>同时需要修改 package.json，添加如下配置：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;scripts&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;postinstall&quot;</span><span class="punctuation">:</span> <span class="string">&quot;patch-package&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>还需要安装<code>patch-package</code>依赖，方便使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i patch-package --save-dev</span><br></pre></td></tr></table></figure><p>后续安装依赖时，会自动执行<code>patch-package</code>，将<code>node_modules</code>中的文件替换为<code>patches</code>中的文件。</p><h1 id="背后原理"><a href="#背后原理" class="headerlink" title="背后原理"></a>背后原理</h1><p>既然解决了问题，那么<code>patch-package</code>是如何实现的呢？</p><p>其实原理相对简单，npm的有个机制叫做</p><h2 id="npm的postinstall"><a href="#npm的postinstall" class="headerlink" title="npm的postinstall"></a>npm的postinstall</h2><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://www.cnblogs.com/operate/p/16363590.html">使用 patch-package 修改第三方模块</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近在项目开发中遇到一个 npm包的一些 bug，但是这个 npm包的作者并没有修复，联系不上作者。 相信大家在开发中或多或少遇到过，我们正</summary>
      
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>《思考，快与慢》，人类到底有多理性？</title>
    <link href="https://www.qborfy.com/study/think-fast-slow.html"/>
    <id>https://www.qborfy.com/study/think-fast-slow.html</id>
    <published>2024-06-10T05:49:34.000Z</published>
    <updated>2024-09-10T05:49:30.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="思考，快与慢"><a href="#思考，快与慢" class="headerlink" title="思考，快与慢"></a>思考，快与慢</h1><p>在书中，卡尼曼会带领我们体验一次思维的终极之旅。他认为，我们的大脑有快与慢两种作决定的方式。常用的无意识的“系统1”依赖情感、记忆和经验迅速作出判断，它见闻广博，使我们能够迅速对眼前的情况作出反应。</p><p>举个例子： 肚子饿了去点菜，我们点很多余点菜，然后吃了一阵子就后悔了，如果我们慢慢规划去点，发现别人都已经吃完走了。</p><p>温馨提醒：本书涉及N多经济学和心理学的专业术语，需要不断查资料去理解其术语的意思，这对经济学、心理学入门有极大的作用。</p><span id="more"></span><h1 id="阅读摘要"><a href="#阅读摘要" class="headerlink" title="阅读摘要"></a>阅读摘要</h1><ul><li>作者介绍<ul><li>丹尼尔·卡尼曼</li><li>以色列和美国双重国籍，2002年诺贝尔经济学奖<ul><li>是因为“把心理学研究和经济学研究结合在一起，特别是与在不确定状况下的决策制定有关的研究”而得奖</li></ul></li></ul></li><li>序言<ul><li>本书的目的：给读者提供更丰富精确的语言来讨论他人乃至自己在判断和决策上的失误，提升发现和理解这些失误的能力。以正确的判断去有效的干预错误，降低错误的预判和决策造成的损失</li><li>研究都是采用对话的形式进行，凭借直觉做出的答案也是共同的，同伴阿莫斯</li><li>第一，人大体而言都是理性的，其想法通常也是合理的</li><li>第二，恐惧、喜爱和憎恨的情感是人们失去理智做出的解释</li><li>可得性法则，解释人们有些事情记得清楚，有些事情却被遗忘</li><li>启发法和成见，往往能让明白有些决策即使是人在理性状态下，也能做出非常愚蠢的选择，因为其认知有限所导致的</li><li>需要明白幸运在每个成功事例中都扮演了重要的角色</li><li>两个人的智慧总要胜过一个人的想法</li><li>本书目标，展示在认知心理学和社会心理学最新发展的基础上展示大脑的工作机制</li><li>直觉思维机制对很多事情都起了很多作用，有积极一面，也有消极一面</li><li>快思考有时候无法解决很多问题，这个时候我们就需要慢思考，投入更多脑力、时间、严谨的思考解决方案</li><li>本书分为五个部分<ul><li>第一部分，通过双系统（系统1：无意识，系统2：受控制的）进行判断和做出决策的基本原理</li><li>第二部分，对判断启发法研究更新，探索了为什么很难具备统计型思维</li><li>第三部分，大脑有说不清的局限，因为对熟悉的事物确信不疑，却无法理解自己的无知程度，无法了解这个世界的不确定性</li><li>第四部分，在决策制定的性质和经济因素为理性的前提下讨论经济的原则</li><li>第五部分，研究两个自我（经验自我和记忆自我）的区别描述，两者有没有共性</li></ul></li></ul></li><li>第一部分 系统1，系统2<ul><li>第一章 一张愤怒的脸和一道乘法题<ul><li>一张愤怒的脸，可以通过直觉分辨出来，无需通过大脑慢慢思考</li><li>一道乘法算法题的过程<ul><li>能提前大概判断某些答案是错误，不是123和12609，可能是568，这就是直觉——快思考</li><li>当你开始使用公式去计算乘法，那就开始慢思考了</li><li>当你计算出结果408或者放弃思考，整个思考过程就结束了</li></ul></li><li>系统1和系统2定义<ul><li>系统1，运行是无意识且快速的，不怎么费脑力，没有感觉，完全处于潜意识状态</li><li>系统2，将注意力转移到需要费脑力的大脑活动上来，例如复杂的运算。系统2的运行通常与行为、选择和专注等主观体验相关联</li></ul></li><li>本书的重点在于研究系统1，虽然大部分的时候我们都处于系统2去做判断选择</li><li>系统1和系统2的分工很明确<ul><li>系统1负责熟悉环境、短期的推测，遇到挑战做出的第一反应也是准确的，但是也很容易犯一些成见的错误</li><li>系统2则持续控制自身，用理性思维去面对一切</li></ul></li><li>系统1和系统2有时候会产生冲突，就等于自主反应的行为， 控制自己的行为是冲突，如：你肚子饿了，想吃饭，但是你要减肥需要控制自己</li><li>系统1给人带来的错误直觉，俗称“认知错觉”<ul><li>缪勒–莱耶错觉图，从视觉上能欺骗你，视觉错误</li><li>如何用系统2去识别认知错觉<ul><li>不能长期的质疑自己的直觉</li><li>学会妥协，学会区别会出现重大错误的场景，在风险很高的时候尽力避免出现错误</li></ul></li></ul></li></ul></li><li>第二章 电影的主角和配角<ul><li>系统1才是主角，而系统2是配角<ul><li>因为系统2的很多行为都是由系统1进行主导的</li></ul></li><li>瞳孔是人类思维活动的灵敏指导器官<ul><li>瞳孔大小会随着努力程度而发生变化</li></ul></li><li>如何使得系统1和系统2平衡，然后让我们的生活更加舒适<ul><li>系统2主要负责重要事情的抉择，不过需要注意系统2如同电表一样是有极限，一旦超过极限就短路，<ul><li>系统2对某件事件的不断练习，那么付出的努力程度就会降低，从而提高某件事情处理效率</li></ul></li><li>系统1主要负责简单判断，只能单一处理事情</li><li>系统2可以处理“多重任务”—— 不仅需要看字，还要数“的”出现的次数</li></ul></li><li>从一个任务转移到另外一个任务的是需要付出努力的，简单的说需要时间适应</li><li>时间制约是人们付出努力的另外一个驱动因素，想要在更短的时间内做出更多的事情</li><li>最轻松的工作方式，就是通过最省力的思维模式去管理大脑活动，不紧不慢的朝目标出发<ul><li>将一个复杂的任务进行拆分成几个简单的任务，变成省脑力的任务</li></ul></li><li>三思而后行，指的就是系统1的直觉可能对的，也可能错的，因此需要经过系统2从头到尾思索一遍</li></ul></li><li>第三章 惰性思维与延迟满足的矛盾<ul><li>最佳散步速度，就是不刺激系统2思考，同时让系统1自然运行起进行思考问题的一种速度</li><li>人的惰性心理，会对付出努力的工作进行正常反抗，需要系统2进行管理后才能集中注意进入努力工作状态<ul><li>当然，并不是所有集中注意的工作都会引起惰性心理反抗</li></ul></li><li>“心流”状态，一种无须做出努力就能集中注意的心理状态，如下：<ul><li>当正在认真画画或写作的时候，会忘记时间，忘记自我，忘记他人的状态</li></ul></li><li>自我控制需要集中注意力，需要付出努力。<ul><li>控制思想和行为是系统2的任务之一。案例如下：<ul><li>又累又饿的面试官很可能否定掉面试offer<ul><li>因为当面试官处于饥饿状态，系统1要求其必须消除饥饿，系统2又要其思考面试者的水平，会发生冲突从而导致面试失败的概率大大提升</li></ul></li></ul></li></ul></li><li>“自我损耗(ego depletion)”，强迫自己去做某件事情，然后途中又面临新的挑战会让你无法自我控制的现象。案例如下：<ul><li>在看一部情感电影的要不准动感情，同时还要按住压力机，会让人无法控制自己</li></ul></li><li>自我损耗的前兆<ul><li>改变日常饮食</li><li>疯狂购物</li><li>反应激烈且带挑衅</li><li>对有把握的任务花费更少的时间</li><li>在做决策的时候表现很糟糕</li></ul></li><li>自我损耗其实是大脑无法同时处理完全不关联的事情导致大脑能量被消耗完（类似短跑后的肌肉内葡萄糖下降），这其中可以通过补充葡萄糖进行状态缓解</li><li>因此结论——当一个人处于疲惫或饥饿的时候，是无法理性处理系统2的任务（面试官会拒绝大部分面试者）</li><li>脱口而出的错误答案，案例：<ul><li>球拍和球一共1.10美元，球拍比球贵一美元，那么球多少钱？</li><li>直觉告诉我们，球是0.1美元，但是一旦经过系统2计算思考后，会发现球0.1美元，那么球拍则是1+0.1=1.10美元，球拍+球=1.20美元，是错误答案</li></ul></li><li>如何避免直觉错误答案呢？<ul><li>先思考一下为什么会出现直觉错误答案？原因在我们不愿意付出过多努力去思考</li><li>避免错误的最佳方式，是需要我们避免思维懒惰，激发思维活跃力，长期对自己的直觉答案保持怀疑，养成习惯后，就会长期处于理性思维状态</li><li>提高自己的控制力，简单的说就是需要将我们的集中更多注意力</li><li>这就是古语“三思而后行”的最佳应用</li></ul></li><li>惰性思考的特点<ul><li>问题1: 今天得到1000美元，1年得到10000美元，你选哪个？<ul><li>其实没有正确答案，重点在于答案是否有被你真正思考过而做出的选择</li><li>直觉答案是10000美元，因为可以获取的更多，但是1年后谁知道会发生什么呢？</li></ul></li><li>更愿意接受系统1给出的答案或选择</li><li>控制力更低，很容易收到诱惑而做出选择</li></ul></li></ul></li><li>第四章 联想的神奇力量<ul><li>联想的连贯性：所有这些都是瞬间发生的，形成一种认知、情感和生理反应的自我强化模式，这种模式变化多样又能形成一个整体<ul><li>简单的说，就是当你看到两个词语，系统1会自动帮你两个词语随意联想在一起，想象出具体的真实画面，然后引发出一系列影响</li></ul></li><li>联想的原则（苏格兰哲学家大卫·休谟）<ul><li>相似性</li><li>时空相接</li><li>因果关系</li></ul></li><li>什么是观点<ul><li>观点就是一张思想巨网的节点，可以被称为联想的记忆</li><li>观点与观点之间相互联结，一个观点的背后关联着无数其他观点</li></ul></li><li>【你觉得你很理解你自己，但是其实你是错误的】—— 你不知道你出现一个观点的背后，联想多少个其他观点<ul><li>有个简单的做法，比如你想减肥，想一想为什么想减肥，是因为想要好身材，想要健康，还是想要拍照发朋友圈，或者其他，然后接着为什么要健康，你会越问越糊涂</li></ul></li><li>启动效应，是联想机制的一种场景效应<ul><li>简单的说，比如：喝_和运动_补充文字，我们都会自然的写【喝汤】【运动场】</li><li>启动效应，等于快速启动联想，也可以引发出【涟漪效应】，从而引起无数心理学家对记忆的进一步理解</li></ul></li><li>涟漪效应<ul><li>启动联想后，大脑的思维就像在池塘里的涟漪一样向外扩展，这就是涟漪效应</li><li>案例：每次吃饭都先喝汤，等到下次要吃饭的时候，就会先等汤做完</li></ul></li><li>佛罗里达效应<ul><li>由一组系列词语想到另外压根没提到过的词语，从而影响到人的行为</li><li>案例：当一群学生正在写生，一部分让其绘画老年人，一部分画年轻人，而绘画老年人的一般行动都会变得慢起来</li></ul></li><li>概念运动效应<ul><li>由行为引起对概念的联想作用</li><li>案例：要求学生每分钟只走30步，由于速度较慢，大部分学生都会想起：老年、健忘等词汇</li></ul></li><li>诚实盒子实验<ul><li>在办公茶厅里，摆放一个自助咖啡机，每次喝咖啡需要放入1美元到盒子中，根据不同日期在盒子上放置【眼睛】或【鲜花】的图片，最终得到结果是：<ul><li>放眼睛的时候诚实盒子里的钱比放鲜花的时候多</li></ul></li><li>结论：一个象征监视符号便可以改善自身的行为，所以系统1对我们的影响往往比我们所想象的更加重要</li></ul></li><li>系统1编了一个故事，系统2相信了，那么我们就OK了<ul><li>保持微笑，能让我们心情会变得更加美丽</li></ul></li></ul></li><li>第五章 你的直觉可能只是错觉<ul><li>认知放松度——用来判断是否需要系统2提供额外帮助到刻度盘</li><li>由记忆造成的错觉<ul><li>错觉一般是从视觉错误引起，但是记忆也会造成错觉</li><li>熟悉感觉有着简单而又强烈的不可复反性，这种不可复返性说明是对过往这种经历的一种直接反应<ul><li>熟悉的特性之一：错觉</li></ul></li><li>引发认知发送和引发认知紧张的方法是相互的，因此造成<ul><li>你不清楚为什么会让认知变得放松或者紧张，是因为这是熟悉感觉造成的</li></ul></li></ul></li><li>什么样的信息更容易让人信服？<ul><li>令人感觉到放松的信息能让人更容易接受</li><li>因为系统 1让人产生熟悉， 系统 2 依据系统 1 的熟悉感去判断</li></ul></li><li>如果某个判断是基于认知放松或者紧张，那么一定会造成错觉<ul><li>任何联想机制运行更加轻松、顺利，都会造成一定的偏见</li></ul></li><li>如果需要写一则需要让人信服的消息，利用认知放松原则去帮助自己，具体做法如下：<ul><li>书写的字体应该正式，与背景色反差较大的更容易信服，如：蓝色、红色大字体</li><li>消息内容应该简洁，同时还要保持易于记忆，如：押韵，更加容易上口，大家都熟悉的知识点等</li><li>消息应该是真实准确的，而不是错误的否则会让你信服度降低</li><li>引入名人名言，可提高更多可信度</li><li>逻辑应该清晰，符合倾听人的信念或偏好，能提高认知放松</li></ul></li><li>股票代码容易读或者记住，更容易获得更高回报率</li><li>自我强化的相互作用也能在认知放松研究中有所体现，如：微笑引起认知放松，皱眉引起的认知紧张<ul><li>认知放松，系统 2 没有介入</li><li>认知紧张，系统 2 开始介入</li></ul></li><li>字体模糊更能让人认知紧张，从而引起系统 2介入，屏蔽系统 1的直觉性答案</li><li>曝光效应，就是让人不断接触到，不断重复，引起放松状态和令人舒心的熟悉感</li><li>只要不断重复接触就能增加喜欢程度的现象，是一个极其重要的生理现象，可推及所有动物身上<ul><li>一个新鲜的刺激，开始是会谨慎，如果对人没有危险，在不断重复接触下，最终就会去掉谨慎</li></ul></li><li>创新是发生在能让人无限联想的环境中的<ul><li>创新与出众的记忆力有关系</li></ul></li><li>认知放松与心情愉悦是相互作用的<ul><li>因为认知放松所以心情愉悦</li><li>因为心情愉悦所以认知放松</li></ul></li><li>因此心情愉悦下做的决策大部分都是认知放松下，系统 1的直觉性的，所以当心情愉悦时候做下的决定，更需要谨慎</li></ul></li><li>第六章 意料之外与情理之中<ul><li>联想机制的不断激活是自动完成，因此系统 2具备某种自动控制记忆和搜索的能力</li><li>从第一次惊喜到第二次的习以为常<ul><li>系统 1 的主要功能：维护并更新你个人世界的思维模式，一种常态的思维模式</li></ul></li><li>惊喜的两种形式：<ul><li>一种是期望会发生 而没法发生的事情</li><li>一种是没有期望，但是突然发生的事情</li></ul></li><li>一件大事必然会带来一些后果，而这些后果也需要一些原因对其作出解释。我们对那天发生的事情所知有限，于是系统1便熟练地将这些知识片段组合成一个连贯的因果关系。</li><li>因果关系并不依存于理性思维，它们是系统1的产物。</li><li>因果性直觉的特点是本书一再出现的主题，因为人们总是很不恰当地将因果性思考用于需要统计论证的情景中。</li><li>统计性思维总是根据事物的不同类别和总体性质得出个案的结论。</li><li>系统1缺乏统计性思维，系统2通过学习可以进行统计性思考</li></ul></li><li>第七章 字母“B”与数字“13”<ul><li>“B”与 “13”的图片展示，表明在不同的环境下，系统 1 会做出不同的判断<ul><li>如果对情况熟悉，那么系统 1  做出的判断，无论对错，都在可以承受的范围内</li><li>如果对情况不熟悉，那么系统 1做出的判断就会冒很大风险，从而犯下直觉错误，这种错误是可以通过系统 2去避免</li></ul></li><li>你做了一个明确的选择，但是却没有意识到自己这样子做了，这就是系统 1的作用<ul><li>系统 1 不会记得放弃几个选择，甚至不记得曾有多个选择</li><li>系统 2的职责是易变和怀疑，有意识的怀疑需要同时在脑子记住多种互不相容的解释</li></ul></li><li>大脑是如何产生信任的<ul><li>系统 1 的自主运作对某个陈述句也会构建出一种最大可能性的解释，如：白鱼吃糖果</li><li>系统 2 的工作是怀疑/不信任，但是当人在疲惫劳累状态，系统 2 往往无法工作，更加容易被说服相信一些空洞的话术</li></ul></li><li>光环效应与群体的智慧<ul><li>光环效应：喜欢一个人，就会喜欢这个人的一切，如：衣着和声音等</li><li>系统 1 可以通过很多比现实更加简单却连贯的方式来表现这个世界</li><li>对一个人的观察顺序是随机，但是顺序却很重要，因为光环效应注重第一印象，而后续信息很大程度被消解了</li><li>老师对学生作业评分也是光环效应的一个例子，这也是为什么应试教育标准答案一直无法改变的原因之一</li><li>如何避免光环效应对我们的影响：<ul><li>采取的避免光环效应的评卷方法遵循了一个普遍原则：消除错误的关联！</li><li>想要从大量证据来源中获取最有用的信息，你应设法使这些来源相互独立。这也是警察办案时所遵循的规则。</li><li>如何节省开会时间，在开始讨论某个问题之前，先让与会的每一位成员各自写下简短的意见<ul><li>避免开放式发言和强势的人意见，使得大部分人都跟随其意见</li></ul></li></ul></li><li>眼见为实的想法让我们仓促做出决定</li><li>联想机制一个最基本的结构特点就是它只能回忆起已被激活的观点。</li><li>衡量系统1是否成功的方法是看它所创造的情境是否具有连贯性，而与故事所需数据的数量和质量关系不大。</li><li>寻找连贯性的系统1和懒惰的系统2相结合，意味着系统2将会赞同许多直觉性的信念，而这些信念又准确地反映了系统1产生的印象。 </li><li>在证据不足到情况下过早下结论对我们理解直觉性思考非常有帮助，一个缩写WYSIATI， “What you see is all there is”</li><li>知道得很少反而可以把已知所有事物都囊括进连贯到思维模式中。</li><li>眼见为实到理念有助于达成连贯性和认知放松的状态，从而让我们相信某个陈述是真实到。</li><li>框架效应、比率忽略等</li></ul></li></ul></li><li>第八章 我们究竟是如何作出判断？<ul><li>系统1以不同的方式运行，不断监视大脑外的一切，提供基本的评估给到直觉性判断，系统2则是调用注意力和通过搜索记忆去寻找答案，提供判断。</li><li>启发法和偏见研究方法的基础理念： 系统1的直觉性判断</li><li>系统1的特点：<ul><li>具备跨维度解读价值观的能力</li><li>没有特定意图的评估一切</li></ul></li><li>直觉性判断可能会影响候选人到底能否成功获得选举<ul><li>自信的微笑 + 方方的下巴</li></ul></li><li>判断启发法，</li><li>与强度等级匹配到描述，是系统1的新能力<ul><li>系统1能根据不同的强度去匹配不同的描述</li><li>如：杀人等于红色，小偷则是浅红色</li></ul></li><li>思维的发散性让我们做出直觉性判断<ul><li>结合思维的强度匹配，就可以解释我们对自己不了解的事情可以作出直觉性判断</li></ul></li></ul></li><li>第九章 目标问题与启发性问题形影不离<ul><li>面对很多事情或者问题，我们都能很快有直觉的想法，也能作出答案</li><li>因为我们针对一些没有遇到的问题或者更加复杂的问题，去想类似更加简单的问题去回答</li><li>这就是启发法，而针对目标问题，我们总能想到其相关到启发式问题（更简单的问题）</li><li>用一个更加简单到问题替代原来复杂到问题，是一个解决难题到好策略</li><li>思维的发散性可以使懒惰到系统2摆脱繁重的工作，快速找到难题的答案<ul><li>如何理解这一点，思维的发散性就是让人产生联想，从而启发到更多的可能性</li></ul></li><li>立体启发法： 远处到物体看上去更高大<ul><li>立体大小替代平面大小氏自主发生的</li></ul></li><li>同用的问题，通过顺序替换就可以得到不一样的关联关系<ul><li>你最近幸福吗？ 你上个月约过多少次约会？ —— 幸福与约会次数无关</li><li>你上个月约过多少次约会？ 你最近幸福吗？ —— 幸福与约会次数成正比</li></ul></li><li>情感启发式：因为喜欢，所以认同<ul><li>为什么喜欢了就会认同，是因为系统2虽然是最高决策地位，可以抵制系统1的建议，但是更多时候系统2是系统1的赞许者而不是批评者，</li><li>系统2搜索记忆和复杂计算的启发，都是源自系统1</li></ul></li></ul></li><li>第一部分总结：<ul><li>系统1自主快速运行，只需要付出较少努力，甚至不需要努力思考，没有自主控制的感觉</li><li>有时候用简单点到问题替代难题（启发法）</li><li>为联想记忆激发出来到各种想法创造连贯形式</li><li>系统2的长期思考训练会形成系统1的直觉反应</li><li>真正去计算，而不是空想（思维发散性）</li></ul></li></ul></li><li>第二部分 启发法与偏见<ul><li>第十章 大数法则与小数定律<ul><li>系统1非常擅长一种思维模式，自动且毫不费力地识别事物之间的因果关系，即使这种关系根本不存在</li><li>系统1对于纯统计学到数据时候是束手无策的</li><li>一个随机事件是不需要解释的，但一连串的随机事件就有规律可循</li><li>大数法则是大样本的数据比小样本的数据得出规律更加精确，但是为什么更精确的原因是什么？</li><li>小样本到出错风险可能高达50%</li><li>评估大样本和小样本的依据是什么？需要用到统计学的相关知识去确定样本数据的数量和范围</li><li>小数定律指的是随机取样的直觉会让数据更加容易找到定律，从而断言大数法则复合小数定律<ul><li>简单的说，就是从小数获取到的定律，让人盲目相信即使使用大数据去统计也能得到相同到规律</li></ul></li><li>信任多于质疑到普遍性偏见<ul><li>人们对于样本大小没有足够的敏感性</li><li>因为系统1并不善于质疑</li><li>小数定律就是普遍性偏见到一种表现，就是对事物的信任大于质疑，从而导致就是相信小样本数据能反映调查对象的整体情况</li></ul></li><li>对随机事件作出因果解释必然是错的<ul><li>联想机制是会搜寻原因的，即使这个是错误的</li><li>对于随机性的广泛误解有时会带来重大影响</li></ul></li><li>小数定律包含在大脑工作的两个重要部分：<ul><li>夸大对小样本的信任只是众多错觉中一种</li><li>对偶发事件做出因果关系解释必然是错误的</li></ul></li></ul></li><li>第十一章 锚定效应在生活中随处可见<ul><li>什么是锚定效应<ul><li>人们在对某一未知的特殊价值进行评估之前，总会事先对这个量进行一番考量</li><li>例子：下高速后会保持一段时间高速行驶</li></ul></li><li>为什么会有锚定效应，因为对锚定值的调整通常是不足的</li><li>如：孩子会把音乐调很大声，家长却觉得很吵闹，这是因为家长忽视了孩子的真心需要，自己需要作出调整，对音乐的锚定值作出调整</li><li>什么是调整？ 调整就是刻意去寻找离开锚定数字的理由，而且是一项需要付出努力的活动</li><li>调整不足是软弱或者懒惰的系统 2 的一种失误</li><li>暗示是一种锚定效应，是一种启动效应，当你开始联想记忆，就会启动系统 1 去选择性激活从而产生一些误差</li><li>锚定效应的两种类型：<ul><li>研究手法</li><li>理论观念</li></ul></li><li>系统 1 试图建立一个将锚定数字视为真实数值的世界</li><li>选择性记忆激发解释了锚定效应，如大小不同的数字能激发起记忆中不同的观念体系</li><li>锚定效应在生活中的应用：<ul><li>如何给商品定价，能让商品价格更符合客户的接受程度</li><li>如何给拍卖物品定价</li><li>…</li></ul></li><li>如何确定锚定效应的适应性：<ul><li>锚定效应解释了饥饿营销的有效性，也就是限量销售</li><li>抵制锚定效应在商品谈价中的影响，激活系统 2 中的记忆来抵制锚定效应，简单的说就是通过搜索大脑关于商品的定价，减少因为锚定效应导致的数字影响</li></ul></li><li>随机锚定效应让我们更加了解系统 1 和系统 2 之间的关系<ul><li>判断选择是锚定效应的结果，因为虽然判断选择是从系统 2 完成的，却是依据系统 1 进行自主的无意识的运行，而系统 1 是很容易受锚定效应影响，影响是因为某些记忆更容易让人回想，这也是为什么广告词需要更让人容易记住</li></ul></li><li>如何利用锚定，引导锚定的影响，让我们更好的思考：<ul><li>放大锚定效应的影响，任何数字都可以会影响你，所以你需要抵抗一些常见数字</li><li>如：炒股中，中国人最受影响的是 6、8 或者 5 整数倍数，看来起来更加友好的数字，那么你不应该买这类数字结尾的，如同对 4 数字的不友善，反而更应该接受，或者其他随机数字，同时你需要观察收盘的数字，观察主力对数字的敏感度</li></ul></li><li>锚定效应的使用，给对方一些锚定值，不单单只是数字，还包括一些方案，同时要抵抗对方给到我们的一些锚定效应影响，去反向思考一些可能性</li></ul></li><li>第 12 章 科学地利用可得性启发法<ul><li>什么是可得性启发法？<ul><li>估计某类事件出现的频率，大脑是怎么运作的，就是启发法</li><li>从记忆中搜寻这类问题的实例，以搜索过程的轻松程度判断概率的可过程，叫做可得性启发法</li></ul></li><li>轻松，需要大脑搜索多少个实例为标准</li><li>可得性启发法，用一个问题替代另外一个问题，用来作为决策的判断依据</li><li>意识到自己的偏见有利于团队的关系融洽，如何理解？<ul><li>可得性偏见，如：明星出轨、飞机意外、亲身经历的图片等</li><li>抵抗这么多偏见会让你身心俱疲，因此所有的偏见都不是坏的，有些偏见更加有利于关系融洽，如：夫妻评价对方</li></ul></li><li>可得性偏见影响我们对自己，或者他人的看法<ul><li>自我评估是由事件呈现在脑海中轻松程度来衡量</li></ul></li><li>可得性偏见是一种心里悖论，对事情越有意见，表示也看重这个事情<ul><li>学生对课堂的建议越多，对课堂评价越高</li></ul></li><li>判断涉及自身情况的人往往更有可能关注他们从记忆中提取的事件数量，对轻松程度不太关注</li><li>我没有满世界做民意调查来告诉自己怎么做才对，知道自己的感受就够了</li><li>可得性启发表明，对直觉的依赖只是个人品行特征的一部分，提醒人们，相信人品等于相信人们对于自己的直觉</li></ul></li><li>第 13 章 焦虑情绪与风险政策的设计<ul><li>可得性效应，能解释对买保险后的行为模式和灾难后的保护性行为模式，如：每次灾难后，人们都会去买保险或者做一些预防行为去形成自我保护和减少损失</li><li>问题：被闪电击中和食物中毒哪个意外致死率更高？<ul><li>计算概率，直觉性思维会觉得食物中毒概率会更高，但是事实却是闪电击中后的致死概率是中毒的两倍以上</li></ul></li><li>作出判断或决策会受情绪影响，如：喜欢、恨、感觉强烈程度等等因素<ul><li>情绪启发是替代问题回答思维模式的一种，如：简单的问题是我对它感觉如何，而情绪启发思维模式往往会让你回答，我对它的评价如何？</li></ul></li><li>可以通过一些知识传播影响人们的感性认知，从而影响人们对某项技术的风险判断，如：发布会的宣讲等等</li><li>如何避免小概率的风险事件变成公共危机？<ul><li>人们是感性而非理性，容易被琐碎细节左右，如：当专家提出与非专业性判断有偏差的时候，应当遵从“双方必须尊重对方的见解和智慧”，因为风险是客观的</li><li>还有一种观点是， 专家是抵制大众越轨的壁垒，从而导致政府提出一些政策对风险的认知有偏差，而这种政策就叫偏见植入政策，专业术语是“效用叠层”</li></ul></li><li>效用叠层，是一连串的自持事件，可能开始于相对次要的媒体报道，从而引发群众恐慌和大规模政府行动<ul><li>简单的理解，就是由于政府对于大众理解有偏差，出台一系列不符合政策，被媒体一开始报导后引发的一系列事件</li><li>根本原因在于政策定制者不能代表大众的利益，忽略普遍存在的大众情绪思维，从而引发大众抵制政府出台的决策</li><li>效用叠层的现象就是媒体大肆报导和宣扬那些还没有真正发生的事情</li></ul></li></ul></li><li>第 14 章 猜一下，汤姆的专业是什么<ul><li>简单的问题：汤姆的专业是工商管理、计算机、法学、医学、社会科学等？<ul><li>大脑直觉思路，根据专业招生规模去统计，判断最有可能的概率选择，这就是基础概率比较</li></ul></li><li>依据典型性作出预测是下意识的行为<ul><li>在有典型性描述的证据，大家都会忽略基础概率的比较，比如：刻意描述汤姆的性格更加偏向理科，那么我们的大脑会忽略基础概率比较，直接偏向理科专业</li></ul></li><li>去解释某个词的含义是比较困难的</li><li>通过典型性去做判断决策是正常的，但却不是最优选择（站在统计学的角度）</li><li>典型性启发的两个错误：<ul><li>过于偏向预测不可能发生的事情，如：在地铁里阅读书籍的人，是有博士学位，还是没大学文凭的人</li><li>对证据或数据的质量不够敏感，如：没有被验证的描述的汤姆语句会影响我们对汤姆专业的判断</li></ul></li><li>如何避免典型性判断思维<ul><li>用贝叶斯定理去约束思维模式</li><li>基础比较概率非常重要，即使目前已有证据</li><li>质疑你对证据的分析</li></ul></li></ul></li><li>第15章 琳达问题的社会效应<ul><li>琳达的描述让其看起来更像一个女权主义者，而不是银行出纳<ul><li>因此给出的选择中：<ul><li>银行出纳</li><li>一个女权主义的银行出纳</li></ul></li></ul></li><li>正常思维下，我们往往会选择【一个女权主义的银行出纳】，但是这个的概率往往会比【银行出纳】的概率低<ul><li>这又违反了概率思维的逻辑</li></ul></li><li>这种思维模式，叫做“合理谬误”<ul><li>这也是典型性判断和概率性判断最佳实践案例，典型性判断更符合大脑思维</li><li>人们更加愿意相信更加详细描述的情节，如：<ul><li>马克有长头发</li><li>马克有金色的长头发</li></ul></li></ul></li><li>少即是多的逻辑悖论<ul><li>A套餐具比B套餐具多了几个，但是B套餐具是完整，所以哪怕A套价格低，数量更多，那么大多数人会更加愿意选择B套</li><li>这个逻辑同时也解释了为什么大家更加愿意选择【琳达是女权主义的银行出纳】，因为大家更加愿意相信完整的信息</li><li>背后的也是因为系统2的惰性，导致我们大脑直接通过系统1直觉判断的原因存在</li></ul></li><li>在实际生活，关注弱点是辩论中非常重要的思维模式， 也是律师辩论去让证人受到怀疑<ul><li>一个非常贵重的东西，赠送一个便宜的东西，那么这个东西也就没那么贵重了</li></ul></li></ul></li><li>第16章 因果关系比统计学信息更有说服力<ul><li>案例：一个证人说肇事车辆为蓝色，证人正确概率为80%，而数据统计：绿色车辆占85%，蓝色车辆占15%，那么肇事车辆是蓝色的概率为多少？<ul><li>正常思维，相信证人的概率， 忽略基础数据的概率， 得出概率80%</li><li>基于贝叶斯公式：P(A|B) = P(A|B)*P(B)/P(A)，应该结合两者的概率去计算，同时需要第三者统计概率为：证人说法得到验证为正确率<ul><li>P(A)为 正常情况无证人下，车子为蓝色正确率15%</li><li>P(A|B)为 证人说法得到验证为正确率 80%</li><li>P(A) 为 所有证人说法得到验证为正确率</li></ul></li></ul></li><li>因果关系基础比率会改变人的看法<ul><li>如：车子为绿色肇事概率为85%，那么你会觉得绿色车肇事概率更高</li></ul></li><li>忽略统计基础概率，有了因果关系概率后，就会更加容易忽略</li><li>因果关系有说服力，是因为我们有思维定式<ul><li>思维定式=系统1在大脑形成的范畴规范和原型范例</li><li>系统1更加适应因果关系的，更容易处理因果关系的事情</li></ul></li><li>我们并没有想象中那么乐于助人<ul><li>容易赋予个人典型特征</li><li>情境容易影响一个人的思想结果</li><li>受试者不愿从普遍现象中推导出特殊性，如同他们愿意相信从特殊性归纳出普遍性</li></ul></li><li>用因果关系进行解释统计学结果对想法的影响更大</li><li>因此，统计学信息的结果难以影响大家，但是它会变成普遍规律的可信过程中</li></ul></li><li>第 17 章 所有表现都会回归平均值<ul><li>技能训练原则：奖励良好表现比错误惩罚更有用<ul><li>教练的反对观点：惩罚做的不好比奖励良好表现更有用，因为惩罚后，下一次的表现会变得更好</li></ul></li><li>原因：<ul><li>因为教练把随机的良好表现与因果解释关联在一起</li><li>表现好的不是固定的，而表现不好是因为下一次有进步空间，这和奖励惩罚没有任何关系</li></ul></li><li>思维窘境：人类环境中一个意义重大的事实：生活给予我们的反馈常常违背常理。<ul><li>正常生活思维，当有人对我们好，我们也会对其友好， 但是当有人对我们不好，我们也会对其不好。</li><li>但是从统计学角度看结果，却是对人好得到惩罚，对人不好得到奖励</li></ul></li><li>第一次表现与第二次表现没有关系<ul><li>因为从多次表现去统计，所有的结果都是回归平均值，这就是回归效应</li></ul></li><li>回归现象的发现意义不亚于万有引力</li><li>相关性和回归性并非两个概念，而是对同一个概念做出的解释<ul><li>只要两个数值之间的相关度不高，就会出现回归平均值的情况</li><li>案例 1： 聪明的女人往往会嫁给不聪明的男人，因为结婚与智商的关系无关，但是为了解释这一现象人们往往通过因果关系去描述这一现象</li></ul></li><li>回归效应，是统计学中一个重要的概念，解释了为什么统计结果会偏离预期<ul><li>解释了为什么第一次表现好的，往往后面表现会变差，因为第二次表现会回归平均值</li></ul></li></ul></li><li>第 18 章 如何让直觉性预测更加恰当有效<ul><li>现实生活中，有很多场景都需要预测，如：建筑需要预测多少袋水泥？投资的风险预测？等等<ul><li>那么如何做到让直觉性预测更加恰当有效？</li></ul></li><li>系统 1的几个机制参与了预测：<ul><li>搜索证据与预测目标的因果关系</li><li>证据的评估与相关规范的紧密联系</li><li>这就是通过问题和信息引起的联想记忆</li></ul></li><li>偏离预测方向的直觉，通过强度匹配和替换思维去让我们直觉预测发生偏差<ul><li>很多直觉都让我们偏离预测方向，就是说我们的直觉会让我们的决策出现偏差</li></ul></li><li>如何对直觉性预测进行修正<ul><li>步骤 1 找到基准线，也就是回归大众的平均点</li><li>步骤 2 根据直觉+证据，找到预测目标的平均点</li><li>步骤 3 评估证据与平均点的关联关系，按照百分制</li><li>步骤 4 最后判断直觉预测平均点与平均点的对比，判断预测的正确性</li></ul></li><li>直觉性预测需要校正是由于它并不具有回归性，因此是带有偏见的。</li><li>直觉预测是允许的，只是需要修正，所以我们不能完全禁止直觉预测<ul><li>当你的信息不足的时候，直觉预测是允许的</li></ul></li><li>替代的运行机制，会将极端获取的信息与极端预测目标做关联匹配，从而让你相信你自己的判断<ul><li>如：投资两家公司，当你对一家公司信息完全掌控，一家公司信息不透明，那么你会认为不透明的公司反而更加具有投资性，因为直觉预测会让你认为不透明的公司的不可预测性会成长的更好</li></ul></li><li>回归平均值，需要系统 2 进行特殊的训练，但是往往我们又会通过因果关系去错误描述平均值</li></ul></li></ul></li><li>第 3 部分 过度自信与决策错误<ul><li>第 19 章 “知道”的错觉<ul><li>“叙事谬误”的概念，用来描述存有缺憾的往事是如何影响我们的世界观和我们对未来的预期的。</li><li>知道的错觉就是“叙事谬误”的一种表现，人们往往通过结果去给自己的行为进行错误的解释</li><li>知道的错觉还有一种表现，就是眼见为实，其实就看到结果，然后通过结果去证明因果关系<ul><li>这个错觉的核心是我们认为自己了解过去，这也表明未来也应该是可知的，但事实上，我们对过去的了解比我们自认为能够了解的要少。 </li></ul></li><li>当你接受一种新的观点，那么你无法回忆起之前的认知，因为记忆会随着时间而改变。<ul><li>你无法重构过去的想法，这种情况会不可避免地导致你低估自己受往事影响的程度。   </li><li>如：当你观看一场比赛前，你预估 A 队会赢，但是 A 队最终输了，你很难想起为什么之前会预测 A 队会赢。</li></ul></li><li>后见之明，俗称马后炮，当结果越严重，那么马后炮的人会更加确信自己的判断</li><li>系统 1 的意义构建体系，会让我们相信世界是可预测，更简单，更整洁的<ul><li>简单的理解，就是更加努力和更加智慧，会更加容易获得成功</li></ul></li><li>企业长青的秘诀，大部分书籍都是说的智慧和勇气<ul><li>企业的发展与领导者和管理措施有关系，但是也不大</li><li>大部分畅销的经济书籍都推崇，夸大领导风格和管理措施对公司业绩的影响</li></ul></li><li>不要带结果偏见，即使这个偏见有时候有用的，但是这个偏见是愚蠢的</li></ul></li><li>第 20 章 未来是不可预测的<ul><li>系统1是在信息有限的情况得出的结论，而这种结论过程很复杂，基于眼见为实和逻辑的连贯性。</li><li>士兵测评案例的错觉 —— 有效性错觉<ul><li>仅仅根据某个场景去对士兵去做评测，是有效的，但却是错误的评测</li></ul></li><li>投资股票的技能错觉<ul><li>股票第一疑问：是什么让人觉得卖了的股票，有人愿意买？双方都觉得当前股价有问题，太高或者太低</li><li>股票交易股票后比上一支股票获得收益更高的概率平均值是3.2%，这个时候就需要考虑回归平均这个概念</li></ul></li><li>股票市场中，不管是业余还是专业的投资者，都很难预测股票市场，因为股票市场是随机波动的</li><li>主观自信与专业知识给错误直觉提供生存的土壤<ul><li>认知错觉比视觉错觉更加固执</li><li>认知来自人的强大专业知识</li></ul></li><li>短期走向是可以预测的，准确率会比较大，而长期的走向是不可预测，即使有再多的证据</li><li>股票投资者大部分人都认为市场是可以预测的，且自己比其他预测更加准确<ul><li>专家的解释往往是在事情发生后详细阅读整个事件发展过程，才按照自己的理解逻辑，用一种因果关系逻辑去解释</li></ul></li></ul></li><li>第 21 章 直觉判断与公式运算，孰优孰劣<ul><li>保罗米尔，通过临床计算预测后续医疗结果</li><li>专家预测比不上简单运算准确<ul><li>案例：阿什菲尔特通过天气三个特征计算葡萄酒的未来价格，十分准确</li><li>为什么：<ul><li>专家总是想要更加聪明，增加了很多复杂因素计算，从而忽略原则性的原因</li><li>人们对于复杂的信息最终难以统一判断</li></ul></li><li>要提高预测的准确度，最终应该统一公式</li><li>闭上眼睛的直觉判断比主观判断更加准确<ul><li>原因：按照规定收集客观信息并对不同特征进行打分</li><li>因为主观印象会影响我们对其结果的判断</li></ul></li></ul></li></ul></li><li>第 22 章 什么时候可以相信专家的直觉<ul><li>直觉是否成为判断的依据，最终的成功与失败的界限<ul><li>判断一个艺术品是否为真品，往往就在眨眼间</li></ul></li><li>决策定制理论，预知认知决策模式，直觉判断就是这么一种思考模式<ul><li>第一阶段，通过系统1联想记忆制定一个计划</li><li>第二阶段，在系统2针对这个计划去确认是否有效</li></ul></li><li>如何锻炼专家型直觉<ul><li>学习需要一定的反复强化，直到形成记忆</li><li>情感学习会让学习变得更加容易</li><li>记忆是有意识的，可以解释你面对问题的情绪</li></ul></li><li>什么时候可以相信专家<ul><li>当环境或者信息是有规律可循的场景，你应当相信专家，如：消防员、临床护士和其他专业知识的专家</li></ul></li><li>如何练习专家直觉<ul><li>一个可预测、有足够规律可循环的环境</li><li>一个通过长期训练练习这些规律的机会</li><li>参考案例：象棋</li></ul></li><li>专业技能不是单一技能，而是由许多技能组成的，因此专业也存在局限性</li><li>专家直觉的局限性：<ul><li>在一个不够规律或者不符合规律判断的环境里，直觉判断就无法有效判断</li></ul></li></ul></li><li>第 23 章 努力养成采纳意见的决策习惯<ul><li>内部预测完成一个项目所需要花费时间？<ul><li>内部预测大约是1年半～2年</li><li>外部团队在通用条件， 平均完成这个项目所需要花费的时间是5年～7年</li><li>很多时候我们以为清楚我们自己的状况，和外界所给予的判断结论是完全不一样的</li></ul></li><li>预测的方法：<ul><li>两种预测方法，一种是内部，一种外部</li><li>最初的预测往往是错误的，因为没有经过内外部的再次验证</li><li>非理性坚持，面对选择时，由于各种原因导致失去理性去坚持做一件事情</li></ul></li><li>比起外部预测，我们往往更加相信内部预测<ul><li>一开始内部预测是正确的，因为开始的数据和信息都是我们能掌握到的</li><li>但是未来的数据信息是不可预测的，所以内部预测会变得不准确，因而会更加依赖外部预测</li><li>外部预测不是100%准确，需要符合当前条件的数据参考，更加依赖外部预测来源</li><li>更相信内部预测往往更加符合人们的道德心理</li></ul></li><li>规划谬误：过于乐观的计划<ul><li>不切实际的让所有条件都处于理想状态</li><li>通过参考类似情况进行规划</li><li>如建筑一栋楼的预算，往往会随着时间的迁移而发生变化</li></ul></li><li>减少错误决策的有效方法<ul><li>明白为什么会发生错误决策，是因为看轻或是忽略分布信息的普遍趋势</li><li>计划者应该尽力划分出预测问题的类别，这样才能充分利用所有能够获取的分布信息。</li></ul></li><li>参考类别预测<ul><li>识别对应的参考类别，如：厨房改建、大型建筑项目等</li><li>获取参考类别的统计数据，利用这些数据作为基准参考</li><li>有特殊特别的原因会比参考类型偏差，可以使用此特别信息对去预测进行调整</li></ul></li><li>高管提出乐观的计划往往忽略可以规避的困难，因此需要控制高管的计划能力</li><li>预测课程项目的主要意义：<ul><li>没有参考类似项目经验</li><li>意识到自己的无能</li><li>往往会忽略外部意见</li><li>不愿意思考正在发生的事情</li></ul></li><li>最终总结，更加明智的去听取外部意见，需要刻意训练形成的思维模式</li></ul></li><li>第24章 乐观是一把双刃剑<ul><li>规划谬误是普遍存在的乐观偏见的一种表现形式<ul><li>以为世界很美好，但是世界并没有想象中那么美好</li><li>以为自己贡献很大，但是其实没有那么大</li><li>夸大自己的预测能力，但是未来总是未知</li></ul></li><li>乐观心态的人有以下几个特征：<ul><li>开朗快乐，认为自己是幸运的</li><li>对失败有更多的承受力</li><li>注重身体，免疫系统能力高</li></ul></li><li>做一个乐观但是不脱离实际的强调积极情绪的乐观主义者，才能更好享受乐观的好处</li></ul></li></ul></li><li>第四部分 选择与风险<ul><li>第 25 章 事关风险与财富的选择<ul><li>人不会完全理性或完全的自私</li><li>心理学和经济学分别研究的是：人类和经济人</li><li>面对风险，我们都不是理性的经济人<ul><li>在不同的简单风险之间和在有风险与确定的事情之间，是什么在控制人们的选择？<ul><li>简单的风险：40%赢得 100 块， 100%获取 10 块，会如何选择？</li></ul></li><li>决策理论：研究人们如何在风险之间做出决策的理论一句<ul><li>期望效用理论：理性代理模式，基于理性的基本原则做出决策</li></ul></li><li>前景理论，待阅读文章《前景理论：风险下的决策分析》？</li><li>框架效应：由无关紧要的措辞变化引起的巨大偏好变化</li></ul></li><li>伯努利的财富效应：通过一个函数去将心理强度与刺激大小关联起来，如：对心理价值和金钱的欲望与钱实际数量的之间的关联关系<ul><li>人们做出的各种选择并非与金钱价值关联，而是基于各种心理价值，就是做出这个选择能得到的成就感（效用）</li><li>财富的边际价值递减现象，越大的财富对于增长的期望与风险的压力是相对的，如：100 万赚 300万，等于 300%，这个时候对于风险的抗压力强，如果时候 1000 万赚 300 万，等于 30%，这个时候对风险抗压力小</li><li>这就是保险公司的心理理论依据，当穷人 100 万损失 30 万等 30%，而富人1000 万损失 30万等于 3%</li></ul></li><li>伯努利财富效用的错误：<ul><li>当穷人从 100 万赚到 500 万和富人从 1000 万亏到 500 万，那么穷人和富人财富一样，他们是否一致心理价值呢？</li><li>因此，伯努利财富效应应该从近期变化去证明，而不是依据当前财富作为依据</li></ul></li><li>从伯努利财富效应理论的错误中发现：<ul><li>理论诱导的盲区(theory-induced blindness)，即一旦你接受了某个理论并将其作为一个思考工具，就很难注意到其错误。</li></ul></li></ul></li><li>第 26 章 更人性化的前景理论<ul><li>效用是伴随财富的变化出现的，而不是伴随财富的各种状态出现的。</li><li>面对财富，你会选择规避风险还是冒险一博？<ul><li>面对盈利和亏损，即使获得的财富值是一样的，但是做出的选择是不同的<ul><li>选择 1：给你 1000 块，100%再获得 500 块，50%获得 1000 块？ 大部分选择获得 500 块，100%获得 1500 块</li><li>选择 2：给你 2000 块，100%损失 500 块，50%损失 1000 块？大部分会选择 50%损失 1000 块，即使100%损失 500 块， 最终也是 1500 块</li></ul></li><li>伯努利理论的弱点：缺失初始依据参考，无法准备评估最终的得失选择。</li></ul></li><li>前景理论的三个认证特征 = 系统 1的运行特征<ul><li>参照点，适应水平</li><li>降低敏感度的原则，财富变化和感觉纬度是一样的</li><li>损失厌恶，损亏比盈利影响更大</li></ul></li><li>损失厌恶：人们对亏损比盈利反应更多<ul><li>做出选择，必须平衡盈利和亏损</li></ul></li><li>“失去比得到给人的感受更强烈”，因此人们往往会规避损失。这也是大多人不愿意去冒险</li><li>像一个商人去思考，或者像一个经济人思考，去降低损失厌恶系数</li><li>前景理论无法应对令人失望的事<ul><li>前景理描述的是：影响人们情绪的是得失，而不是最终获取多少财富</li><li>但是无法描述后悔情绪，因为后悔情绪是另外一种参照点</li><li>后悔这种体验依赖于你本应该采取却没有采取的意见</li></ul></li></ul></li><li>第 27  章 禀赋效应与市场交易<ul><li>所有缺失参考点的理论会陷入一个错误：<ul><li>拟定各项事务状态的效用只依赖于该状态本身，并不受过往的影响。</li></ul></li><li>人们为什么不愿意割舍自己拥有的东西？<ul><li>禀赋效应：人们往往会高估自己拥有的东西</li><li>为什么：因为损失厌恶的理论，得到是乐趣，而失去比得到影响更加强烈</li><li>但是禀赋效应并没有普遍性，如：商品等价交换</li><li>因此引发另外一个问题：R 教授不愿意出售葡萄酒和市场交易的区别？</li><li>交易实验：所有代币都集中到那些能从实验人员那儿拿到最多钱的受试者手中。市场魔力显神威！<ul><li>金钱或商品：最终会流入对其作用最大的人群中，简单的说，如果金钱在你手中能发挥最大作用，那么金钱会不断的流入你的手中</li><li>得出区别的原因：<ul><li>正常商品交易：如果“买方”不觉得花钱买下这个杯子是种损失的话，这个相似的现金值便与我们的预期正相吻合。</li><li>非正常商品交易：当卖方觉得这个杯子卖掉是一种损失，就会持续持有</li></ul></li></ul></li></ul></li><li>像商人一样思考和交易<ul><li>理性的代理人来说，从前的买价与自己根本就不相干——当前的市场价值才是最重要的。</li><li>而现实中的人来说，高价购买的房子的业务希望以更高的房子卖掉</li><li>如何让禀赋效应消失：<ul><li>经常交易可以降低禀赋效应</li><li>长期拥有一个商品，大概率会出现禀赋效应</li><li>商人思考点：与可以得到的其他东西相比，那个杯子真的是我特别想‘得到’的吗<ul><li>有了这个问题，禀赋效应就不复存在了，因为得到的快乐和放弃的痛苦之间的不对称性没有关联。</li></ul></li></ul></li><li><strong>对于穷人来说，花钱就意味着损失。</strong><ul><li>买不同的商品就是不同的损失，只是哪个损失比较少一点</li></ul></li><li>因此商人思考模式对于某些人并不符合，但是对于炒股的人更加适合思考</li></ul></li></ul></li><li>第 28 章 公平性 —— 经济交易的参照点<ul><li>将损失厌恶与大脑双系统模式相结合进行研究</li><li>威胁仍然优先于机遇，即使是对纯粹象征性的威胁，大脑的反应也很迅速。</li><li>负面情况在众多方面都可战胜正面情况，而且损失厌恶是负面占优势的典型例子之一</li><li>人们更加愿意避开负面的定义和情绪，比追求正面情绪还要强烈</li><li>生理状况的重要改善，能影响人们的短期情绪变化</li><li>目标就是参照点<ul><li>损失厌恶系数指的是两种动机的相对强度：我们想要规避损失的动机要强于获得利益的动机。</li><li>设定短期目标后，接近目标后就会慢慢变懒惰，因为目标接近后不是用来超越的，就是一个参照点</li></ul></li><li>我们为什么不愿意改变现状<ul><li>因为避免损失的动机和获得收益的动机强度并不对称</li><li>当蛋糕足够大，那么所有人都会变得随和</li><li>所有动物（包括人）都想有所得，但他们会更努力地避免有所失。</li><li>损失厌恶是一种强大而保守的力量，保守主义会让我们的生活保持稳定，是引力作用让我们的生命无限靠近参照点。</li></ul></li><li>商人提价或降低员工工资行为公平吗？<ul><li>公平性的一条基本原则是：不可利用市场的力量将损失强加给他人。</li><li>公司有其自身的权利，即保持当前的收益。</li><li>对当时经济学家们公认的知识的挑战，即经济行为是受自身利益驱使的，而与是否公平无关。</li><li>如果遭受损失的人比没能赢利的人遭受更大的损失，他们也许应该得到更多的法律保护</li></ul></li><li>损失厌恶和权利的影响</li></ul></li><li>第 29 章 对结果可能性的权衡<ul><li>对某个复杂情况的决定，一般会有一个总体评估，主要对复杂情况进行抽象化成几个特征。<ul><li>总体评估都是由系统1作出的</li></ul></li><li>可能性效应与确定性效应<ul><li>赌注是通过其预期值加以评估的。</li><li>从零到5%的巨大转变表明了“可能性效应”(possibility effect)，这一效应会是我们高估那些出现可能性极低的结果的发生频率。</li><li>从95%提升到100%是另一种实质性改变，也会产生巨大的影响，是“确定性效应”(certainty effect)。</li><li>可能性和确定性在损失研究方面具有同样强大的效应。<ul><li>因为厌恶损失，面对损失的会尽量避免损失的可能性，或者追求降低损失必然性</li></ul></li><li>由理性选择的公理推出的期望效用理论，说明理性决策是基于期望预计结果才能做出的</li></ul></li><li>著名经济学家也难逃阿莱斯悖论的陷阱<ul><li>61%获得 52 万和63%获得 50 万， 大部分人都会选前者，这违背了效用理论<ul><li>效用理论：指的当决策的理论依据是能获取最佳结果的</li></ul></li><li>将效用理论看成是理性选择的逻辑基础，但并不认为人们都是非常棒的理性选择者</li><li>决策权重的大小取决于人们的担忧程度<ul><li>1%得到和 1%损失对于人们的影响不完全不同，前者可能不会当一回事，后者必然会焦虑不安</li><li>5%～95%的概率对人们情绪影响最少，在做决策的时候可以更加理性面对</li><li>影响决策权重的因子，是人们的担忧程度，程度越深影响决策的权重越大</li></ul></li><li>四重模式：可能性与决策权重的关系模型<ul><li>所得、损失与较大可能性的确定性效应、较小可能性的可能性效应之间的关系</li><li>偏好的四重模式是前景理论的核心成果</li><li>为什么人们会对95%损失可能性去做更加冒险的行为<ul><li>举例说明，当你炒股损失的时候， 你会更加冒险的决策，当你盈利的时候，为了避免损失你会更加保守决策</li><li>原因 1：敏感性不断降低，由于损失让你对损失的敏感性在降低</li><li>原因 2：必然性的损失和可能的盈利，你会规避必然损失，如：割肉离场和追新的盈利点</li></ul></li><li>人类的大部分损失都是因为规避 95%的损失而去做出更加冒险的行为，导致更大的损失</li><li>正如一场比赛，输只是时间问题，但是输的一方还是会不断挣扎</li></ul></li><li>可能性效应影响下的风险决策<ul><li>可能性效应会让人们去规避必然的损失去做更加冒险的事情，同时也会让人们去争取更多可能性的利益，去获得更少的必然利益</li></ul></li></ul></li></ul></li><li>第 30 章 被过分关注的罕见事件<ul><li>以色列巴士被恐怖袭击事件，会让大部分人尽量不去搭乘巴士，即使大多人心里清楚的知道巴士再次发生恐怖袭击的概率很低<ul><li>为什么：因为恐怖主义降低了效用层叠，同时我们无法组织系统 1 的运行，即使系统 2  做出了极大的控制</li></ul></li><li>你认为一只三流球队获得 NBA 总冠军的可能性多大？<ul><li>对于罕见事件，人们往往高估了罕见的概率</li><li>过高估计和过高权衡是不同的行为，但是背后心理机制是一样的<ul><li>集中注意力、证实性偏差和认知放松</li></ul></li><li>因此过高估计的现象会出现决策失误，尤其只针对某一种可能性进行预测判断，大脑往往只会去计算出有利于这一可能性的所有因素</li></ul></li><li>画面感越强，决策权重越大<ul><li>同样可能性的事件，往往越生动的描述能让大脑形成画面，从而更能记住该可能性，对判断决策影响更大</li></ul></li><li>对风险的表述方式不同，所做的决策可能截然不同<ul><li>“分母忽视”，人们在做决策的时候，由于系统 1的存在，往往会忽略大数量分母的对比，而是对比分子的大小，如书中所失：10 个中有一个红球，100 个中 8 个红球， 大部分人会优先从 100 个箱子去获取。</li><li>解释不同语言描述同一个风险事件会带来不同结果，是因为利用“分母忽视”原理，突出分子对比从而达到不同的结果</li></ul></li><li>罕见事件又为何让人忽视<ul><li>是罕见事件从未发生过，因此人们往往会凭借经验做出选择，因为系统 1 的存在更加容易忽视这个罕见事件，而系统 2 未参与是因为不知道要如何处理该类事件</li></ul></li></ul></li><li>第 31 章 能带来长远收益的风险政策 <ul><li>全部决策，一般会将收益和损失分开去选择，让大脑更加容易做出判断</li><li>宽框架还是窄框架？<ul><li>上面的决策选择，是基于处于收益状态会规避损失，处于亏损状态承担风险是需要付出代价的</li><li>窄框架：分别思考两个简单问题</li><li>宽框架：一个有4个选项的综合决策性问题</li><li>宽框架在任何情况下，将多种决策综合考虑会更有优势</li><li>但是人们会更加喜欢用窄框架去思考决策问题</li></ul></li><li>聪明的投资不会每天都看股票行情<ul><li>遇到赌一次输 100，但是能赚 200 的机会，大部分人都会选择不赌</li><li>但是真正的聪明人会想，如果读1000 次，那么大概率还是会赢的</li><li>利用宽框架思维去避免亏损厌恶带来的痛苦：<ul><li>提高理性对待盈利和亏损，如：用商人的思维去思考</li><li>降低查看投资结果频率</li><li>每天查看股票，容易造成股票投资进行无效的变动</li></ul></li></ul></li><li>风险政策可以抵消风险厌恶的偏见<ul><li>风险政策：在决策的影响因素中增加特别有风险的选项，从而增加思考的全面性</li><li>类似于外部意见，从而增加自己用宽框架去思考问题</li><li>结合风险政策+外部意见，能更好的统计去做决策</li></ul></li></ul></li><li>第 32 章 心理账户是如何影响我们的选择？<ul><li>绝对大多数人赚钱并不是处于经济动机<ul><li>钱是衡量一个人自身利益与自我成就感的标尺</li><li>奖励与惩罚会给人们带来情绪的变化</li></ul></li><li>你会卖掉盈利的股票还是亏损的股票？<ul><li>我们把钱存进还是银行，还是投资到股票市场中，其实只是把钱存入到我们不同的心理账户<ul><li>期待稳定收入，还是高风险收入</li><li>心理账户是一种窄框架思维体现，能更好掌握事情</li></ul></li></ul></li><li>当遇到需要用钱的时候，你会把盈利的股票卖掉 还是卖掉亏损的股票？<ul><li>遇到这种选择，金融研究已经记录大量人们的记录偏见，这也叫处置效应</li><li>处置效应，是指人们倾向于卖掉盈利的股票，而不是亏损的股票，因为人们总想着盈利</li><li>但是不管是卖盈利还是卖亏损，处置效应更多是一种窄框架思维，思考的只是单方面的现在的盈利亏损情况</li><li>真正理性思维应该是思考哪只股票在未来的情况不可能有上涨的可能性</li><li>理性的投资人只会对未来的结果感兴趣，而不是针对当前的情况</li><li>对亏损的股票进行再次追加，俗称“沉没成本的悖论”，简单的分析就是继续亏损+增加多资金承担更大风险，去获取更少的收益，如：10 万亏 1 万，追投10 万，只想赚回这1 万，但是 20 万赚 1 万的成本太高了</li><li>【沉没成本的悖论】，会让人们在亏损的事情投入太多</li></ul></li><li>那种选择会让你更后悔？<ul><li>后悔是一种情绪，也是一种自我惩罚</li><li>后悔是由替代现实实用性引发的反现实的情绪</li><li>决策制定者很容易后悔，然后又很容易受到后悔情绪的影响做下一个决定</li><li>后悔情绪的大小，往往不采取行动的情绪比采取行动的情绪更多</li><li>如同医生在手术中，承担风险采取行动导致死亡，但是没有采取行动而死亡，那么后悔情绪会更大</li></ul></li><li>因为害怕将来后悔而做出不理性的选择<ul><li>为什么会有这种心理？<ul><li>因为损失带来的痛苦是获取带来快乐的两倍，损失厌恶</li><li>愿意付出更多代价去避免损失，如：家长愿意花更多的钱去避免孩子承担风险，购买更高价格的杀虫剂</li></ul></li><li>如何避免害怕后悔情绪？<ul><li>对做任何决策，可以将可能后悔的事情进行预防</li><li>针对可能发生的事情作为决策因素之一</li><li>不同决策应该有不同策略<ul><li>远期的目标应该是一个大目标，不需要思考后悔的事情，等于不需要思考方方面面的问题</li><li>近期的目标应该是小目标，需要思考更多可能性</li></ul></li><li>同时应该降低后悔带给我们的痛苦程度，因为我们每个人都有心理免疫系统</li></ul></li></ul></li></ul></li><li>第 33 章 评估结果的逆转<ul><li>同样中枪得到保险，但是在不同场景下，人们希望获得的金额赔偿是不一样的，从而提出偏好逆转的理论<ul><li>偏好逆转：风险策略下一种奇怪现象，对于同一个价值的博弈下，往往会选择概率高和损失小的，但是对概率低和损失大会定价更高</li></ul></li><li>开启经济学与心理学的跨界交流<ul><li>偏好逆转在经济学家和心理学家中的沟通占据重要地位</li><li>为什么会有偏好逆转？<ul><li>因为在做联合评估决策的时候，会将注意力集中在某一个情况，从而忽略其他因素</li></ul></li><li>理性经纪人不受偏好逆转影响，是因为：<ul><li>偏好逆转是理性因素模式的一种挑战</li></ul></li></ul></li><li>联合评估引发偏好逆转<ul><li>不应该单一判断和综合判断的结果不一致</li><li>应该同一类问题进行综合判断</li><li>单一评估和联合评估是完全不同的决策，同时会产生不同的结果</li></ul></li><li>同类案件判罚力度为何不一样？<ul><li>因为先判断案例 1，一般使用单一评估，可能赔偿金额没那么大</li><li>但是一旦联合评估后，案例 1 得到赔偿比单一评估要多</li><li>这就是法律规定定性某类案件后，最高赔偿多少金额的原因</li></ul></li></ul></li><li>第 34 章 善用框架效应，让生活更加美好<ul><li>一场比赛的结果用不同的话术描述会给人不同的感觉，如：“A队赢了” 给人一种 A队属于正常赢了，“B 队输了”表达了 B队本来要赢但是却输了的感觉 </li><li>情感的框架很难抵挡<ul><li>成本就是没有损失</li><li>当获得是确定的，系统1便会偏向于获得；若损失是确定的时候，系统1便又会规避损失</li><li>系统 2  很懒惰，除非有明确的理由需要这样子做外才会激发系统 2去思考</li></ul></li><li>用框架性政策助推人们作出更好的选择<ul><li>不同的说法会让人们更加愿意去做不同选择倾向</li><li>对风险规避或冒险的倾向都不是基于现实的</li><li>框架效应下：如何处理穷人和富人的生育免税额度？<ul><li>穷人更高，还是富人更高？ </li></ul></li><li>某个重要的决定是受该情况下完全无关的特征控制的<ul><li>如：意外死亡是否要自愿捐献器官，是不是应该放到汽车驾照标识中？</li><li>大多数人会认为捐献器官是重要的，但是放到汽车驾照中不是重要的决策，往往就会草率做决定<br>第 5 部分 两个自我</li></ul></li></ul></li></ul></li><li>第 35 章 体验效用与决策效用的不一致<ul><li>体验效用的含义：因为痛苦和快乐而作出决策的行为</li><li>如何测量体验效用？<ul><li>测量体验效用的工具是快乐测量仪，可衡量一个人所经历的痛苦或快乐的大小</li><li>快乐测量值和回顾性评估是评估体验效用的两种方法<ul><li>快乐测量值：从他人不同时刻的体验报告中计算出的数据</li><li>回顾性评估：会权衡两个单一时刻，即高峰和末端</li></ul></li></ul></li><li>记忆自我放大了痛苦的体验<ul><li>在经验自我和记忆自我引起冲突，也是在体验效用和决策效用引起冲突</li><li>相比下，记忆自我保存的记忆是对代表性时刻的感觉，受到高峰和结束时刻的强烈影响</li><li>支配人类记忆自我的规则是一个漫长的发展历史，这也是人类与其他物种进化不同的原因</li></ul></li><li>记忆没那么可靠<ul><li>记忆的两个原则：过程忽视和峰终定律<ul><li>过程忽视：过程的持续对所有疼痛的评估没有任何影响。</li><li>峰终定律：整体的回顾性评级可通过将最糟糕时期和最后时刻的疼痛程度的平均加权而评估出来</li></ul></li><li>因为两个原则得出：决策和体验不协调</li><li>决策不会产生最可能的体验，对未来的感觉预测也可能是错误的</li></ul></li></ul></li><li>第 36 章 人生如戏<ul><li>每次看到电影里紧张时刻，我们还是会紧张揪心</li><li>比起整个人生，我们更在意人生的结局<ul><li>为什么会在意结局？因为记忆自我工作机制：编故事保存起来，然后作为将来的参考点</li><li>如何判断一个故事主角的幸福，往往取决于最终的结局，而不是故事的过程<ul><li>这更能证实记忆的两个原则：过程忽视和峰终定律</li></ul></li><li>“少即是多”效应：平均（典型）可替代总体，简单的理解就是平均的幸福程度可能大于平均的幸福程度</li></ul></li><li>关于上一次旅行你还记得多少？<ul><li>许多旅行者都会拍很多照片和视频，是因为他们想保存这段美好记忆，这也是往往旅游的目的</li><li>上一次旅行的照片与视频，往往会成下一次旅游的计划造成影响</li><li>如果没有上一次旅游的记忆，那么会这次旅游计划会发生变化吗？</li></ul></li><li>我 = 记忆自我 + 经验自我，但是我们往往对两个我很陌生</li></ul></li><li>第 37 章 你有多幸福？<ul><li>幸福的初步认识：<ul><li>从各方面考虑，对当前生活的满意程度</li><li>另外一种角度对幸福的衡量，就是经验自我的幸福感</li><li>幸福的事情是指的我们愿意继续，不想停止的，包含心理和生理上的</li></ul></li><li>测量经验自我的幸福感<ul><li>经验取样法，从每天固定时间取样，从获取每天幸福平均值</li><li>U 指数：个人处于不愉快的时间比例</li><li>人在任何时刻的心情都是由他的性情和整体幸福感决定的</li><li>对于个人和社会而言，降低 U 指数的方法是有意义，个人可以通过做一些喜欢的事情，社会可以通过为劳动人提供更好的交通条件等</li></ul></li><li>幸福的方法<ul><li>评估生活的总体评价：坎特里尔自我奋斗量尺，台阶分数，0～10，你会如何估自己处于几分的台阶？</li><li>评估生活的幸福程度主要影响因素：<ul><li>教育程度，教育越高对生活要求的标准也越高</li><li>收入程度，收入越高那么幸福的下限会高，但是却不是影响幸福的重要因素，不过贫穷往往会导致很多不幸，因为贫穷会经历更多不幸的痛苦</li><li>收入同用会影响对幸福的评估，比如：同一块巧克力对不同家庭而言带来的幸福感是完全不同的</li></ul></li></ul></li></ul></li><li>第 38 章 思考生活<ul><li>生活满意度：一个很难回答的问题<ul><li>婚姻后生活的满意程度陡然下降，大部分认为在适应过程中</li><li>对生活是否满意是一个很回答的问题，因为系统 1 无法直接给出答案，而且其特别容易受最近某些小事的影响<ul><li>在问满意之前先问最近约了几次约会，那么满意的影响因素是约会</li></ul></li><li>经验自我的幸福不受婚姻的影响，原因是婚姻不能影响幸福感<ul><li>经验自我的幸福感和生活满意度总体上取决于性情的遗传</li><li>个人生活环境与生活满意度相关性低</li></ul></li><li>年轻时候的目标会影响未来将要经历的事情、未来发展和对生活满意度</li><li>幸福是各个方面的综合体观点，必须把记忆自我和经验自我感受都考虑在内</li></ul></li><li>被放大的幸福错觉<ul><li>当仔细思索某件事情的时候，这件事情就变得没那么重要<ul><li>是因为聚焦错觉</li></ul></li><li>聚焦错觉=眼见为实，以为见到就是真实，会把当前能见到的影响因素放大<ul><li>如买车的时候，大部分考虑的是买到车后的快乐，往往忽略了后续需要承担的经济压力，这也是聚焦忽略</li></ul></li><li>为什么会聚焦错觉？因为人们总相信眼见为实，忽略了时间的影响</li><li>忽略了时间，导致维持人们长久的注意力价值会忽视，如：长时间学习和短时间的刷抖音是一样的原因</li></ul></li><li>前往不要忽视时间的作用<ul><li>大脑善于处理故事，但是不能很好的处理时间</li><li>经验自我的生活是一系列有价值的时刻，如：小时候获得第一名、长大后的初恋等等</li><li>记忆自我的生活往往更加注重开始与结局，往往忽视了过程</li></ul></li><li>忽视时间的作用，往往是因为我们大脑更加在意当前时刻带来的感受，不过我们可以通过过去，现在，未来的时间发展去让自己更加注重时间的作用</li></ul></li></ul></li><li>结语<ul><li><h1 id="术语解释"><a href="#术语解释" class="headerlink" title="术语解释"></a>术语解释</h1></li></ul></li></ul><h2 id="1-可得性法则"><a href="#1-可得性法则" class="headerlink" title="1.可得性法则"></a>1.可得性法则</h2><ul><li>一般又称可获得性启发、易得性法则</li><li>人们是根据从记忆中提取信息的容易程度来估测事情的重要程度的，而这往往也与媒体报道的广泛程度有关。</li><li>解释人们有些事情记得清楚，有些事情却被遗忘</li></ul><h2 id="2-启发法和成见"><a href="#2-启发法和成见" class="headerlink" title="2.启发法和成见"></a>2.启发法和成见</h2><ul><li>启发法，或者称策略法、助发现法、启发力、捷思法<ul><li>在不可能找到最佳解决方案或不切实际的情况下，可以使用启发式方法来加快找到满意解决方案的过程。</li><li>解释了在知识有限（信息不完整）和时间有限的情况下，得出可能陈述或可行解决方案的艺术。</li><li>简单理解，在完全不理解情况下如何利用自己已有的知识和原则性的原理去得到可行的解决方案</li></ul></li></ul><h2 id="3-缪勒–莱耶错觉图"><a href="#3-缪勒–莱耶错觉图" class="headerlink" title="3.缪勒–莱耶错觉图"></a>3.缪勒–莱耶错觉图</h2><p>缪勒莱耶错觉是指前提为两条长度相等的线段，假如一条线段两端加上向外的两条斜线，另一条线段两端加上向内的两条斜线，则前者要显得比后者长得多。如下图所示：</p><p><img src="/assets/img/think-fast-1.png" alt=""></p><h2 id="4-心理学家米哈里·契克森米哈-Mihaly-Csikszentmihalyi-的“心流”状态"><a href="#4-心理学家米哈里·契克森米哈-Mihaly-Csikszentmihalyi-的“心流”状态" class="headerlink" title="4.心理学家米哈里·契克森米哈(Mihaly Csikszentmihalyi)的“心流”状态"></a>4.心理学家米哈里·契克森米哈(Mihaly Csikszentmihalyi)的“心流”状态</h2><ul><li>是什么<ul><li>心流状态是一种精神状态，其特征在于完全沉浸在活动中并专心致志，使相应过程令人满足且令人愉悦。</li><li>“心流”这个词是心理学家 Mihaly Csikszentmihalyi 在 1975 年创造的，当时他观察到一些艺术家完全沉浸在自己的创作中，以至于忽视或根本不受食物、饮水或睡眠需求的影响。</li></ul></li><li>心流状态的明显标志<ul><li>高度专注</li><li>行动和意识高度融合</li><li>完全沉浸其中</li><li>有一种毫不费力就能完成任务的感觉</li><li>对手头任务有很强的控制感</li><li>失去时间感/忘记时间</li><li>感到任务本身就是回馈（甚至在任务完成之前就感觉如此）</li></ul></li><li>进入心流的条件<ul><li>明确的目标</li><li>可战胜的挑战</li><li>让人能享受其中/有回馈的活动，也被称为本身具有目的的任务</li></ul></li><li>怎么做<ul><li>消除干扰：需要时间来适应一项任务，确保这段时间没有任何干扰</li><li>静下心来：建议要素是冥想练习</li><li>更专注：减少场景切换或任务切换</li><li>工作富有挑战性：增加富有挑战性的任务</li></ul></li></ul><h2 id="5-自我损耗-ego-depletion"><a href="#5-自我损耗-ego-depletion" class="headerlink" title="5.自我损耗(ego depletion)"></a>5.自我损耗(ego depletion)</h2><ul><li>俗称“内耗”</li></ul><h2 id="6-联想的连贯性"><a href="#6-联想的连贯性" class="headerlink" title="6.联想的连贯性"></a>6.联想的连贯性</h2><ul><li><p>联想的机制，是人类大脑思维活跃最常见的一种</p></li><li><p>启动效应</p><ul><li>是指由于之前受某一刺激的影响而使得之后对同一刺激的知觉和加工变得容易的心理现象。</li></ul></li><li><p>涟漪效应</p><ul><li>启动联想后，大脑的思维就像在池塘里的涟漪一样向外扩展，这就是涟漪效应</li><li>案例：每次吃饭都先喝汤，等到下次要吃饭的时候，就会先等汤做完</li></ul></li><li><p>佛罗里达效应</p><ul><li>佛罗里达里大部分是老年人，所以一想到佛罗里达，就会想到年老，白发，缓慢行走，其实是联想效应一种表现</li></ul></li></ul><h2 id="7-贝叶斯定理"><a href="#7-贝叶斯定理" class="headerlink" title="7. 贝叶斯定理"></a>7. 贝叶斯定理</h2><blockquote><p>贝叶斯定理（英语：Bayes’ theorem）是概率论中的一个定理，描述在已知一些条件下，某事件的发生概率。比如，如果已知某种健康问题与寿命有关，使用贝叶斯定理则可以通过得知某人年龄，来更加准确地计算出某人有某种健康问题的概率。 —— <a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86">贝叶斯定理 维基百科</a></p></blockquote><ul><li>用公式去解释一件事发生的概率，或者判断某件事情的正确性概率<ul><li>当事件B发生后，事件A发生的可能性概率1</li><li>反过来需要思考， 事件A发生后事件B发生的概率2</li><li>概率1 != 概率2</li></ul></li><li>贝叶斯定理，通常用来解决去检测或者判断某个事情的概率，<ul><li>案例1:检测公司有多少人得新冠，通过检测纸的准确概率+平时公司阳了的人基础比率去判断检测，得出公司大概率有多少人可能得了新冠</li></ul></li></ul><h2 id="8-前景理论"><a href="#8-前景理论" class="headerlink" title="8. 前景理论"></a>8. 前景理论</h2><blockquote><p>1970年代，卡内曼和特沃斯基系统地研究这一领域。长久以来，主流经济学都假设每个人作决定时都是“理性”的，然而现实情况并不如此；展望理论加入了人们对得失、发生概率高低等条件的不对称心理效用，成功解释了许多看来不理性的现象。展望理论对分析在不确定情况下的人为判断和决策方面作出了突出贡献，康纳曼更因此获得2002年的诺贝尔经济学奖。<br>展望理论是描述性而非指示性的理论——它旨在解释现象，而非分析怎样作决策才是最好的。利用展望理论可以对风险与报酬的关系进行实证研究。<br>前景理论（展望理论）：人在不确定条件下的决策选择，取决于结果与展望（预期、设想）的差距而非单单结果本身。</p></blockquote><p>解释描述人们为何在当下做出选择的理论依据，而不是作为决策依据。不过可以利用理论去分析当前面临选择的可能性。</p><h2 id="9-禀赋效应"><a href="#9-禀赋效应" class="headerlink" title="9. 禀赋效应"></a>9. 禀赋效应</h2><blockquote><p>禀赋效应 [1]或厌恶剥夺（英语：Endowment effect），形容当一个人拥有某项物品或资产的时候，他对该物品或资产的价值评估要大于没有拥有这项物品或资产的时候。<br>这一现象常常用于行为经济学的分析中，并与损失厌恶的理论相联系。由于禀赋效应，人们在决策过程中，往往会产生偏见，导致对于规避风险的考虑远远大于对于追逐利益的考虑，因此人们在出卖物品或资产时，往往索价要比其本身更高的价值。</p></blockquote><p>这在炒股中往往很常见，当你拥有一只股票的时候，你往往会收集无数利好的消息去以为它会持续上涨。而不是因为你看到利好的消息而去拥有一只股票。</p><h1 id="相关书籍"><a href="#相关书籍" class="headerlink" title="相关书籍"></a>相关书籍</h1><ul><li>斯坦诺维奇 《理性和反思性思维》</li><li>苏格兰哲学家大卫·休谟《人类理解研究》</li><li>心理学家蒂莫西·威尔逊《我们是自己的陌生人》</li><li>纳西姆·塔勒布所著的《黑天鹅》</li><li>丹尼尔·吉尔伯特(Daniel Gilbert) 《哈佛幸福课》</li><li>《注意与努力》</li><li>菲利普·罗森茨威格《光环效应》</li><li>波顿·麦基尔(Burton Malkiel)的著作《漫步华尔街》</li><li>保罗·米尔《临床与统计的预测：理论分析与事实回顾》</li><li>罗宾·道斯的论文《决定中非正当线性模型的稳定之美》</li><li>《前景理论：风险下的决策分析》</li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;思考，快与慢&quot;&gt;&lt;a href=&quot;#思考，快与慢&quot; class=&quot;headerlink&quot; title=&quot;思考，快与慢&quot;&gt;&lt;/a&gt;思考，快与慢&lt;/h1&gt;&lt;p&gt;在书中，卡尼曼会带领我们体验一次思维的终极之旅。他认为，我们的大脑有快与慢两种作决定的方式。常用的无意识的“系统1”依赖情感、记忆和经验迅速作出判断，它见闻广博，使我们能够迅速对眼前的情况作出反应。&lt;/p&gt;
&lt;p&gt;举个例子： 肚子饿了去点菜，我们点很多余点菜，然后吃了一阵子就后悔了，如果我们慢慢规划去点，发现别人都已经吃完走了。&lt;/p&gt;
&lt;p&gt;温馨提醒：本书涉及N多经济学和心理学的专业术语，需要不断查资料去理解其术语的意思，这对经济学、心理学入门有极大的作用。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>好工具推荐Automa —— 可视化配置+工作流+自动化执行浏览器插件</title>
    <link href="https://www.qborfy.com/today_2024/20240531.html"/>
    <id>https://www.qborfy.com/today_2024/20240531.html</id>
    <published>2024-05-30T10:00:01.000Z</published>
    <updated>2024-06-04T07:56:20.629Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><blockquote><p>Automa是通过可视化配置，工作流连接实现浏览器自动化的插件。能完成自动填写表格、重复任务、截屏到抓取网站数据等，想做什么取决于你自己。</p></blockquote><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://chromewebstore.google.com/detail/infppggnoaenmfagbfknfkancpbljcca">Automa插件官方下载安装</a></li><li><a href="https://github.com/AutomaApp/automa">Automa Github</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;是什么&quot;&gt;&lt;a href=&quot;#是什么&quot; class=&quot;headerlink</summary>
      
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>如何优化chrome web页面开了很久卡顿</title>
    <link href="https://www.qborfy.com/today_2024/20240604.html"/>
    <id>https://www.qborfy.com/today_2024/20240604.html</id>
    <published>2024-05-30T10:00:01.000Z</published>
    <updated>2024-06-06T07:04:12.410Z</updated>
    
    <content type="html"><![CDATA[<h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><h1 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h1><h2 id="利用chrome性能解析工具"><a href="#利用chrome性能解析工具" class="headerlink" title="利用chrome性能解析工具"></a>利用chrome性能解析工具</h2><h1 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h1><h1 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://github.com/LuckyWinty/blog/blob/master/markdown/Q%26A/Chrome%20%E6%B5%8F%E8%A7%88%E5%99%A8%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E5%88%86%E6%9E%90.md">Chorme 浏览器中的垃圾回收和内存泄漏</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;原因&quot;&gt;&lt;a href=&quot;#原因&quot; class=&quot;headerlink&quot; title=&quot;原因&quot;&gt;&lt;/a&gt;原因&lt;/h1&gt;&lt;h1 id=&quot;原因-1&quot;&gt;&lt;a href=&quot;#原因-1&quot; class=&quot;headerlink&quot; title=&quot;原因&quot;&gt;&lt;/a&gt;原因&lt;/h1&gt;&lt;h</summary>
      
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>Vue2老项目优化打包逻辑</title>
    <link href="https://www.qborfy.com/today_2024/20240523.html"/>
    <id>https://www.qborfy.com/today_2024/20240523.html</id>
    <published>2024-05-23T10:00:01.000Z</published>
    <updated>2024-05-30T04:13:50.297Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>由于最近接手一个老的Vue2项目，其打包编译速度，每次发布都需要等待30分钟以上，实在受不了，故此在互联网上收集了</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://blog.csdn.net/JZevin/article/details/108478555">使用可视化的Vue项目管理器Vue UI </a></li><li><a href="https://tiven.cn/p/edae9a97/">Vue 打包优化之 externals 抽离公共的第三方库</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>VSCode远程连接服务器开发</title>
    <link href="https://www.qborfy.com/today_2024/20240429.html"/>
    <id>https://www.qborfy.com/today_2024/20240429.html</id>
    <published>2024-04-29T10:00:01.000Z</published>
    <updated>2024-04-29T08:33:02.461Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>VScode是前端开发最受欢迎的IDE工具之一， 里面的插件市场十分丰富，插件有个插件叫<a href="https://code.visualstudio.com/docs/remote/ssh">Remote - SSH</a>，其主要功能介绍如下：</p><blockquote><p>Visual Studio Code 远程 - SSH 扩展允许你在任何远程计算机、虚拟机或具有正在运行的 SSH 服务器的容器上打开远程文件夹，并充分利用 VS Code 的功能集。连接到服务器后，您可以与远程文件系统上任何位置的文件和文件夹进行交互。</p></blockquote><p>因此，我们可以直接连接远程服务器去做很多事情：</p><ul><li>搭建云端个人开发机， 从而使得所有无论更换本地环境，都不会影响个人开发进度</li><li>更加友好的可视化文件管理，包括一些简单的文件编辑等等</li><li>使用SSH登录，能更好更安全的避免密码泄漏</li></ul><p>下面还是以【如何搭建个人远程开发机】作为案例去学习</p><h1 id="如何搭建个人远程开发机"><a href="#如何搭建个人远程开发机" class="headerlink" title="如何搭建个人远程开发机"></a>如何搭建个人远程开发机</h1><h2 id="步骤一-安装-Remote-SSH插件"><a href="#步骤一-安装-Remote-SSH插件" class="headerlink" title="步骤一 安装 Remote-SSH插件"></a>步骤一 安装 Remote-SSH插件</h2><p>在VSCode的插件市场中，查询【Remote-SSH】，然后进行安装，具体如下图：</p><p><img src="/assets/img/20240429-1.png" alt=""></p><h2 id="步骤二-配置远程服务器"><a href="#步骤二-配置远程服务器" class="headerlink" title="步骤二 配置远程服务器"></a>步骤二 配置远程服务器</h2><ol><li><p>打开SSH配置界面，具体如下图：<br><img src="/assets/img/20240429-2.png" alt=""><br><img src="/assets/img/20240429-3.png" alt=""><br><img src="/assets/img/20240429-4.png" alt=""></p></li><li><p>编辑SSH配置文件<code>~/.ssh/config</code>，路径和上述文件路径保持一致，具体代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">## </span><br><span class="line">## Host 远程连接名称</span><br><span class="line">## HostName 主机IP</span><br><span class="line">## User 连接帐号</span><br><span class="line">## Port 连接SSH端口</span><br><span class="line">##</span><br><span class="line"></span><br><span class="line">Host self_remote_host</span><br><span class="line">    HostName 10.11.67.18</span><br><span class="line">    User root</span><br><span class="line">    Port 22</span><br></pre></td></tr></table></figure></li></ol><p>完成步骤一，基本上就可以连接远端服务器，不过每次都要输入密码有点麻烦，所以可以通过SSH密钥认证去解决，具体如下步骤</p><h2 id="步骤二-本地生成SSH密钥，进行免密登录"><a href="#步骤二-本地生成SSH密钥，进行免密登录" class="headerlink" title="步骤二 本地生成SSH密钥，进行免密登录"></a>步骤二 本地生成SSH密钥，进行免密登录</h2><p>不同操作系统，执行命令不太一样，具体如下。</p><ol><li>Mac | Linux操作系统<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认会在相应路径下（~/.ssh/）生成id_rsa和id_rsa.pub两个文件，如下面代码所示</span></span><br><span class="line">ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</span><br></pre></td></tr></table></figure></li></ol><ul><li><code>id_rsa</code> SSH私钥文件，用来解密公钥，一般存在本地使用</li><li><code>id_rsa.pub</code> SSH公钥文件，用来传输信息的时候加密用， 一般存在远端服务器</li></ul><ol start="2"><li>Windows操作系统<br>安装Git Bash，执行如下命令即可：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认会在相应路径下（C:\Users\yourname\.ssh）生成id_rsa和id_rsa.pub两个文件，如下面代码所示</span></span><br><span class="line">ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</span><br></pre></td></tr></table></figure>接下来就是将公钥<code>id_rsa.pub</code>复制到远端服务器上<code>~/.ssh/</code>目录下即可</li></ol><ol start="3"><li>将公钥<code>id_rsa.pub</code>添加到远端服务器中可信任文件中<code>authorized_keys</code>，具体命令如下：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>验证登录：<code>ssh &lt;user&gt;:10.1.1.1</code></p><ol start="4"><li>配置VSCode SSH config文件，具体如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">## </span><br><span class="line">## Host 远程连接名称</span><br><span class="line">## HostName 主机IP</span><br><span class="line">## User 连接帐号</span><br><span class="line">## Port 连接SSH端口</span><br><span class="line">## IdentityFile 认证登录的SSH密钥文件</span><br><span class="line">##</span><br><span class="line"></span><br><span class="line">Host self_remote_host</span><br><span class="line">    HostName 10.11.67.18</span><br><span class="line">    User root</span><br><span class="line">    Port 22</span><br><span class="line">    IdentityFile ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure></li></ol><h1 id="SSH免密码登录原理"><a href="#SSH免密码登录原理" class="headerlink" title="SSH免密码登录原理"></a>SSH免密码登录原理</h1><ul><li>SSH远端服务会发送【公钥(remote)】信息</li><li>本地SSH客户端会验证远端传输来的【公钥(remote)】和 本地【公钥(local)】对比是否一致，如果一致，发送【随机字符串（challenge）】给到远端服务器</li><li>远端服务器接受到随机字符串（challenge）信息后，继续用【公钥(remote)】加密传输信息-随机字符串（challenge）给回到客户端</li><li>本地SSH客户端用本地【私钥(local)】去解密【公钥(remote)】加密传输信息-随机字符串（challenge），如果与之前一致，则建立连接</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://cloud.tencent.com/developer/article/2175073">使用VS Code插件远程连接Linux服务器</a></li><li><a href="https://www.cnblogs.com/brf-test/p/16036703.html">Windows下生成SSH密钥</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
</feed>
