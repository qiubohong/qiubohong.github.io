<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qborfy知识库</title>
  
  
  <link href="https://www.qborfy.com/atom.xml" rel="self"/>
  
  <link href="https://www.qborfy.com/"/>
  <updated>2025-06-14T09:16:22.407Z</updated>
  <id>https://www.qborfy.com/</id>
  
  <author>
    <name>Qborfy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AI从零开始 - AI学习路线图(1) AI应用开发工程师</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn-road1.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn-road1.html</id>
    <published>2025-12-31T07:00:00.000Z</published>
    <updated>2025-06-14T09:16:22.407Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><blockquote><p>本文参考 <a href="https://roadmap.sh/">roadmap.sh</a> <a href="https://roadmap.sh/ai-engineer">AI Engineer(AI应用开发工程师)RoadMap</a>整理，如有侵权，请联系删除。</p></blockquote><p>学习一门技能最重要的是<strong>目标</strong>和<strong>路线</strong>：</p><ul><li>有了目标，才能知道自己所学可以用到哪里</li><li>有了路线，才能知道自己该学什么，怎么学</li></ul><span id="more"></span><h1 id="AI应用开发学习路线图"><a href="#AI应用开发学习路线图" class="headerlink" title="AI应用开发学习路线图"></a>AI应用开发学习路线图</h1><h2 id="完整思维导图"><a href="#完整思维导图" class="headerlink" title="完整思维导图"></a>完整思维导图</h2><p><img src="/assets/img/ailearn/ailearn-road1.png" alt="AI应用开发学习路线图"></p><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><p><img src="/assets/img/ailearn/ailearn-road11.png" alt="前置知识"></p><h2 id="入门能力"><a href="#入门能力" class="headerlink" title="入门能力"></a>入门能力</h2><p><img src="/assets/img/ailearn/ailearn-road12.png" alt="入门能力"></p><h2 id="进阶能力"><a href="#进阶能力" class="headerlink" title="进阶能力"></a>进阶能力</h2><p><img src="/assets/img/ailearn/ailearn-road13.png" alt="进阶能力"></p><h2 id="高级能力"><a href="#高级能力" class="headerlink" title="高级能力"></a>高级能力</h2><p><img src="/assets/img/ailearn/ailearn-road14.png" alt="高级能力"></p><h2 id="后续发展路线"><a href="#后续发展路线" class="headerlink" title="后续发展路线"></a>后续发展路线</h2><p><img src="/assets/img/ailearn/ailearn-road14.png" alt="后续发展路线"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://roadmap.sh/ai-engineer">AI Engineer RoadMap (AI应用开发工程师学习路线图)</a></li><li><a href="https://zhuanlan.zhihu.com/p/717978798">如何选择AI Agent框架？五种主流AI Agent框架对比</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;本文参考 &lt;a href=&quot;https://roadmap.sh/&quot;&gt;roadmap.sh&lt;/a&gt; &lt;a href=&quot;https://roadmap.sh/ai-engineer&quot;&gt;AI Engineer(AI应用开发工程师)RoadMap&lt;/a&gt;整理，如有侵权，请联系删除。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;学习一门技能最重要的是&lt;strong&gt;目标&lt;/strong&gt;和&lt;strong&gt;路线&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有了目标，才能知道自己所学可以用到哪里&lt;/li&gt;
&lt;li&gt;有了路线，才能知道自己该学什么，怎么学&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(4) - 神经网络</title>
    <link href="https://www.qborfy.com/ailearn/daily/04.html"/>
    <id>https://www.qborfy.com/ailearn/daily/04.html</id>
    <published>2025-06-29T07:00:00.000Z</published>
    <updated>2025-06-29T09:32:46.453Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>神经网络算法</strong></p><blockquote><p>一句话核心：“神经网络 = 模拟人脑的计算网络，通过层层传递数据自动学习规律，​​输入→加工→输出​​是它的核心工作流”</p></blockquote><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/04/1.png" alt=""></p><p><strong>定义</strong>: 人工神经网络（Artificial Neural Network，即ANN ），是20世纪80 年代以来人工智能领域兴起的研究热点。它从信息处理角度对人脑神经元网络进行抽象， 建立某种简单模型，按不同的连接方式组成不同的网络。</p><h2 id="三层功能"><a href="#三层功能" class="headerlink" title="三层功能"></a>三层功能</h2><ol><li><strong>输入层</strong>：接收数据（如28x28像素的手写数字图片）  </li><li><strong>隐藏层</strong>：层层提取特征（线条→局部图案→完整数字）  </li><li><strong>输出层</strong>：给出预测结果（概率最大的数字0-9）  </li></ol><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p>神经网络如何实现预测结果？</p><ol><li>神经元计算(积木拼装), 将所有数据(w1)+影响因子(x1)+权重(b)都输入到网络中，公式:<code>w1*x1+w2*x2+...+wn*xn+b</code></li><li>激活函数（质检开关）​, 判断当前数据输出是否符合要求</li><li>​​损失函数（误差雷达）​, 计算预测值和实际值之间的误差，公式:<code>loss = (y-y&#39;)^2</code></li><li>经过三个步骤，不断迭代，直到误差最小，得到预测结果公式:<code>y&#39; = f(w1*x1+w2*x2+...+wn*xn+b)</code></li></ol><p><img src="/assets/img/ailearn/daily/04/2.png" alt=""></p><h2 id="神经网络算法类型"><a href="#神经网络算法类型" class="headerlink" title="神经网络算法类型"></a>神经网络算法类型</h2><table><thead><tr><th><strong>类型</strong></th><th>特点</th><th>典型应用</th><th>在线实验</th></tr></thead><tbody><tr><td>全连接网络</td><td>每层神经元全部连接</td><td>房价预测</td><td>TF Playground回归任务</td></tr><tr><td>卷积网络CNN</td><td>局部感知/权重共享</td><td>人脸识别</td><td>CNN Explainer可视化</td></tr><tr><td>循环网络RNN</td><td>记忆之前状态</td><td>语音识别</td><td>Karpathy Char-RNN</td></tr><tr><td>Transformer</td><td>自注意力机制</td><td>ChatGPT</td><td>Hugging Face Demo</td></tr></tbody></table><h1 id="生活案例"><a href="#生活案例" class="headerlink" title="生活案例"></a>生活案例</h1><p><strong>快递分拣中心模型</strong>：  </p><ul><li>收货区（输入层）：接收全国包裹（原始数据）  </li><li>分拣线（隐藏层）：<br>→ 首站：按省份粗分（提取大特征）<br>→ 中转：按城市细分（识别局部特征）<br>→ 末站：按街道精分（确认细节）  </li><li>发货区（输出层）：送至具体地址（分类结果） </li></ul><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ul><li>GPT-3的神经元数量（1750亿）≈ 人类大脑神经元（860亿）的 <strong>2倍</strong>，  </li><li>但人脑能耗仅20瓦，而训练GPT-3需 <strong>190万度电</strong>（相当于200家庭年用电）！</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="http://easyai.tech/ai-definition/ann//">什么是人工神经网络？</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;神经网络算法&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：“神经网络 = 模拟人脑的计算网络，通过层层传递数据自动学习规律，​​输入→加工→输出​​是它的核心工作流”&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>10篇 AI从零开始 - Langgraph开发(1)</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn10.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn10.html</id>
    <published>2025-06-27T07:00:00.000Z</published>
    <updated>2025-06-28T14:24:51.058Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面我们学了LangChain的使用和Agent开发，Langchain是一个线性工作流，如果想要在实际开发复杂的Agent，那么实现非常麻烦，比如可能会遇上一以下一些问题：</p><ul><li>当调用某个工具方法出现错误或不是所需要的结果，需要循环调用工具方法直到返回需要的结果</li><li>当需要一次任务中，需要保存不同工作节点的状态</li><li>当需要调用不同LLM模型时候</li><li>当链路中断，需要从上一个工作节点继续执行</li><li>……</li></ul><p>为了解决这些问题，LangChain抽象出一个高级框架: <code>LangGraph</code>，接下来就开始学习LangGraph的开发。</p><span id="more"></span><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><blockquote><p>LangGraph 是一个用于构建、管理和部署长期运行、有状态代理的低级编排框架，受到塑造代理未来的公司（包括 Klarna、Replit、Elastic 等）的信赖。</p></blockquote><h2 id="主要架构"><a href="#主要架构" class="headerlink" title="主要架构"></a>主要架构</h2><p>一个LangGraph有状态(State)、节点(Node)、边(Egde)组成，如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn10-01.png" alt="LangGraph"></p><ul><li><strong>状态(State)</strong>：可以理解为Agent整体上下文，用于存储Agent运行过程中产生的数据，比如：任务状态、任务结果等</li><li><strong>节点(Node)</strong>：可以理解为Agent调用的工具或函数，用于表示Agent执行过程中的一个步骤，比如：调用LLM模型、调用Tool API等</li><li><strong>边(Edge)</strong>：可以理解为Agent执行下一节点所需要执行的逻辑判断， 用于表示节点之间的链接关系，比如：判断是直接返回给用户，还是调用Tool工具</li></ul><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li><strong>循环和分支</strong>：可以实现循环和条件判断</li><li><strong>持久性</strong>：在LangGraph中的每个节点Node后都会自动保存到状态State中，因此在任何时候暂时或异常中断都可以重新恢复</li><li><strong>人机交互</strong>：中断当前任务，是否允许当前节点执行还是跳过当前节点执行</li><li><strong>流Stream支持</strong>：支持流Stream输出</li><li><strong>LangChain无缝集成</strong>：LangGraph、LangChain、LangSimit 无缝集成，无需额外配置</li></ul><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装LangGraph LangChain  Ollama依赖的大模型</span></span><br><span class="line">pip install -U langgraph langchain langchain_ollama</span><br></pre></td></tr></table></figure><h2 id="Hello-World示例"><a href="#Hello-World示例" class="headerlink" title="Hello World示例"></a>Hello World示例</h2><p>接下来我们尝试实现一个大模型调用日期Tool工具函数，实现获取当前日期的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个日期工具函数</span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line"></span><br><span class="line"><span class="comment"># graph的各种节点与状态</span></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> END, StateGraph, MessagesState</span><br><span class="line"><span class="comment"># 持久化状态</span></span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"><span class="comment"># 调用工具的node节点</span></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_day</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取今天日期&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> datetime.now().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line"></span><br><span class="line">tools = [get_current_day]</span><br><span class="line"><span class="comment"># 创建工具节点</span></span><br><span class="line">tool_node = ToolNode(tools)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绑定工具列表到大模型中</span></span><br><span class="line">llm = ChatOllama(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:11434&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;qwen3:32b&quot;</span></span><br><span class="line">).bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义调用LLM大模型Node节点</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_llm</span>(<span class="params">state: MessagesState</span>):</span><br><span class="line">    messages = state[<span class="string">&#x27;messages&#x27;</span>]</span><br><span class="line">    response = llm.invoke(messages)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: response</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 定义工作流和初始化状态</span></span><br><span class="line">workflow = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 添加节点</span></span><br><span class="line">workflow.add_node(<span class="string">&quot;agent&quot;</span>, call_llm)</span><br><span class="line">workflow.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 定义工作流入口设定为agent</span></span><br><span class="line">workflow.set_entry_point(<span class="string">&quot;agent&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 添加条件边， agent有条件（是否继续执行函数判断）的流转线</span></span><br><span class="line"><span class="comment"># 定义函数，是否继续执行</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">should_continue</span>(<span class="params">state: MessagesState</span>) -&gt; <span class="type">Literal</span>[<span class="string">&quot;tools&quot;</span>, END]:</span><br><span class="line">    messages = state[<span class="string">&#x27;messages&#x27;</span>]</span><br><span class="line">    <span class="comment"># 获取最新的消息 判断是否应该调用工具</span></span><br><span class="line">    last_message = messages[-<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># LLM调用工具 则转到tools节点</span></span><br><span class="line">    <span class="keyword">if</span> last_message.tool_calls:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="keyword">return</span> END</span><br><span class="line"></span><br><span class="line">workflow.add_conditional_edges(</span><br><span class="line">    <span class="comment"># source 表示上一个节点输出的内容</span></span><br><span class="line">    <span class="string">&quot;agent&quot;</span>,</span><br><span class="line">    <span class="comment"># 接下来要执行的判断操作</span></span><br><span class="line">    should_continue,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5 添加tools到agent的普通链接，直接把tools返回内容给到agent</span></span><br><span class="line">workflow.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;agent&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6 添加checkpointer 经过每个节点都会保存到状态中，然后编译成LangChain链</span></span><br><span class="line"><span class="comment"># MemorySaver 支持redis、mongodb</span></span><br><span class="line">checkpointer = MemorySaver()</span><br><span class="line">app = workflow.<span class="built_in">compile</span>(checkpointer=checkpointer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7 执行graph</span></span><br><span class="line">final_state = app.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="string">&quot;今天几号&quot;</span>)]&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8 获取最终结果输出</span></span><br><span class="line">result = final_state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><p>执行上面的代码，我们可以获得到当前的日期，结果如下图：</p><p><img src="/assets/img/ailearn/ai-learn10-02.png" alt="LangGraph"></p><h2 id="多轮会话功能"><a href="#多轮会话功能" class="headerlink" title="多轮会话功能"></a>多轮会话功能</h2><p>上面我们实现了让Agent调用工具函数获取当天日期，接下来我们实现通过会话记录，让Agent可以根据之前的记录回答问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 7 执行graph 添加会话id</span></span><br><span class="line">final_state = app.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="string">&quot;今天几号&quot;</span>)]&#125;,</span><br><span class="line">    <span class="comment"># 这里config是配置是不是同一个会话的id</span></span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="number">42</span>&#125;&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8 获取最终结果输出</span></span><br><span class="line">result = final_state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 9 测试记录会话状态</span></span><br><span class="line">final_state = app.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="string">&quot;我刚刚问的哪天&quot;</span>)]&#125;,</span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="number">42</span>&#125;&#125;</span><br><span class="line">)</span><br><span class="line">result = final_state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><p>最终LLM大模型返回结果如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn10-03.png" alt="LangGraph"></p><p>上面代码执行完后，可以大概LangGraph执行过程有个初步了解，也可以通过生成Meraid Graph图片具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 10 保存Graph到本地图片</span></span><br><span class="line">graph_png = app.get_graph().draw_mermaid_png()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;langgraph1.png&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(graph_png)</span><br></pre></td></tr></table></figure><p>最终得到图片，如下图所示:<br><img src="/assets/img/ailearn/ai-learn10-04.png" alt="LangGraph"></p><ul><li><code>__start__</code>: 代表开始节点，也可以理解成初始化<code>StateGraph</code>工作流</li><li><code>agent</code>: 代表agent节点，设置了入口第一个节点，等同于<code>workflow.add_node(&quot;agent&quot;)</code></li><li><code>tools</code>: 代表工具节点，设置了工具节点，等同于<code>workflow.add_node(&quot;tools&quot;, tool_node)</code></li><li><code>实现连接线</code>: 代表当前节点执行完后，无需条件判断，直接流转到下一个节点，等同于<code>workflow.add_edge(&quot;tools&quot;, &quot;agent&quot;)</code></li><li><code>虚线连接线</code>: 代表条件边执行，当前节点执行完后，需要判断是否继续执行，如果继续执行则流转到下一个节点，否则流转到结束节点，等同于<code>workflow.add_conditional_edges(&quot;agent&quot;, should_continue)</code></li><li><code>_end</code>: 代表结束节点</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>经过上面学习，总结下本篇文章：</p><ul><li>LangGraph是LangChain的抽象而来的高级框架，能够实现更加复杂的工作流，如：循环、条件判断、多轮会话等</li><li>LangGraph的几个核心概念：<code>State</code>、<code>Node</code>、<code>Edge</code>等作用</li><li>一个<code>HelloWorld</code>的例子，可以看出比LangChain更加简单，加上State多轮会话记录功能，减少开发工作量</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://langchain-ai.github.io/langgraph/">LangGraph官方文档</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?p=10&share_source=copy_web&vd_source=ddb29dacf001bda27b38794cc29b82c8">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们学了LangChain的使用和Agent开发，Langchain是一个线性工作流，如果想要在实际开发复杂的Agent，那么实现非常麻烦，比如可能会遇上一以下一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当调用某个工具方法出现错误或不是所需要的结果，需要循环调用工具方法直到返回需要的结果&lt;/li&gt;
&lt;li&gt;当需要一次任务中，需要保存不同工作节点的状态&lt;/li&gt;
&lt;li&gt;当需要调用不同LLM模型时候&lt;/li&gt;
&lt;li&gt;当链路中断，需要从上一个工作节点继续执行&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了解决这些问题，LangChain抽象出一个高级框架: &lt;code&gt;LangGraph&lt;/code&gt;，接下来就开始学习LangGraph的开发。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(2) - 无监督学习</title>
    <link href="https://www.qborfy.com/ailearn/daily/02.html"/>
    <id>https://www.qborfy.com/ailearn/daily/02.html</id>
    <published>2025-06-26T07:00:00.000Z</published>
    <updated>2025-06-26T05:03:22.020Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>无监督学习</strong></p><blockquote><p>一句话核心：让AI在「没有标准答案」的数据中自己发现规律——像人类探索未知世界！</p></blockquote><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/02/1.png" alt=""></p><p><strong>定义</strong>：从未标记数据中挖掘隐藏模式，通常采用聚类、降维、关联等算法去发现数据中的规律。  </p><p>✅ 关键特征：无老师指导、数据无标签<br>❌ 常见误区 ≠ 完全不需要人类（仍需设计算法目标）</p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/02/2.png" alt=""></p><p>无监督学习，主要实现算法方案有以下三种：</p><ul><li>聚类：相似数据分组</li><li>降纬：压缩数据特征</li><li>关联：发现数据关联规律</li></ul><h2 id="聚类-K均值聚类-——-物以类聚"><a href="#聚类-K均值聚类-——-物以类聚" class="headerlink" title="聚类(K均值聚类) —— 物以类聚"></a>聚类(K均值聚类) —— 物以类聚</h2><p>主要解决问题： “哪些东西本质相似？”</p><p>例子： 自助餐厅菜品自动分区</p><ul><li>原始状态：200道菜杂乱摆放</li><li>聚类过程：<ul><li>✓ 算法检测菜品特征（烹饪方式/食材/口味）</li><li>✓ 自动划分为：海鲜刺身区、川湘热炒区、西式烘焙区</li></ul></li><li>价值：顾客5秒锁定目标区域</li></ul><h2 id="降维-PCA-——-去芜存菁"><a href="#降维-PCA-——-去芜存菁" class="headerlink" title="降维(PCA) —— 去芜存菁"></a>降维(PCA) —— 去芜存菁</h2><p>主要解决问题： “如何简化复杂信息？”</p><p>例子： 购房决策简化模型</p><ul><li>原始参数：20个维度（学区/通勤/绿化率/物业费…）</li><li>降维过程：<ul><li>✓ 算法提取核心特征 → 教育资源指数 &amp; 生活便利度</li><li>✓ 生成二维图谱</li></ul></li><li>价值：半小时锁定目标房源</li></ul><h2 id="关联（Association）——-发现隐藏规律"><a href="#关联（Association）——-发现隐藏规律" class="headerlink" title="关联（Association）—— 发现隐藏规律"></a>关联（Association）—— 发现隐藏规律</h2><p>主要解决问题： “哪些事总一起发生？”</p><p>例子： 便利店商品摆放策略</p><ul><li>原始数据：10万条购物小票</li><li>关联规则挖掘：<ul><li>{薯片，可乐} → {纸巾} [支持度=22%，置信度=81%]</li><li>规律：买零食饮料的顾客81%会顺手拿纸巾</li></ul></li><li>价值：收银台旁放置纸巾架→ 纸巾销量+35%</li></ul><h1 id="动手实验"><a href="#动手实验" class="headerlink" title="动手实验"></a>动手实验</h1><ul><li>聚类实操：用<code>K-means GUI</code>可视化分群过程 → <a href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/">在线查看</a></li><li>降维对比：在<code>TensorFlow Embedding Projector</code> 看词向量压缩 → <a href="https://projector.tensorflow.org/">在线查看</a></li><li>关联发现：通过Python实现超时购物车数据分析 →<a href="https://pbpython.com/market-basket-analysis.html">在线查看</a></li></ul><h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><ul><li>电商聚类：亚马逊用<code>DeepCluster</code>算法将商品分成27万类（比人工分类多19倍）</li><li>降维奇效：NASA用<code>t-SNE</code>分析星系图像，将数据处理时间从3周缩短到4小时</li><li>关联暴利：7-Eleven发现 <code>关东煮 + 清酒</code> 关联销售规律，冬季单店增收$6,800</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/unsupervised-learning/">一文学会无监督学习 – Unsupervised learning</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;无监督学习&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：让AI在「没有标准答案」的数据中自己发现规律——像人类探索未知世界！&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(3) - 强化学习</title>
    <link href="https://www.qborfy.com/ailearn/daily/03.html"/>
    <id>https://www.qborfy.com/ailearn/daily/03.html</id>
    <published>2025-06-26T07:00:00.000Z</published>
    <updated>2025-06-27T07:44:02.771Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>强化学习</strong></p><blockquote><p>一句话核心：AI在试错中成长，像小孩学走路，通过奖励/惩罚信号找到最优行为策略</p></blockquote><span id="more"></span><h1 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h1><p><img src="/assets/img/ailearn/daily/03/1.png" alt=""></p><p><strong>定义</strong>: 强化学习(reinforcement learning)，又称再励学习、评价学习，是一种重要的机器学习方法，在智能控制机器人及分析预测等领域有许多应用。</p><blockquote><p>百度百科： 在连接主义学习中，把学习算法分为三种类型，即<strong>非监督学习(unsupervised learning)</strong>、<strong>监督学习(supervised leaning)</strong>和<strong>强化学习</strong>。</p></blockquote><p>✅ 关键特征：奖励与惩罚</p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/03/2.png" alt=""></p><table><thead><tr><th><strong>维度</strong></th><th>免模型学习 (Model-Free)</th><th>有模型学习 (Model-Based)</th></tr></thead><tbody><tr><td><strong>核心思想</strong></td><td><strong>直接学习策略</strong></td><td><strong>先理解环境运作规则</strong></td></tr><tr><td>工作方式</td><td>试错→记下最佳动作</td><td>构建环境模拟器→规划行动</td></tr><tr><td>计算成本</td><td>低（不需模拟环境）</td><td>高（需建模环境动态）</td></tr><tr><td>适用场景</td><td>环境复杂难建模（如股票交易）</td><td>环境可精确仿真（如围棋）</td></tr><tr><td>代表算法</td><td>Q-Learning, DQN</td><td>动态规划, MCTS</td></tr><tr><td>—</td><td></td><td></td></tr></tbody></table><ul><li>免模型：当前状态 → 查表选最高Q值动作  </li><li>有模型：当前状态 → 模拟未来N步 → 选最优路径  </li></ul><h2 id="免模型学习"><a href="#免模型学习" class="headerlink" title="免模型学习"></a>免模型学习</h2><p><strong>案例：学骑电动车</strong></p><ul><li><strong>试错过程</strong><ul><li>右转时摔倒 → <strong>惩罚</strong>（痛觉信号）  </li><li>保持平衡前进 → <strong>奖励</strong>（速度感）  </li></ul></li><li><strong>关键特点</strong>：无需理解机械原理，靠肌肉记忆学习  </li></ul><h2 id="有模型学习"><a href="#有模型学习" class="headerlink" title="有模型学习"></a>有模型学习</h2><p><strong>案例：国际象棋对战</strong></p><ul><li><strong>建模过程</strong>：  <ul><li>先背棋谱（学习“兵走直线，象飞斜角”规则）  </li><li>大脑推演：“如果走车，对方可能有3种回应…”  </li></ul></li><li><strong>关键特点</strong>：依赖对环境的精确认知  </li></ul><p>免模型和有模型算法区别：</p><p><img src="/assets/img/ailearn/daily/03/3.png" alt=""></p><h1 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h1><h2 id="免模型案例：AlphaGo的走棋网络"><a href="#免模型案例：AlphaGo的走棋网络" class="headerlink" title="免模型案例：AlphaGo的走棋网络"></a>免模型案例：AlphaGo的走棋网络</h2><ul><li><strong>输入</strong>：棋盘当前状态  </li><li><strong>输出</strong>：直接评估落子位置价值  </li><li><strong>优势</strong>：省去推演计算，每秒决策100+次  </li><li><strong>工具复现</strong>：OpenAI Gym围棋环境  </li></ul><h2 id="有模型案例：特斯拉自动驾驶仿真"><a href="#有模型案例：特斯拉自动驾驶仿真" class="headerlink" title="有模型案例：特斯拉自动驾驶仿真"></a>有模型案例：特斯拉自动驾驶仿真</h2><ul><li><strong>环境模型</strong>：  <ul><li>物理引擎模拟雨天路滑  </li><li>神经网络生成行人行为  </li></ul></li><li><strong>优势</strong>：0风险试错百亿次  </li><li><strong>开发框架</strong>：CARLA仿真平台  </li></ul><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><ul><li>DeepMind用免模型 <strong>DQN</strong> 玩打砖块游戏，2小时超越人类水平，4小时发现开发者未预设的 <strong>挖地道秘籍</strong>  </li><li>波士顿动力机器人摔倒时<strong>调整姿态的算法</strong>，本质是免模型的 <strong>策略梯度（PPO）</strong>  </li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/reinforcement-learning/">一文学会强化学习-Reinforcement learning | RL</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一句话核心：AI在试错中成长，像小孩学走路，通过奖励/惩罚信号找到最优行为策略&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>5分钟AI，每天搞懂一个知识点(1) - 监督学习</title>
    <link href="https://www.qborfy.com/ailearn/daily/01.html"/>
    <id>https://www.qborfy.com/ailearn/daily/01.html</id>
    <published>2025-06-25T07:00:00.000Z</published>
    <updated>2025-06-26T04:38:16.393Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>今天我们来学习 <strong>监督学习</strong>。</p><h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><blockquote><p><strong>监督学习</strong>：让AI像学生一样，通过「带答案的习题集」学习总结出规律，然后根据规律应用到新的习题中。</p></blockquote><p>监督学习，是机器学习中的一种方式，把已经分类的数据给到数据模型，让模型自己学习规律，然后对没有分类的数据进行分类。</p><span id="more"></span><p><img src="/assets/img/ailearn/daily/01/1.png" alt=""></p><h1 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h1><p><img src="/assets/img/ailearn/daily/01/2.png" alt=""></p><p>怎么让AI模型根据训练数据，总结规律呢？主要分为两个类型：</p><ul><li>回归: 数值预测，数据是连续的、具体的</li><li>分类: 类别判断，数据是离散的</li></ul><p>一张图理解两者的区别<br><img src="/assets/img/ailearn/daily/01/3.png" alt=""></p><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><p>例子： 天气预测，连续数值（如温度）的预测。<br>预测目标​: 今天天气是多少度<br>​​常见算法​: 线性回归、决策树回归<br>提供训练数据：A(湿度)、B(风力)、C(海拔)、D(风向),Y(温度)<br>最终输出： Y = f(A,B,C,D) 公式 ，输入新的ABCD，的到最终天气温度</p><h2 id="分类任务"><a href="#分类任务" class="headerlink" title="分类任务"></a>分类任务</h2><p>例子： 动物分类， 离散类别数据（如：猫、狗）的预测。<br>预测目标​: 判断图片是猫还是狗<br>​​常见算法​: 逻辑回归、支持向量机<br>标签分值：眼睛(5)、鼻子(7)、耳朵(6)、嘴巴(7) = 猫， 眼睛(5)、鼻子(5)、耳朵(6)、嘴巴(7) = 狗<br>最终输出： 猫(20~40) ， 狗（42～60）输入图片的到最终分类</p><h1 id="动手试试！"><a href="#动手试试！" class="headerlink" title="动手试试！"></a>动手试试！</h1><p>打开 [Google Teachable Machine]  </p><ol><li>点击「图片项目」→ 创建「苹果」「橘子」分类  </li><li>用手机拍摄/上传20张样本  </li><li>点击「训练」→ 测试新图片识别效果！<br>🔗 工具链接：<a href="https://teachablemachine.withgoogle.com/">https://teachablemachine.withgoogle.com/</a></li></ol><h1 id="冷知识"><a href="#冷知识" class="headerlink" title="冷知识"></a>冷知识</h1><p>ImageNet数据集包含1400万张带标签图片，AI学习它相当于人类不眠不休看16年照片！</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://easyai.tech/ai-definition/supervised-learning/">一文学会监督学习 – Supervised learning</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们来学习 &lt;strong&gt;监督学习&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&quot;是什么&quot;&gt;&lt;a href=&quot;#是什么&quot; class=&quot;headerlink&quot; title=&quot;是什么&quot;&gt;&lt;/a&gt;是什么&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;监督学习&lt;/strong&gt;：让AI像学生一样，通过「带答案的习题集」学习总结出规律，然后根据规律应用到新的习题中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;监督学习，是机器学习中的一种方式，把已经分类的数据给到数据模型，让模型自己学习规律，然后对没有分类的数据进行分类。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="5分钟AI" scheme="https://www.qborfy.com/tags/5%E5%88%86%E9%92%9FAI/"/>
    
  </entry>
  
  <entry>
    <title>09篇 AI从零开始 - LangChain学习与实战(6) Agent智能体开发</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn09.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn09.html</id>
    <published>2025-05-26T07:00:00.000Z</published>
    <updated>2025-06-26T11:02:00.494Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面我们已经学习如何通过 Langchain调用独立部署的<code>DeepSeek-R1:32b</code>模型，且完成一些简单的应用，如： RAG 知识库的实现。</p><p>接下来我们学习如何通过LangChain实现一个Agent智能体，从而让 AI 模型帮忙实现做更多事情。</p><span id="more"></span><h1 id="1-Agent智能体"><a href="#1-Agent智能体" class="headerlink" title="1. Agent智能体"></a>1. Agent智能体</h1><h2 id="1-1-是什么"><a href="#1-1-是什么" class="headerlink" title="1.1 是什么"></a>1.1 是什么</h2><p>在开发之前我们先来了解下Agent智能体是什么，它主要解决什么问题？</p><blockquote><p>Agent是使用 LLM 大模型作为推理引擎的系统，用于确定应采取哪些行动(Action)以及这些行动输入应该是什么，然后会把行动的输出结果反馈给到Agent，用于判断是否需要更多行动或者结束然后输出返回。</p></blockquote><p>结合网上的资料和个人理解，Agent智能体的出现主要是解决以下问题：</p><ul><li>LLM大模型与人类之间的交互是基于 prompt 实现的，prompt 是否清晰明确会影响大模型回答的效果</li><li>LLM大模型只能进行推理，无法进行实际性的行动</li><li>LLM大模型只能单独使用，无法结合多个 LLM 大模型进行组合使用</li><li>LLM大模型只能输出文本，却无法符合用户需要的数据结构，如：如何标准的 JSON Schema</li><li>LLM大模型只能依据当前输入进行推理，无法进行长期记忆</li></ul><p>AI Agent是模仿人类思考技术，具体如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn09-1.png" alt=""></p><p><strong><em>一句话弄明白，就是AI大模型可以作为一个大脑进行学习推理，但是 Agent技术利用 LLM大模型的推理能力，能根据人类输入，代替人类去做一些真正想要的事情，最后输出人类真正想要结果或者去执行某些行动。</em></strong></p><p>为了更好理解 Agent技术， 我们可以看看目前AI协同工作类型，具体如下：</p><ol><li>Embbedding 模式: 人类输入目标，AI输出几个意见，人类自主决定采用哪个意见，代表产品为: RAG 智能客服机器人</li><li>Copilot 模式: 人类输入目标，AI经过几个流程确定初步输出，人类可以自由调整输出，代表产品为: <a href="https://github.com/features/copilot">Copilot代码提示</a></li><li>Agent 模式: 人类输入目标，AI 根据输入自主拆分任务，然后根据任务所需要的选择工具，最终完成任务最终结束，代表产品为: <a href="https://manus.im/">Manus AI 助手</a></li></ol><h2 id="1-2-怎么做"><a href="#1-2-怎么做" class="headerlink" title="1.2 怎么做"></a>1.2 怎么做</h2><p>上面说到Agent技术是模仿人类思考技术，利用大模型进行推理，拆分人类输入的任务，那么 Agent其实最大的重点在于激发 LLM 大模型的推理能力，去拆分人类输入的任务。</p><p>那么如何激发 LLM 大模型的推理能力呢？ 主要有以下几点：</p><h3 id="1-Prompt-的思考链"><a href="#1-Prompt-的思考链" class="headerlink" title="1. Prompt 的思考链"></a>1. Prompt 的思考链</h3><blockquote><p>思维链（Chain of Thoughts）已成为一种标准的提示技术，用于提高模型在复杂任务中的表现。模型被要求 “一步一步地思考”，将艰巨的任务分解为更小更简单的步骤。思维链将大任务转化为多个可管理的任务，并帮助人们理解模型的思维过程。</p></blockquote><p>无思考链的 Prompt：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">问：罗杰有5个网球，他又买了两盒网球，每盒有3个网球。他现在有多少网球？</span><br><span class="line">答：答案是11</span><br><span class="line">问：食堂有23个苹果，如果他们用掉20个后又买了6个。他们现在有多少个苹果？</span><br><span class="line">模型输出：</span><br><span class="line">答：答案是27</span><br></pre></td></tr></table></figure><p>有思考链的 Prompt：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">问：罗杰有5个网球，他又买了两盒网球，每盒有3个网球。他现在有多少网球？</span><br><span class="line">答：罗杰一开始有5个网球，2盒3个网球，一共就是2*3=6个网球，5+6=11。答案是11.</span><br><span class="line">问：食堂有23个苹果，如果他们用掉20个后又买了6个。他们现在有多少个苹果？</span><br><span class="line">模型输出：</span><br><span class="line">答：食堂原来有23个苹果，他们用掉20个，所以还有23-20=3个。他们又买了6个，所以现在有6+3=9。答案是9 </span><br></pre></td></tr></table></figure><p>PS: <code>DeepSeek</code>的推理模式出来后，现在大部分模型默认就支持思考链的回答了。</p><p><strong>思维树</strong> 是思维链的另一种表现形式，通过在任务的每一步探索多种推理可能性来扩展思维链。它首先将问题分解为多个思考步骤，并在每个步骤中生成多个想法，从而创建一个树状结构。试错和纠错在现实世界的任务决策中是不可避免且至关重要的步骤。自我反思帮助 AI Agent 完善过去的行动决策、纠正以前的错误、从而不断改进。主要可以包括以下几种模式：</p><ol><li>ReAct: 结合推理（Reasoning）和行动（Action）​​，动态与环境交互。简单的理解就是: 推理+动作。</li><li>Reflexion: 让 AI Agent 具备动态记忆和自我反思能力以提高推理能力的框架。简单的理解就是: 重复步骤（记忆+推理+动作）。</li><li>Hindsight: 利用已知结果优化过去决策​​，从失败经验中学习。简单理解就是: 根据已知结果进行反向推理。</li></ol><h3 id="2-记忆"><a href="#2-记忆" class="headerlink" title="2. 记忆"></a>2. 记忆</h3><blockquote><p>记忆模块负责存储信息，包括过去的交互、学习到的知识，甚至是临时的任务信息。</p></blockquote><p>AI有了记忆后，就可以根据已知的记忆知识去更好回答用户提问。而在 AI Agent 定义里：</p><blockquote><p>用户在与其交互过程中产生的内容都可以认为是 Agent 的记忆，和人类记忆的模式能够产生对应关系。</p></blockquote><p>记忆可以分为几类：</p><ul><li>感觉记忆: 初始输入文本、图片等数据，如：看一张照片后，当不看照片，还能想起照片的印象，这是感觉记忆</li><li>短期记忆: 本次与 AI 对话的上下文，如：进行记忆几个数字，短期内还是可以记住这几个数字，这就是短期记忆</li><li>长期记忆: Agent在工作时需要查询向量数据库，如：学会骑自行车，及时很长时间没骑自行车，但是骑自行车这个技能还在，那么骑自行车这个技能就是长期记忆</li></ul><p>而针对记忆这方面的技术， Embedding 技术和向量相似度计算就是记忆（向量数据库的核心），具体可以做以下理解：</p><ul><li>Embedding 技术：将文本、图片等数据转换为向量，从而实现记忆功能</li><li>向量相似度计算：通过数学方法来计算两个向量之间的相似度，常见的算法有：余弦相似度、欧式距离、汉明距离等，通过相似度计算可以判断两个向量是否相似，从而获取我们所需要的记忆数据</li></ul><h3 id="3-工具"><a href="#3-工具" class="headerlink" title="3. 工具"></a>3. 工具</h3><blockquote><p>AI 懂得使用工具才会更像人类。</p><p>AI Agent 除了记忆，还需要在获取到每一步子任务的工作后，Agent 都会判断是否需要通过调用外部工具来完成该子任务，并在完成后获取该外部工具返回的信息提供给 LLM，进行下一步子任务的工作。</p></blockquote><p>目前AI 大模型接入工具的使用方式如下：</p><ol><li>函数调用(Function Call): 向大模型描述函数，如：函数的作用和参数结构（如：JSON对象），从让 AI 大模型在执行任务能够调用外部工具，如：<code>open(&quot;test.txt&quot;)</code></li><li>插件系统​(Plugin)​:通过标准化接口扩展大模型能力，等同于公共的函数调用，让大家都能用。</li><li>模型内嵌工具: 不同模型会提供不同内置工具，如：OpenAI 的<code>file_search</code>和<code>code_interpreter</code>，能AI直接调用去搜索文件和解析文件的能力。</li></ol><p>目前绝大部分 AI Agent开发使用的工具的方式都是 <code>Function Call</code>的方式，目前主流大模型基本都支持这个能力，具体如下：</p><table><thead><tr><th>模型</th><th>支持Function Call</th><th>说明</th></tr></thead><tbody><tr><td>GPT-4 Turbo、GPT-4o、GPT-3.5 Turbo</td><td>是</td><td>OpenAI 系列模型，闭源</td></tr><tr><td>​Claude 3（Opus/Sonnet/Haiku）、Claude 3.5</td><td>是</td><td>Anthropic 系列模型，闭源​</td></tr><tr><td>Gemini Pro、Gemini 1.5 Pro、Gemini Flash</td><td>是</td><td>OpenAI 系列模型，闭源​</td></tr><tr><td>Llama 3（8B/70B）、Llama 3.1</td><td>是</td><td>Meta Llama 系列​，开源​， 需要微调后才支持，不过有现成的 Gorilla 微调框架</td></tr><tr><td>Mistral Large、Mistral-7B-Instruct</td><td>是</td><td>Mistral AI 系列​，开源​，轻量级模型适合本地部署​</td></tr><tr><td>通义千问（Qwen-Chat）</td><td>是</td><td>阿里云系列​ ​，开源​，基于 ReAct Prompting 原理优化工具</td></tr><tr><td>GLM-Z1-32B-0414、ChatGLM3-6B</td><td>是</td><td>清华智谱系列模型，开源​</td></tr><tr><td>​​DeepSeek V3​​</td><td>是</td><td>​​DeepSeek，开源​，专为函数调用优化，支持多工具协同</td></tr></tbody></table><h1 id="2-Langchain-AI-Agent开发实战"><a href="#2-Langchain-AI-Agent开发实战" class="headerlink" title="2. Langchain AI Agent开发实战"></a>2. Langchain AI Agent开发实战</h1><p>完整了解 Agent的知识后，解析来我们要通过Langchain框架去实现一个 AI Agent，获取获取当天的龙虎榜数据。</p><h2 id="2-1-基础概念"><a href="#2-1-基础概念" class="headerlink" title="2.1 基础概念"></a>2.1 基础概念</h2><ul><li><code>langchain_core.tools.tool</code>: Langchain用来创建工具的方法</li><li><code>langchain.agents.create_tool_calling_agent</code>: 创建工具调用Agent的函数</li><li><code>langchain.agents.AgentExecutor</code>: 创建 Agent执行器的类</li></ul><p>开始实现思路如下：</p><ol><li>编写工具函数和工具描述</li><li>创建LLM模型</li><li>创建符合工具调用Agent的Prompt</li><li>创建Agent和 AgentExecutor</li><li>通过LangSmith查看 Agent执行过程（调试使用）</li></ol><h2 id="2-2-工具声明"><a href="#2-2-工具声明" class="headerlink" title="2.2 工具声明"></a>2.2 工具声明</h2><h3 id="获取当前日期"><a href="#获取当前日期" class="headerlink" title="获取当前日期"></a>获取当前日期</h3><p>接下来我们声明一个工具函数，用于解决大模型无法判断当前的日期。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_day</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取今天的时间&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> date.today().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="获取龙虎榜数据"><a href="#获取龙虎榜数据" class="headerlink" title="获取龙虎榜数据"></a>获取龙虎榜数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入参数格式说明</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LhbInput</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    date: <span class="built_in">str</span> = Field(description=<span class="string">&quot;date,  format is YYYY-MM-DD&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool(<span class="params">args_schema=LhbInput</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_lhb</span>(<span class="params">date: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取龙虎榜数据&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始获取%s龙虎榜&quot;</span> % date)</span><br><span class="line">    callback = <span class="string">&quot;jQuery1123029212767559503716_1747729555061&quot;</span></span><br><span class="line">    url = <span class="string">f&quot;https://datacenter-web.eastmoney.com/api/data/v1/get?callback=<span class="subst">&#123;callback&#125;</span>&amp;sortColumns=SECURITY_CODE%2CTRADE_DATE&amp;sortTypes=1%2C-1&amp;pageSize=200&amp;pageNumber=1&amp;reportName=RPT_DAILYBILLBOARD_DETAILSNEW&amp;columns=SECURITY_CODE%2CSECUCODE%2CSECURITY_NAME_ABBR%2CTRADE_DATE%2CEXPLAIN%2CCLOSE_PRICE%2CCHANGE_RATE%2CBILLBOARD_NET_AMT%2CBILLBOARD_BUY_AMT%2CBILLBOARD_SELL_AMT%2CBILLBOARD_DEAL_AMT%2CACCUM_AMOUNT%2CDEAL_NET_RATIO%2CDEAL_AMOUNT_RATIO%2CTURNOVERRATE%2CFREE_MARKET_CAP%2CEXPLANATION%2CD1_CLOSE_ADJCHRATE%2CD2_CLOSE_ADJCHRATE%2CD5_CLOSE_ADJCHRATE%2CD10_CLOSE_ADJCHRATE%2CSECURITY_TYPE_CODE&amp;source=WEB&amp;client=WEB&amp;filter=%28TRADE_DATE%3C%3D%27<span class="subst">&#123;date&#125;</span>%27%29%28TRADE_DATE%3E%3D%27<span class="subst">&#123;date&#125;</span>%27%29&quot;</span></span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    content = response.content.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    content = content.split(callback + <span class="string">&quot;(&quot;</span>)[<span class="number">1</span>].split(<span class="string">&quot;);&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> json.loads(content).get(<span class="string">&quot;result&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="2-3-创建LLM模型"><a href="#2-3-创建LLM模型" class="headerlink" title="2.3 创建LLM模型"></a>2.3 创建LLM模型</h2><p>不同的模型对于工具调用不同， 目前已知支持最好的模型是<code>GPT-4 Turbo</code>， 但是这个模型是闭源的， 国内支持较好是 DeepSeek但是也收费，对于调试模型更加友好可以利用g模型厂商 - <a href="https://cloud.siliconflow.cn/models">siliconflow AI 云服务平台</a>，从而减少我们的调试成本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">api_key = <span class="string">&quot;xxxxxx&quot;</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    base_url=<span class="string">&quot;https://api.siliconflow.cn&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-235B-A22B&quot;</span>, <span class="comment"># 这里可以更换不同模型 更好的达到实现效果</span></span><br><span class="line">    api_key=api_key</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="2-4-创建Prompt"><a href="#2-4-创建Prompt" class="headerlink" title="2.4 创建Prompt"></a>2.4 创建Prompt</h2><p>Prompt对于LLM大模型的实现有关键作用， 其中<code>agent_scratchpad</code>的占位符对于 AI 大模型实现非常重要，主要用于 ​​记录和传递 Agent 执行过程中的中间推理步骤，同时还会强制按照 tool所需要的参数进行输入调用。</p><p>Prompt 具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是人工智能助手&quot;</span>),</span><br><span class="line">        MessagesPlaceholder(variable_name=<span class="string">&quot;agent_scratchpad&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="2-5-创建Agent和-AgentExecutor"><a href="#2-5-创建Agent和-AgentExecutor" class="headerlink" title="2.5 创建Agent和 AgentExecutor"></a>2.5 创建Agent和 AgentExecutor</h2><p>创建Agent, Langchain也提供不同的类型，如下：</p><ul><li>Tool Calling Agent (create_tool_calling_agent)​ ： 依赖模型原生工具调用能力，自动将工具描述注入模型上下文， 直接返回工具调用参数对象，部分LLM模型支持</li><li>ReAct Agent (create_react_agent)​ ： 遵循 Thought → Action → Observation 循环，每步根据上下文选择工具，结合自然语言与工具调用</li><li>​​Structured Chat Agent (create_structured_chat_agent)​：必须遵循预定义响应模板，严格匹配工具参数格式，通常一次性完成工具选择</li></ul><p>目前我们使用的是 <code>create_tool_calling_agent</code>， 具体实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_tool_calling_agent, AgentExecutor</span><br><span class="line"></span><br><span class="line">tools = [get_current_day, get_lhb]</span><br><span class="line"></span><br><span class="line">agent = create_tool_calling_agent(llm, tools, prompt)</span><br><span class="line"></span><br><span class="line">agent_executor = AgentExecutor(</span><br><span class="line">    agent=agent, </span><br><span class="line">    tools=tools, </span><br><span class="line">    handle_parsing_errors=<span class="literal">True</span>, </span><br><span class="line">    verbose=<span class="literal">True</span>, <span class="built_in">format</span>=<span class="string">&quot;json&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line"><span class="built_in">print</span>(agent_executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;帮我查询一下今天的龙虎榜数据&quot;</span>&#125;))</span><br></pre></td></tr></table></figure><p>PS:</p><ul><li><code>handle_parsing_errors</code>: 当 Agent执行发生异常的时候，如传入参数不符合工具描述，是否抛出异常，当为 True错误信息会通过 intermediate_steps 传递到下一轮推理，模型基于历史步骤中的错误反馈重新生成正确的工具调用指令</li><li><code>verbose</code>: 是否打印中间步骤，从而更好的理解模型推理过程</li></ul><p>以下是完整代码实现过程截图：</p><p><img src="/assets/img/ailearn/ai-learn09-2.png" alt=""><br><img src="/assets/img/ailearn/ai-learn09-3.png" alt=""></p><h2 id="2-6-Smith调试"><a href="#2-6-Smith调试" class="headerlink" title="2.6  Smith调试"></a>2.6  Smith调试</h2><p>在 Agent中避免不了调试，尤其不同大模型对于工具的调用和判断是不一样的，同时执行过程异常 Langchain也比较难定位，所以因此我们可以使用<code>LangSmith</code>进行调试。</p><p>前往<a href="https://smith.langchain.com/">LangSmith</a>官网，注册账号，创建项目，获取API_KEY，设置环境变量，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置LangSimth 环境变量</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_TRACING&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_ENDPOINT&quot;</span>] = <span class="string">&quot;https://api.smith.langchain.com&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_API_KEY&quot;</span>] = <span class="string">&quot;&lt;LANGSMITH_API_KEY&gt;&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_PROJECT&quot;</span>] = <span class="string">&quot;test_agent&quot;</span></span><br></pre></td></tr></table></figure><p>再次运行Agent，可以前往<a href="https://smith.langchain.com/">LangSmith</a>查看调试结果，如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn09-4.png" alt=""></p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h1><p>AI Agent的实现，对于我们来说，可以更好的理解大模型的能力，同时也可以更好的利用大模型能力，从而更好的实现业务场景。 回顾一下，AI Agent的知识点：</p><ol><li>AI Agent是利用 AI 大模型的推理能力，结合记忆+工具调用能力，实现扩展 AI 大模型能力的一种技术方案</li><li>实现 AI Agent的方案有目前主流是通过大模型  Function Call</li><li>实现 AI Agent中的 Prompt中，<code>agent_scratchpad</code>占位符是非常重要，记录和传递 Agent 执行过程中的中间推理步骤，同时还会强制按照 tool 所需要的参数进行输入调用。</li></ol><p>以上就是 AI Agent的实现过程，希望对你有所帮助。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li><li><a href="https://zhuanlan.zhihu.com/p/694458202">Langchain Agent - Agent类型说明</a></li><li><a href="https://www.cnblogs.com/huaweiyun/p/18289995">万字长文解析AI Agent技术原理和应用</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们已经学习如何通过 Langchain调用独立部署的&lt;code&gt;DeepSeek-R1:32b&lt;/code&gt;模型，且完成一些简单的应用，如： RAG 知识库的实现。&lt;/p&gt;
&lt;p&gt;接下来我们学习如何通过LangChain实现一个Agent智能体，从而让 AI 模型帮忙实现做更多事情。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>11篇 AI从零开始 - Langgraph开发(2)</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn11.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn11.html</id>
    <published>2025-03-31T07:00:00.000Z</published>
    <updated>2025-06-29T09:00:13.459Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="工作流是什么"><a href="#工作流是什么" class="headerlink" title="工作流是什么"></a>工作流是什么</h1><p>前面我们对LangGraph知识有一个基础入门，如果要完成一个真正的Agent工作流应用开发，还是远远不够的。</p><p>一个复杂且完整的Agent工作流应用，需要完成以下几个方面：</p><ol><li>确定工作流目标，如：规划未来的旅游行程</li><li>按照目标规划和拆分任务清单，如：预定酒店、饮食推荐、景点参观时间等等</li><li>单执行任务（包含异常中断且重试机制），如：预定酒店</li><li>更新任务状态给工作流，如：预定酒店成功或失败</li><li>对任务清单状态进行重新思考或规划，如：预定酒店失败后需要重试其他渠道</li><li>对任务状态反馈给到用户，如：给用户酒店预定失败，是否选择其他渠道预定</li></ol><span id="more"></span><p>具体可如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn11-01.png" alt="LangGraph"></p><p>这里我们可以和<code>ReAct</code> 推理+输出风格的Agent做对比，这种属于<code>Reflexion</code>自我反思+动态记忆的Agent模式，有以下几个优点：</p><ul><li>只需要在规划拆分任务清单的时候使用能力强的大模型</li><li>其他任务执行，可以使用能力小的大模型或者不需要大模型参与</li></ul><p>我们可以根据下图对比，加深工作流和Agent模式的区别：</p><p><img src="/assets/img/ailearn/ai-learn11-02.png" alt="LangGraph"></p><h1 id="实现工作流"><a href="#实现工作流" class="headerlink" title="实现工作流"></a>实现工作流</h1><p>目标：实现一个简单的<a href="https://formilyjs.org/zh-CN">formily表单</a>生成助手工作流</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;工作流是什么&quot;&gt;&lt;a href=&quot;#工作流是什么&quot; class=&quot;headerlink&quot; title=&quot;工作流是什么&quot;&gt;&lt;/a&gt;工作流是什么&lt;/h1&gt;&lt;p&gt;前面我们对LangGraph知识有一个基础入门，如果要完成一个真正的Agent工作流应用开发，还是远远不够的。&lt;/p&gt;
&lt;p&gt;一个复杂且完整的Agent工作流应用，需要完成以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;确定工作流目标，如：规划未来的旅游行程&lt;/li&gt;
&lt;li&gt;按照目标规划和拆分任务清单，如：预定酒店、饮食推荐、景点参观时间等等&lt;/li&gt;
&lt;li&gt;单执行任务（包含异常中断且重试机制），如：预定酒店&lt;/li&gt;
&lt;li&gt;更新任务状态给工作流，如：预定酒店成功或失败&lt;/li&gt;
&lt;li&gt;对任务清单状态进行重新思考或规划，如：预定酒店失败后需要重试其他渠道&lt;/li&gt;
&lt;li&gt;对任务状态反馈给到用户，如：给用户酒店预定失败，是否选择其他渠道预定&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>11篇 AI从零开始 - Langgraph开发(2)</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn12.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn12.html</id>
    <published>2025-03-31T07:00:00.000Z</published>
    <updated>2025-06-29T02:18:59.467Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>回顾一下LangChain系列学习文章：</p><ul><li><a href="https://qborfy.com/ailearn/ai-learn04.html">04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</a></li><li><a href="https://qborfy.com/ailearn/ai-learn05.html">05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉</a></li><li><a href="https://qborfy.com/ailearn/ai-learn06.html">06篇 AI从零开始 - LangChain学习与实战(3) LCEL工作流编排原理与实战</a></li><li><a href="https://qborfy.com/ailearn/ai-learn07.html">07篇 AI从零开始 - LangChain学习与实战(4) LangServer部署</a></li><li><a href="https://qborfy.com/ailearn/ai-learn08.html">08篇 AI从零开始 - LangChain学习与实战(5) 基于RAG开发问答机器人</a></li></ul><p>经过LangChain系列文章的学习后， 现在我们需要通过 LangChain + 大模型 + 低代码平台， 开发具备实际功能的 AI 应用：</p><blockquote><p><strong>低代码平台AI助手</strong>：通过用户输入自然语言能实现 低代码平台页面生成、编辑等</p></blockquote><span id="more"></span><h1 id="1-前期与实现方案"><a href="#1-前期与实现方案" class="headerlink" title="1. 前期与实现方案"></a>1. 前期与实现方案</h1><p>目标：通过用户输入自然语言能实现，完成低代码平台页面的生成，同时能低代码平台页面组件元素进行属性调整。</p><p>实际原理： 利用 AI大模型实现用户输入的自然语言与低代码平台特定 DSL语言（JSON Schema）互相转换</p><h2 id="1-1-前期准备"><a href="#1-1-前期准备" class="headerlink" title="1.1 前期准备"></a>1.1 前期准备</h2><ol><li>搭建低代码平台服务，可以参考文档： <a href="https://formilyjs.org/zh-CN/guide/form-builder">Formily 表单设计器</a></li><li>Langchain 和 LangServer环境准备， 参考： <a href="https://qborfy.com/ailearn/ai-learn04.html">04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</a></li></ol><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ol><li>LangChain开发实现大模型理解低代码平台DSL语言的输入，并能输出是低代码平台DSL语言</li><li>通过 LangServer提供大模型 API<ol><li>输入当前页面 json schema</li><li>用户输入自然语言，LangServer调用大模型API，返回结果</li><li>LangServer将返回结果转换成低代码平台DSL语言</li></ol></li><li>低代码平台新增 AI助手 UI，更改低代码页面JSON内容 </li></ol><h1 id="2-实战开发"><a href="#2-实战开发" class="headerlink" title="2. 实战开发"></a>2. 实战开发</h1><h2 id="2-1-LangChain-Agent-Server开发"><a href="#2-1-LangChain-Agent-Server开发" class="headerlink" title="2.1 LangChain Agent + Server开发"></a>2.1 LangChain Agent + Server开发</h2><h2 id="2-2-Formily-插件-AI-助手前端开发"><a href="#2-2-Formily-插件-AI-助手前端开发" class="headerlink" title="2.2 Formily 插件 AI 助手前端开发"></a>2.2 Formily 插件 AI 助手前端开发</h2><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li><li><a href="https://zhuanlan.zhihu.com/p/694458202">Langchain Agent - Agent类型说明</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><p>对 Agent的一些思考， 首先 agent本身的  Prompt很重要， LLM 大模型会依据Prompt+用户输入去判断需要使用哪个工具</p><p>然后创建Agent, Langchain也提供不同的类型，如下：</p><ul><li>Tool Calling Agent (create_tool_calling_agent)​ ： 依赖模型原生工具调用能力，自动将工具描述注入模型上下文， 直接返回工具调用参数对象，部分LLM模型支持</li><li>ReAct Agent (create_react_agent)​ ： 遵循 Thought → Action → Observation 循环，每步根据上下文选择工具，结合自然语言与工具调用</li><li>​​Structured Chat Agent (create_structured_chat_agent)​：必须遵循预定义响应模板，严格匹配工具参数格式，通常一次性完成工具选择</li></ul><p>利用 Agent 开发一个完整的低代码平台 AI 助手，整体实现过程如下：</p><p><a href="https://langchain-ai.github.io/langgraph/agents/agents/#1-install-dependencies">https://langchain-ai.github.io/langgraph/agents/agents/#1-install-dependencies</a></p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;回顾一下LangChain系列学习文章：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn04.html&quot;&gt;04篇 AI从零开始 - LangChain学习与实战(1) 基础知识&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn05.html&quot;&gt;05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn06.html&quot;&gt;06篇 AI从零开始 - LangChain学习与实战(3) LCEL工作流编排原理与实战&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn07.html&quot;&gt;07篇 AI从零开始 - LangChain学习与实战(4) LangServer部署&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn08.html&quot;&gt;08篇 AI从零开始 - LangChain学习与实战(5) 基于RAG开发问答机器人&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;经过LangChain系列文章的学习后， 现在我们需要通过 LangChain + 大模型 + 低代码平台， 开发具备实际功能的 AI 应用：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;低代码平台AI助手&lt;/strong&gt;：通过用户输入自然语言能实现 低代码平台页面生成、编辑等&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>08篇 AI从零开始 - LangChain学习与实战(5) 基于RAG开发问答机器人</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn08.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn08.html</id>
    <published>2025-03-15T07:00:00.000Z</published>
    <updated>2025-06-07T01:58:54.348Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面几篇学习LangChain，基本上完成对 LangChain从开发到上线有一个整体的了解，那么接下来我们就要开始实战了，我们将会使用LangChain开发一个问答机器人，这个问答机器人将会使用到RAG模型，那么接下来我们开始学习RAG。</p><span id="more"></span><h1 id="RAG是什么"><a href="#RAG是什么" class="headerlink" title="RAG是什么"></a>RAG是什么</h1><blockquote><p>RAG是一种用额外数据增强大模型知识的技术，俗称“RAG”（Retrieval-Augmented Generation），中文叫检索增强生成。</p></blockquote><p>RAG是LangChain中一个重要的应用场景，它能够将检索和生成结合起来，从而生成更加精准的答案。</p><p>RAG模型由两个部分组成：Retriever和Generator。</p><ul><li><code>Generator</code> 生成索引向量，根据文档中问题和答案生成索引向量数据库。</li><li><code>Retriever</code> 检索对比类似，根据用户的问题，从生成的知识库中检索召回最相关的问题和答案。</li></ul><p>RAG技术是通过检索和生成相结合的方式找最相关的知识内容， 加入到大模型的提示语中，通过大模型推理得到用户问题在知识库中最合适的答案。</p><p>下面是我个人依据网上相关资料整理的通用RAG模型架构图：</p><p><img src="/assets/img/ailearn/ai-learn08-1.png" alt=""></p><h2 id="生成向量索引（Indexing）"><a href="#生成向量索引（Indexing）" class="headerlink" title="生成向量索引（Indexing）"></a>生成向量索引（Indexing）</h2><p>生成向量索引有三个步骤，分别如下：</p><ol><li>加载(load)，加载所需数据，LangChain中提供各种加载器，如：PDFLoader、TextLoader、ImageLoader等。</li><li>分割(Split)，将加载的数据进行分割成一个个块，LangChain中提供各种分割器，如：TextSplitter、ImageSplitter等。</li><li>存储(Store)，得到分割的Chunks，需要将Chunk转成向量索引并存储，这里我们会依赖<code>Embeddings</code>模型进行生成索引，然后存储到向量数据库<code>VectorStore</code>。</li></ol><h2 id="Embeddings嵌入模型"><a href="#Embeddings嵌入模型" class="headerlink" title="Embeddings嵌入模型"></a>Embeddings嵌入模型</h2><p>RAG模型使用<code>Embeddings</code>模型将问题和答案进行编码，生成向量数据，这里我们必不可免需要对<code>Embeddings</code>模型进行初步了解。</p><blockquote><p>Embeddings模型，也叫嵌入模型，是一种将高维度的数据，如：自然语言、图片、视频等，转换成低维度的向量数据，如：多维矩阵数组等，方便后续进行相似度对比。</p></blockquote><p>或者我们可以更加直观的理解，<code>Embeddings</code>模型可以把我们人类能够理解的内容，转换成计算机能够计算理解的数据，从而实现更多的算法对比逻辑。</p><h2 id="检索和生成"><a href="#检索和生成" class="headerlink" title="检索和生成"></a>检索和生成</h2><ol><li>检索：通过用户输入的内容，使用检索器将内容转换为向量，然后从向量数据库中检索最相关的向量数据。</li><li>生成：通过检索器检索到的向量数据，使用生成器生成新的向量数据，然后存储到向量数据库中。</li></ol><p>这两个步骤一般都是同时进行，一般也是 通过Embeddings嵌入模型去转换搜索内容为向量，然后通过检索到最后生成内容。</p><h1 id="实战：做一个问答机器人"><a href="#实战：做一个问答机器人" class="headerlink" title="实战：做一个问答机器人"></a>实战：做一个问答机器人</h1><h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><ol><li>用户上传问题知识内容上传文件</li><li>服务端对上传文件进行解析，拆分chunk</li><li>将 chunk 传给 Embeddings模型，生成向量索引</li><li>将 向量索引存储到向量数据库中</li><li>用户输入问题，通过检索器检索到最相关的向量数据</li><li>然后将最相关向量数据传给对话大模型，组织推理得到答案，返回给用户</li></ol><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>Ollama安装模型：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对话大模型</span></span><br><span class="line">ollama install deepseek-r1:7b</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">embeddings模型</span></span><br><span class="line">ollama install shaw/dmeta-embedding-zh:latest</span><br></pre></td></tr></table></figure><p>LangChain和  Streamlit安装</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python环境 3.12.4</span></span><br><span class="line"><span class="comment"># streamlit 1.39.0</span></span><br><span class="line"><span class="comment"># toml</span></span><br><span class="line"></span><br><span class="line">pip install langchain</span><br><span class="line">pip install streamlit</span><br></pre></td></tr></table></figure><p><code>requirements.txt</code>文件内容如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">streamlit==1.39.0</span><br><span class="line">langchain==0.3.21</span><br><span class="line">langchain-chroma==0.2.2</span><br><span class="line">langchain-community==0.3.20</span><br><span class="line">langchain-ollama==0.2.3</span><br></pre></td></tr></table></figure><blockquote><p>streamlit是构建和共享数据应用程序的更快方法， 几分钟内将您的数据脚本转换为可共享的网络应用程序，全部采用纯 Python 编写，无需前端经验。<br>官方文档：<a href="https://docs.streamlit.io/get-started/installation">https://docs.streamlit.io/get-started/installation</a></p></blockquote><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>新建一个文件<code>bot_chat.py</code>， 分步骤实现。</p><h3 id="1-stremlit页面搭建"><a href="#1-stremlit页面搭建" class="headerlink" title="1. stremlit页面搭建"></a>1. stremlit页面搭建</h3><p>代码参考如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 st 的标题和布局</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;RAG测试问答&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置应用标题</span></span><br><span class="line">st.title(<span class="string">&quot;RAG测试问答&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持上传 txt 文件</span></span><br><span class="line">upload_file = st.sidebar.file_uploader(label=<span class="string">&quot;上传文件&quot;</span>, <span class="built_in">type</span>=[<span class="string">&quot;txt&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> upload_file:</span><br><span class="line">    st.info(<span class="string">&quot;请上传 txt 文件&quot;</span>)</span><br><span class="line">    st.stop()</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><p><img src="/assets/img/ailearn/ai-learn08-2.png" alt=""></p><h3 id="2-解析文档并生成知识库检索器"><a href="#2-解析文档并生成知识库检索器" class="headerlink" title="2. 解析文档并生成知识库检索器"></a>2. 解析文档并生成知识库检索器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> tempfile</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory <span class="comment"># 会话记录到内存</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> StreamlitChatMessageHistory <span class="comment">#  Streamlit聊天记录存储</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader <span class="comment"># 文本加载器</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.embeddings <span class="keyword">import</span> OllamaEmbeddings <span class="comment"># Ollama Eembeddings 语言模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma <span class="comment"># Chroma 向量数据库</span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter <span class="comment"># 文本分割器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 st 的标题和布局</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;RAG测试问答&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置应用标题</span></span><br><span class="line">st.title(<span class="string">&quot;RAG测试问答&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持上传 txt 文件</span></span><br><span class="line">upload_file = st.sidebar.file_uploader(label=<span class="string">&quot;上传文件&quot;</span>, <span class="built_in">type</span>=[<span class="string">&quot;txt&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> upload_file:</span><br><span class="line">    st.info(<span class="string">&quot;请上传 txt 文件&quot;</span>)</span><br><span class="line">    st.stop()</span><br><span class="line"></span><br><span class="line"><span class="comment"># step1 实现知识库生成</span></span><br><span class="line"><span class="meta">@st.cache_resource(<span class="params">ttl=<span class="string">&quot;1h&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_knowledge_base</span>(<span class="params">uploaded_file</span>):</span><br><span class="line">    <span class="comment"># 读取上传的文档</span></span><br><span class="line">    docs = []</span><br><span class="line">    <span class="comment"># 将 uploaded_file 存到 /tmp</span></span><br><span class="line">    temp_dir = tempfile.TemporaryDirectory(<span class="built_in">dir</span>=<span class="string">r&quot;/tmp&quot;</span>)</span><br><span class="line">    tempfilepath = os.path.join(temp_dir.name, uploaded_file.name)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(tempfilepath, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(uploaded_file.getvalue())</span><br><span class="line">    <span class="comment"># 使用 TextLoader 加载文档</span></span><br><span class="line">    docs = TextLoader(tempfilepath, encoding=<span class="string">&quot;utf-8&quot;</span>).load()</span><br><span class="line">    <span class="comment"># 使用 RecursiveCharacterTextSplitter 分割文档</span></span><br><span class="line">    splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">200</span>)</span><br><span class="line">    splits = splitter.split_documents(docs)</span><br><span class="line">    <span class="comment"># 使用 OllamaEmbeddings 生成文档向量</span></span><br><span class="line">    embeddings = OllamaEmbeddings(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;shaw/dmeta-embedding-zh&quot;</span>)</span><br><span class="line">    <span class="comment"># 使用 Chroma 向量数据库存储文档向量</span></span><br><span class="line">    chroma_db = Chroma.from_documents(splits, embeddings)</span><br><span class="line">    <span class="comment"># 创建文档检索器 约等于 知识库</span></span><br><span class="line">    retriever = chroma_db.as_retriever()</span><br><span class="line">    <span class="keyword">return</span> retriever</span><br><span class="line">    </span><br><span class="line">retriever = get_knowledge_base(upload_file) </span><br></pre></td></tr></table></figure><p>上文件后， 执行效果如下：</p><p><img src="/assets/img/ailearn/ai-learn08-4.png" alt=""></p><p><img src="/assets/img/ailearn/ai-learn08-3.png" alt=""></p><h3 id="3-初始化聊天消息界面"><a href="#3-初始化聊天消息界面" class="headerlink" title="3. 初始化聊天消息界面"></a>3. 初始化聊天消息界面</h3><p>聊天功能主要几点：</p><ul><li>记录聊天内容</li><li>显示聊天内容</li><li>用户输入框</li></ul><p>具体实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step2 初始化聊天消息界面</span></span><br><span class="line"><span class="comment"># 如果用户输入&quot;清空聊天记录&quot;，则重新初始化界面</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state <span class="keyword">or</span> st.sidebar.button(<span class="string">&quot;清空聊天记录&quot;</span>):</span><br><span class="line">    st.session_state[<span class="string">&quot;messages&quot;</span>] = [&#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;你好&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;我是测试 RAG 问答小助手&quot;</span></span><br><span class="line">    &#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示历史聊天记录</span></span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> st.session_state[<span class="string">&quot;messages&quot;</span>]:</span><br><span class="line">    st.chat_message(msg[<span class="string">&quot;role&quot;</span>], msg[<span class="string">&quot;content&quot;</span>])  <span class="comment"># </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建历史聊天记录</span></span><br><span class="line">msgs = StreamlitChatMessageHistory()</span><br><span class="line"><span class="comment"># 创建对话缓存</span></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    chat_memory=msgs,</span><br><span class="line">    return_messages=<span class="literal">True</span>,</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    output_key=<span class="string">&quot;out&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建 UI 输入框</span></span><br><span class="line">user_query = st.chat_input(placeholder=<span class="string">&quot;请输入要测试的问题&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="4-创建LLM-检索-agent执行"><a href="#4-创建LLM-检索-agent执行" class="headerlink" title="4. 创建LLM 检索 agent执行"></a>4. 创建LLM 检索 agent执行</h3><p>这里实现一个Agent， 过程是 去调用一个检索工具，支持模板和用户输入，调用大模型进行检索，然后返回结果。</p><p>具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step3 创建检索 agent </span></span><br><span class="line"><span class="keyword">from</span> langchain.tools.retriever <span class="keyword">import</span> create_retriever_tool</span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-1 用于创建文档检索的工具</span></span><br><span class="line">tool = create_retriever_tool(</span><br><span class="line">    retriever=retriever,</span><br><span class="line">    name=<span class="string">&quot;文档检索&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;根据输入的关键词，检索相关文档&quot;</span>,</span><br><span class="line">)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-2 创建 LLM对话模型</span></span><br><span class="line"><span class="comment"># 创建指令 Prompt</span></span><br><span class="line">instruction = <span class="string">&quot;&quot;&quot;你是一个设计用于查询文档回答问题的代理</span></span><br><span class="line"><span class="string">您可以使用文档检索工具，并基于检索内容来回答问题。</span></span><br><span class="line"><span class="string">可能你不查询文档就知道答案，但是仍然要去查询文档来获得答案。</span></span><br><span class="line"><span class="string">如果从文档找不到任何信息和答案来回答问题，则需要返回“非常抱歉，这个问题暂时没有录入到知识库中。”作为答案。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">base_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#123;instruction&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">TOOLS:</span></span><br><span class="line"><span class="string">----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你可以使用以下工具：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;tools&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">使用工具中，你可以参考这样子：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string">思考：我是否需要使用工具？ 是的</span></span><br><span class="line"><span class="string">动作：我需要使用工具：[&#123;tool_names&#125;]</span></span><br><span class="line"><span class="string">动作：输入:&#123;input&#125;</span></span><br><span class="line"><span class="string">动作执行后： 返回动作执行后的结果</span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当你需要返回一个答案，且这个答案不需要使用工具时，你可以参考这样子：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string">思考：我是否需要使用工具？ 不是</span></span><br><span class="line"><span class="string">答案： [你的答案]</span></span><br><span class="line"><span class="string">ZWJ```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">开始！</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">上一次历史对话内容如下：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">新的问题是：&#123;input&#125;</span></span><br><span class="line"><span class="string">&#123;agent_scratchpad&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># agent_scratchpad 是 agent 的 scratchpad，用于存储 agent 的状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基础模板</span></span><br><span class="line">base_prompt = PromptTemplate.from_template(base_template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充基础模板</span></span><br><span class="line">prompt = base_prompt.partial(instruction=instruction)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 LLM 模型</span></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:7b&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># step3-3 创建 agent</span></span><br><span class="line">agent = create_react_agent(llm=llm, prompt=prompt, tools=tools)</span><br><span class="line"></span><br><span class="line">agent_excutor = AgentExecutor(</span><br><span class="line">    agent=agent,</span><br><span class="line">    tools=tools,</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    handle_parsing_errors=<span class="string">&quot;从知识库没找到对应内容或者答案&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="5-用户输入与-Agent返回"><a href="#5-用户输入与-Agent返回" class="headerlink" title="5. 用户输入与 Agent返回"></a>5. 用户输入与 Agent返回</h3><p>这一步基本上就是解决用户输入显示与 Agent返回结果，同时通过 streamlit的 callbank函数去 展示 Agent的执行过程，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step5 用户输入查询与返回</span></span><br><span class="line"><span class="keyword">if</span>  user_query:</span><br><span class="line">    <span class="comment"># 添加到 session 历史记录</span></span><br><span class="line">    st.session_state[<span class="string">&quot;messages&quot;</span>].append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_query&#125;)</span><br><span class="line">    <span class="comment"># 显示用户信息</span></span><br><span class="line">    st.chat_message(<span class="string">&quot;user&quot;</span>).write(user_query)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">        <span class="comment"># 创建回调</span></span><br><span class="line">        callback = StreamlitCallbackHandler(st.container())</span><br><span class="line">        <span class="comment"># 将 agent执行过程 显示在 streamlit中，如：思考、选择工具、执行查询等等</span></span><br><span class="line">        config = &#123;<span class="string">&quot;callbacks&quot;</span>: [callback]&#125;</span><br><span class="line">        <span class="comment"># agent 执行</span></span><br><span class="line">        response = agent_excutor.invoke(&#123;<span class="string">&quot;input&quot;</span>: user_query&#125;, config=config)</span><br><span class="line">        <span class="comment"># 保存agent 执行结果到聊天记录 </span></span><br><span class="line">        st.session_state[<span class="string">&quot;messages&quot;</span>].append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response[<span class="string">&quot;output&quot;</span>]&#125;)</span><br><span class="line">        <span class="comment"># 显示在 streamlit中</span></span><br><span class="line">        st.write(response[<span class="string">&quot;output&quot;</span>])</span><br></pre></td></tr></table></figure><h3 id="最终运行"><a href="#最终运行" class="headerlink" title="最终运行"></a>最终运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamlit run bot_chat.py</span><br></pre></td></tr></table></figure><p>执行效果如下：<br>对话中：<br><img src="/assets/img/ailearn/ai-learn08-5.png" alt=""></p><p>返回答案：<br><img src="/assets/img/ailearn/ai-learn08-6.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文我们主要学习了LangChain的去实现一个RAG智能问答客服，通过Streamlit框架快速搭建一个UI界面，上传知识库文件，利用RAG技术加强大模型的企业内部特有的知识。回顾一下，我们主要学习了以下内容：</p><ul><li>RAG技术原理，加载(load)、训练(train)、推理(inference)三个步骤</li><li>Embeddings嵌入模型的具体作用，将文本、图片转换为向量</li><li>利用LangChain+Streamlit+Chroma(向量数据库)快速搭建一个企业内部的智能客服问答系统</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面几篇学习LangChain，基本上完成对 LangChain从开发到上线有一个整体的了解，那么接下来我们就要开始实战了，我们将会使用LangChain开发一个问答机器人，这个问答机器人将会使用到RAG模型，那么接下来我们开始学习RAG。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>07篇 AI从零开始 - LangChain学习与实战(4) LangServer部署</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn07.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn07.html</id>
    <published>2025-03-12T07:00:00.000Z</published>
    <updated>2025-04-07T12:04:38.763Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>从 LangChain系列文章开始到现在，我们学习 LangChain的基础知识和实战撸代码，现在我们假设已经开发好一个 LangChain链式任务，那么如何部署以及如何与 web服务进行互相调用呢？</p><p>那么接下来我们应该就学习LangServer与LangSmith，如何让 LangChain进行企业级开发。</p><blockquote><p>LangServer: 帮开发者将  LangChain 部署一个 Restful 服务。</p><p>LangSmith: 监控 LangChain调用链路服务和提供更加友好的可视化界面。</p></blockquote><span id="more"></span><h1 id="认识-LangServer"><a href="#认识-LangServer" class="headerlink" title="认识 LangServer"></a>认识 LangServer</h1><p>LangServer是集成了FastApi + Pydantic的Restful框架。它提供了一些特性：</p><ul><li>每次 API调用都会返回丰富的错误信息</li><li>自带 JSON Schema和   Swagger API文档</li><li>高效的<code>/invoke</code>、 <code>batch</code>和 <code>/stream</code>接口服务，支持单个服务器多个并发请求</li><li>支持调用<code>/stream_log</code>接口，实现链式任务中间态步骤返回</li><li><code>/stream_events</code>更加清晰任务事件状态信息</li><li>提供LangServer SDK，调用 Restful 和 直接调用大模型一样简单</li></ul><h1 id="实战教程"><a href="#实战教程" class="headerlink" title="实战教程"></a>实战教程</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>安装<code>langchain-cli</code>全局命令，方便快速启动 Lang Server项目</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U langchain-cli </span><br></pre></td></tr></table></figure><p>安装<code>poetry</code>管理项目的依赖，更好管理服务依赖 pip包。</p><blockquote><p><code>poetry</code> Python packaging and dependency management made easy， 翻译过来就是更加轻松管理 python项目和依赖</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 pipx</span></span><br><span class="line">pip install pipx</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pipx添加到环境变量</span></span><br><span class="line">pipx ensurepath</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 poetry</span></span><br><span class="line">pipx install poetry</span><br></pre></td></tr></table></figure><h2 id="初始化和运行项目"><a href="#初始化和运行项目" class="headerlink" title="初始化和运行项目"></a>初始化和运行项目</h2><ol><li>项目初始化<br>利用langchain-cli 脚手架， 初始化一个 langserver项目</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化一个langserver的项目</span></span><br><span class="line">langchain app new mylangserver</span><br><span class="line"></span><br><span class="line">pipx run langchain app new mylangserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入项目目录</span></span><br><span class="line">cd mylangserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装项目依赖</span></span><br><span class="line">poetry install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装后续依赖的包</span></span><br><span class="line">poetry add langchain</span><br><span class="line">poetry add langchain_ollama</span><br></pre></td></tr></table></figure><ol start="2"><li>项目结构说明<br>生成的目录结构与说明如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mylangserver # 项目名</span><br><span class="line">├─.gitignore</span><br><span class="line">├─Dockerfile </span><br><span class="line">├─README.md</span><br><span class="line">├─pyproject.toml # 项目结构说明文件</span><br><span class="line">├─poetry.lock # poetry依赖锁文件 类似前端的yarn.lock</span><br><span class="line">├─packages</span><br><span class="line">|    └README.md</span><br><span class="line">├─app</span><br><span class="line">|  ├─__init__.py</span><br><span class="line">|  ├─server.py  # 服务主入口 后续开发都在这里</span><br></pre></td></tr></table></figure><ol start="3"><li>运行项目</li></ol><p>在根目录下运行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">langchain server</span><br></pre></td></tr></table></figure><p>就可以直接访问 <code>http://localhost:8080</code>，效果具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-1.png" alt=""></p><h2 id="接口开发"><a href="#接口开发" class="headerlink" title="接口开发"></a>接口开发</h2><ol><li><code>server.py</code>文件<br>在接口开发之前我们先看看 <code>server.py</code>文件，具体如下：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> RedirectResponse</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里是定义路由和对应路由实现的方法</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">redirect_root_to_docs</span>():</span><br><span class="line">    <span class="keyword">return</span> RedirectResponse(<span class="string">&quot;/docs&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们可以添加路由</span></span><br><span class="line"><span class="comment"># add_routes(app, NotImplemented)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    <span class="comment"># 这里通过 uvicorn启动服务，端口为8000</span></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure><ol start="2"><li>添加一个调用<code>DeepSeek-R1</code>模型的接口</li></ol><p>通过 <code>add_routes</code>新增一个模型对象，会自动封装成对应的 Restful接口，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> RedirectResponse</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"></span><br><span class="line">deepseek = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"></span><br><span class="line">app = FastAPI(</span><br><span class="line">    title=<span class="string">&quot;Qborfy个人 LangServer&quot;</span>,</span><br><span class="line">    version=<span class="string">&quot;0.1.0&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Qborfy个人 LangServer，学习测试使用&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">redirect_root_to_docs</span>():</span><br><span class="line">    <span class="keyword">return</span> RedirectResponse(<span class="string">&quot;/docs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 deepseek路由</span></span><br><span class="line">add_routes(app, deepseek, path=<span class="string">&quot;/deepseek&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>接下来我们访问 <code>http://localhost:8000/</code>，就会出现和<code>/deepseek</code>相关的文档，具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-2.png" alt=""></p><h2 id="接口测试"><a href="#接口测试" class="headerlink" title="接口测试"></a>接口测试</h2><p>接口测试我们可以通过<a href="https://apifox.com/">ApiFox</a> (一个和 Postman类似  API 测试工具)进行测试，具体如下.</p><ol><li><code>/invoke</code> 发起一个对话请求, 具体如下图：</li></ol><p><img src="/assets/img/ailearn/ai-learn07-3.png" alt=""></p><ol start="2"><li><code>/stream</code> 流式调用，具体如下图：</li></ol><p><img src="/assets/img/ailearn/ai-learn07-4.png" alt=""></p><h2 id="SDK调用"><a href="#SDK调用" class="headerlink" title="SDK调用"></a>SDK调用</h2><p>在LangChain中是可以通过 LangServe提供的 <code>RemoteRunable</code> 进行远程调用，和原来的调用大模型的使用方式其实是一样的， 具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用远端调用 LangServer</span></span><br><span class="line"><span class="keyword">from</span> langchain.schema.runnable <span class="keyword">import</span> RunnableMap</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> RemoteRunnable</span><br><span class="line"></span><br><span class="line">llm = RemoteRunnable(<span class="string">&quot;http://127.0.0.1:8000/deepseek&quot;</span>)</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;你是世界级的 AI 技术专家, &#123;input&#125;&quot;</span></span><br><span class="line"><span class="comment"># 这里我们使用一个简单的模板</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    template=template</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建一个简单的链式调用</span></span><br><span class="line">chain = prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行链式调用</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> llm.stream(<span class="string">&quot;海洋是什么颜色&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(chunk, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样子我们不仅可以在本地调用大模型，还能调用其他人提供 LangChain服务，从而实现更加复杂的功能。</p><h2 id="生产部署"><a href="#生产部署" class="headerlink" title="生产部署"></a>生产部署</h2><p>LangServer生产部署，按照 LangChain官方推荐是通过<code>Dockerfile</code>打包进行部署，其中也比较简单，具体执行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打包镜像</span></span><br><span class="line">docker build . -t my-langserve-app</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行镜像</span></span><br><span class="line">docker run -p 8080:8080 my-langserve-app</span><br></pre></td></tr></table></figure><p>或者是通过 docker-compose启动 docker服务，具体如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">langserver:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">my-langserve-app</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8080</span><span class="string">:8080</span></span><br></pre></td></tr></table></figure><p>最终执行<code>docker-compose up -d</code>启动服务后，就可以通过<code>http://localhost:8080/docs</code>访问到服务了。</p><h1 id="监控与日志"><a href="#监控与日志" class="headerlink" title="监控与日志"></a>监控与日志</h1><h2 id="LangSmith监控"><a href="#LangSmith监控" class="headerlink" title="LangSmith监控"></a>LangSmith监控</h2><p>LangSmith是 LangChain官方提供的监控工具，可以监控模型运行情况，一个 SASS服务需要我们将服务相关信息注册到 LangSmith网站上，因此可以按个人或公司需要判断是否允许使用。</p><blockquote><p>LangSmith是一个用于构建生产级应用的平台。它允许您密切监控和评估您的应用，以便您可以快速而自信地发布应用。</p><p>传统软件应用程序是通过编写代码来构建的，而 AI 应用程序则需要编写提示来指导应用程序执行哪些操作。</p><p>LangSmith 提供了一套旨在实现和促进提示工程的工具，以帮助您找到适合您的应用程序的完美提示。</p></blockquote><p><strong>PS：LangSmith这里提示未来编程开发者的思维转变，我们实现功能的思路不再是针对一些实现逻辑，而是面向不同的 AI 模型，优化提示语实现我们想要的功能。</strong></p><p>在 LangServer 中使用 LangSmith，需要先注册一个账号，然后获取 api key 添加到 LangServer中，具体使用代码如下： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置LangSimth 环境变量</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_TRACING&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_ENDPOINT&quot;</span>] = <span class="string">&quot;https://api.smith.langchain.com&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_API_KEY&quot;</span>] = <span class="string">&quot;&lt;LANG_SIMTH_KEY&gt;&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;LANGSMITH_PROJECT&quot;</span>] = <span class="string">&quot;mylangserver&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>具体使用教程可以参考<a href="https://docs.smith.langchain.com/">LangSmith官方文档</a></p><p>LangSmith主要作用是监控 链路任务节点调用和扭转情况，可以更加清晰的分析链的运行情况和日志，具体效果如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn07-5.png" alt=""></p><h2 id="Verbose关键日志"><a href="#Verbose关键日志" class="headerlink" title="Verbose关键日志"></a>Verbose关键日志</h2><p>如果我们不想把自己的服务相关的日志信息暴露给 LangSmith， 我们还可以通过设置<code>set_verbose</code>设置详细日志开关， 从而实现我们调用 LangChain链路的完整日志，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.<span class="built_in">globals</span> <span class="keyword">import</span> set_verbose</span><br><span class="line"><span class="comment"># 全局 verbose配置开关</span></span><br><span class="line">set_verbose(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 针对部分链接调用设置详细日志开关</span></span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>打开开关后，我们再调用<code>helloworld.py</code>大模型，可以看到关键的日志信息，但是verbose只会输出关键日志，下面我们还可以 <code>debug</code>查看更加详细的日志信息。</p><h2 id="Debug日志"><a href="#Debug日志" class="headerlink" title="Debug日志"></a>Debug日志</h2><p>我们可以通过<code>debug</code>设置日志级别，从而查看更加详细的日志信息，具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.<span class="built_in">globals</span> <span class="keyword">import</span> set_debug</span><br><span class="line"><span class="comment"># 全局 debug配置开关</span></span><br><span class="line">set_debug(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>打开开关后，我们再调用<code>helloworld.py</code>大模型，可以看到更加详细的日志信息，具体如下图：</p><p><img src="/assets/img/ailearn/ai-learn07-7.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文我们主要学习了LangServer的去部署一个 LangChain链，通过 LangServe对于第三方就能加友好的访问我们的提供 LangChain服务，从而实现更加复杂的功能。回顾一下，我们主要学习了以下内容：</p><ul><li>LangServer 安装与运行：通过 LangChain-Cli脚手架创建项目和<code>langchain serve</code>运行项目</li><li>LangServer 接口开发：<code>add_routes</code>添加接口，可以直接把一个 LangChain添加到 LangServer中且自动生成 Swagger文档  </li><li>LangServer监控与日志：LangSmith是LangChain官方提供的监控工具，但是会上报我们服务相关的日志信息，因此我们可以设置<code>set_verbose</code>或者<code>set_debug</code>设置详细日志开关， 从而实现我们调用 LangChain链路的完整日志</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从 LangChain系列文章开始到现在，我们学习 LangChain的基础知识和实战撸代码，现在我们假设已经开发好一个 LangChain链式任务，那么如何部署以及如何与 web服务进行互相调用呢？&lt;/p&gt;
&lt;p&gt;那么接下来我们应该就学习LangServer与LangSmith，如何让 LangChain进行企业级开发。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LangServer: 帮开发者将  LangChain 部署一个 Restful 服务。&lt;/p&gt;
&lt;p&gt;LangSmith: 监控 LangChain调用链路服务和提供更加友好的可视化界面。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>06篇 AI从零开始 - LangChain学习与实战(3) LCEL工作流编排原理与实战</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn06.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn06.html</id>
    <published>2025-03-03T07:00:00.000Z</published>
    <updated>2025-03-03T13:13:47.467Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>上一篇文章我们学习<a href="ttps://qborfy.com/ailearn/ai-learn05.html">05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉</a>，对 LangChain实际应用有了基本的了解，接下我们会进入 LangChain最重要的一次学习，就是 LangChain工作流编排原理与实战(LCEL), 学了本文基本上后续 LangChain实际开发都可以独立完成，本文内容较多，建议大家收藏，慢慢学习。</p><span id="more"></span><h1 id="1-LCEL介绍"><a href="#1-LCEL介绍" class="headerlink" title="1. LCEL介绍"></a>1. LCEL介绍</h1><p>LCEL(LangChain Expression Language) 是 LangChain提出来一种强大的工作流编排模式，可以通过基础组件去构建复杂任务链条式，包括但不限于：</p><ul><li>流式处理</li><li>并行处理</li><li>日志记录</li><li>…等等</li></ul><h2 id="1-1-LCEL的特性"><a href="#1-1-LCEL的特性" class="headerlink" title="1.1 LCEL的特性"></a>1.1 LCEL的特性</h2><ul><li><strong>一流的流式支持</strong>： 通过 LCEL 构建链时， 可以获得链式最佳时间（从第一个任务到最后一个输出所经历的时间），如：你通过不同链路调用 LLM 大模型到输出 ≈ 直接调用 LLM 大模型输出</li><li><strong>异步支持</strong>：LCEL链路中任何一个任务都可以异步执行，如：你可以在一个任务中调用另一个任务，而无需等待该任务完成</li><li><strong>优化的并行任务处理</strong>：针对多个并行步骤时候，LCEL会自动优化并行任务，达到最小延迟</li><li><strong>重试和回退</strong>：LCEL 链路中的任何任务都可以重试，如果失败，可以回退到上一个任务</li><li><strong>访问中间结果</strong>：可以访问 LCEL 链中的任何任务的结果，可以给用户提供实时结果和方便开发调试</li><li><strong>标准化的输入和输出模式</strong>：每个 LCEL链都可以直接使用 <code>Pydantic</code>对象和 <code>JSON</code>对象作为输入和输出，从而更好验证链路的正确性，并且LangServer的重要组成部分</li></ul><h1 id="2-LCEL原理设计-——-Runable-Interface"><a href="#2-LCEL原理设计-——-Runable-Interface" class="headerlink" title="2. LCEL原理设计 —— Runable Interface"></a>2. LCEL原理设计 —— Runable Interface</h1><p>LCEL之所以有如此强大的功能，离不开它的设计理念 —— Runable Interface，LangChain一套标准且强大的接口设计规范，让所有的组件都按照这个去实现，从而实现 LCEL 工作流编排。</p><p>Runable Interface接口设计有以下几个方面“</p><h2 id="2-1-标准调用方法"><a href="#2-1-标准调用方法" class="headerlink" title="2.1 标准调用方法"></a>2.1 标准调用方法</h2><p>同步调用方法：</p><ul><li>stream: 支持按照 stream流式返回</li><li>invoke: 支持同步调用</li><li>batch: 批量调用，等于多个invoke调用</li></ul><p>结合<code>await</code>实现异步调用的方法：</p><ul><li>astream: 异步调用stream流式返回</li><li>ainvoke: 异步调用</li><li>abatch: 异步调用批量调用，等于多个ainvoke调用</li><li>astream_log: 异步返回中间步骤，可以监控异步调用，最终会返回最后的结果</li><li>astream_envent: stream的异步事件监听，如：开始调用和结束调用触发</li></ul><h2 id="2-2-输入和输出"><a href="#2-2-输入和输出" class="headerlink" title="2.2 输入和输出"></a>2.2 输入和输出</h2><p>LangChain的输入和输出都是遵循<code>schema</code>规范，从可运行对象结构自动生成对应的<code>Pydantic</code>模型。</p><blockquote><p><code>Pydantic</code>是用于数据建模/解析的Python库，它允许您定义一个数据模型，然后使用该模型验证输入和输出。<br>它可以帮助您确保输入和输出数据符合预期的格式和类型，从而提高代码的健壮性和可维护性。<br>同时 <code>Pydantic</code> 内置了对JSON编码和解码的支持。</p></blockquote><p>不过不同组件输入类型和输出类型是不同的，下面常用 LangChain组件输入和输出类型：</p><table><thead><tr><th>组件</th><th>输入类型</th><th>输出类型</th></tr></thead><tbody><tr><td>提示 Prompt</td><td>string</td><td>PromptTemplate提示值</td></tr><tr><td>聊天模型</td><td>string、聊天信息列表、提示值</td><td>string</td></tr><tr><td>LLM</td><td>string、聊天信息列表、提示值</td><td>string</td></tr><tr><td>输出解析器</td><td>LLM、 LLM的输出</td><td>取决于解析器的类型，如 <code>jsonparser</code>输出的是 json格式</td></tr></tbody></table><p>流式运行对于基于 LLM 开发的应用会对用户使用体验上有更好的体验，所以目前LangChain中重要的组件都实现 LangChain Runable Interface中的 <code>stream</code>和<code>astream</code>，如：<code>PromptTemplate</code>、<code>ChatModel</code>、<code>LLM</code>、<code>OutputParser</code>等。</p><h2 id="2-3-Stream流"><a href="#2-3-Stream流" class="headerlink" title="2.3 Stream流"></a>2.3 Stream流</h2><p>上面弄清楚 LCEL的运行原理，我们还需要了解 <code>Stream</code>这一概念，才能更好的理解 LCEL工作流编排。</p><blockquote><p><code>Stream</code> 指的是一个数据流，它表示一个连续的数据序列，可以是一个数据块、一个文件、一个数据库表、一个网络连接等。在计算机科学中，流通常用于表示实时数据传输，例如从网络连接中接收的数据、从文件中读取的数据等。流数据具有连续性、实时性和不可预测性等特点，因此处理流数据需要特殊的算法和数据结构。</p></blockquote><p>在 LangChain中所有 Runable对象都实现了 <code>stream(同步)</code> 和 <code>astream(异步)</code>接口，通过 <code>stream</code> 和 <code>astream</code>接口，LangChain链式中的每个任务步骤都可以按照流式输入与输出。<br>从简单的任务，如发起一个 LLM调用，到复杂的任务，如：传输json数据等。</p><h1 id="3-LCEL工作流编排实战"><a href="#3-LCEL工作流编排实战" class="headerlink" title="3. LCEL工作流编排实战"></a>3. LCEL工作流编排实战</h1><p>了解完 LCEL工作流编排原理，我们开始实战，下面我们通过几个的例子，来更好理解 LCEL工作流编排。</p><h2 id="3-1-一次基础的流式调用"><a href="#3-1-一次基础的流式调用" class="headerlink" title="3.1 一次基础的流式调用"></a>3.1 一次基础的流式调用</h2><p>我们去调用一个 Ollama 大模型，然后调用 <code>stream</code>方法，看看最终会输出什么？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"></span><br><span class="line">chunks = []</span><br><span class="line"><span class="comment"># llm.stream 会返回一个流</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> llm.stream(<span class="string">&quot;海洋是什么颜色&quot;</span>):</span><br><span class="line">    chunks.append(chunk)</span><br><span class="line">    <span class="built_in">print</span>(chunk, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>最终输出效果，按照一块块输出，如下图：</p><p><img src="/assets/img/ailearn/ai-learn06-1.png" alt=""></p><h2 id="3-2-astream-异步调用"><a href="#3-2-astream-异步调用" class="headerlink" title="3.2 astream 异步调用"></a>3.2 astream 异步调用</h2><p>进一步看看<code>astream</code>调用和<code>stream</code>调用有什么区别？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line">propmt = ChatPromptTemplate.from_template(<span class="string">&quot;给我讲一个关于&#123;input&#125;的笑话&quot;</span>)</span><br><span class="line">parser = StrOutputParser()</span><br><span class="line">chain = propmt | llm | parser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步调用需要定义 async 方法</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> chain.astream(<span class="string">&quot;公鸡&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(chunk, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用的话需要通过  asyncio.run() 方法       </span></span><br><span class="line">asyncio.run(async_stream())</span><br></pre></td></tr></table></figure><p>异步调用需要定义 async 方法，调用的话需要通过  asyncio.run() 方法，最终效果和<code>stream</code>调用效果一样，不过在并行任务较多的情况下，<code>astream</code>调用会利用更多的CPU资源，从而提高并行任务处理效率。</p><h2 id="3-3-json输出格式"><a href="#3-3-json输出格式" class="headerlink" title="3.3 json输出格式"></a>3.3 json输出格式</h2><p>在实际应用中，我们很多场景其实 web服务通过 http协议传输，而且希望能被其他服务调用因此<code>json</code>格式输出会更好，下面我们看看如何实现？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line">propmt = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    以 JSON格式返回&#123;x&#125;的人口列表</span></span><br><span class="line"><span class="string">    使用一个`省份`作为字段列表返回</span></span><br><span class="line"><span class="string">    每个省份都应有有字段`省份名`+`人口`字段                                  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>)</span><br><span class="line">parser = JsonOutputParser() <span class="comment"># 保证每次输出都是json格式</span></span><br><span class="line">chain = propmt | llm | parser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步调用需要定义 async 方法</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> chain.astream(<span class="string">&quot;广东省、福建省、广西省&quot;</span>):</span><br><span class="line">        <span class="comment"># 可以看到每次 chunk都是一个完整的 json 格式</span></span><br><span class="line">        <span class="built_in">print</span>(chunk, end=<span class="string">&quot;\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用的话需要通过  asyncio.run() 方法       </span></span><br><span class="line">asyncio.run(async_stream())</span><br></pre></td></tr></table></figure><p>上文我们可以看到用到<code>JsonOutputParser</code>，它保证每次输出都是json格式，所以最终输出效果如下：<br><img src="/assets/img/ailearn/ai-learn06-2.png" alt=""></p><h2 id="3-4-stream-event监听"><a href="#3-4-stream-event监听" class="headerlink" title="3.4 stream_event监听"></a>3.4 stream_event监听</h2><p>我们先看调用一个 LLM模型会产生哪些事件？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> event <span class="keyword">in</span> llm.astream_events(<span class="string">&quot;你好&quot;</span>, version=<span class="string">&quot;v2&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(event)</span><br><span class="line"><span class="comment"># 调用的话需要通过  asyncio.run() 方法       </span></span><br><span class="line">asyncio.run(async_stream())</span><br></pre></td></tr></table></figure><p>输出如下图：</p><p><img src="/assets/img/ailearn/ai-learn06-3.png" alt=""></p><p>返回<code>event</code>数据结构如下：</p><ul><li><code>event</code>事件类型，如：<code>stream_start</code>、<code>stream_end</code>、<code>stream_chunk</code>等</li><li><code>data</code>事件数据，如：<code>stream_chunk</code>事件数据为<code>chunk</code>，<code>stream_end</code>事件数据为<code>end</code>等</li><li><code>run_id</code>本次调用id，当多次任务并发的时候可以找到对应任务</li><li><code>metadata</code>事件元数据，包括模型版本、模型名称、模型参数等</li><li>其他一些其他信息，如：<code>tags</code>、<code>name</code>、<code>parent_ids</code>等</li></ul><p>完整的事件类型我们可以到 LangChain官方文档去查看，地址为<a href="https://python.langchain.com/docs/how_to/streaming/#using-stream-events">如何使用 Stream Events</a></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过本文我们完整了解 LangChain LCEL流式调用和工作原理，从而为后续使用LangChain进入实际开发提供基础知识。 LCEL主要包含以下内容：</p><ul><li>流式调用方法 <code>stream</code>、<code>astream</code></li><li>调用事件监听 <code>astream_events</code></li><li>输出格式要求 <code>JsonOutputParser</code>等</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一篇文章我们学习&lt;a href=&quot;ttps://qborfy.com/ailearn/ai-learn05.html&quot;&gt;05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉&lt;/a&gt;，对 LangChain实际应用有了基本的了解，接下我们会进入 LangChain最重要的一次学习，就是 LangChain工作流编排原理与实战(LCEL), 学了本文基本上后续 LangChain实际开发都可以独立完成，本文内容较多，建议大家收藏，慢慢学习。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>05篇 AI从零开始 - LangChain学习与实战(2) PromptTemplate降低AI幻觉</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn05.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn05.html</id>
    <published>2025-02-20T07:00:00.000Z</published>
    <updated>2025-03-13T07:58:03.922Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>上一节学习了<a href="https://qborfy.com/ailearn/ai-learn04.html">04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</a>，对Langchain有了基础的认知和简单应用，其中我们使用<code>PromptTemplate</code>去实现一次大模型对话。</p><p>同时我们在<a href="https://qborfy.com/ailearn/ai-learn03.html">03篇 AI从零开始 - Prompt提示语学习与应用</a>也学习了提示语生成规范，但是在结合 LangChain中我们应该如何利用<code>PromptTemplate</code>提示模板+提示语规范去降低 AI幻觉呢？</p><blockquote><p><strong>AI幻觉</strong>, 指人工智能（尤其是大语言模型）生成看似合理但实际错误、虚构或与现实不符的内容的现象。本质是模型在缺乏真实理解能力的情况下，基于统计模式生成的「自信错误」。</p></blockquote><span id="more"></span><p>下面是 Langchain执行一次 LLM 调用的流程图：</p><p><img src="/assets/img/ailearn/ai-learn05-1.png" alt=""></p><h1 id="1-什么是PromptTemplate"><a href="#1-什么是PromptTemplate" class="headerlink" title="1. 什么是PromptTemplate"></a>1. 什么是PromptTemplate</h1><p>提示词模板跟平时大家使用邮件模板、短信模板类型，本质上是一个字符串模板，模板里包含了模板参数，可以通过输入参数来生成最终的提示词。</p><p>一个提示词模板包括以下内容：</p><ul><li>发送给大模型的指令</li><li>一个问答示例，提醒大模型用什么格式返回</li><li>发给大模型的问题</li></ul><h1 id="2-创建提示词模板"><a href="#2-创建提示词模板" class="headerlink" title="2. 创建提示词模板"></a>2. 创建提示词模板</h1><p>可以使用<code>PromptTemplate</code>类来创建一个提示词模板，它接收一个<code>prompt</code>参数，这个参数是一个字符串，用于指定提示词模板。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过一个消息数组创建聊天消息模板</span></span><br><span class="line"><span class="comment"># 数组每一个元素代表一条消息</span></span><br><span class="line"><span class="comment"># 第一个参数是消息角色  system 代表系统消息， 第二个参数代表消息内容</span></span><br><span class="line"><span class="comment"># 消息角色 system 代表系统消息</span></span><br><span class="line"><span class="comment"># 消息角色 human 代表系统消息代表人类</span></span><br><span class="line"><span class="comment"># 消息角色 ai 代表LLM大模型返回的消息内容</span></span><br><span class="line"><span class="comment"># &#123;xxx&#125; 定义 模板参数，如下定义两个模板参数  name代表人工智能名字 user_input 代表用户输入的文本 </span></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是人工智能助手， 你的名字是&#123;name&#125;&quot;</span>), </span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;你好&quot;</span>), </span><br><span class="line">        (<span class="string">&quot;ai&quot;</span>, <span class="string">&quot;你好，我是人工智能助手&#123;name&#125;，很高兴为您服务&quot;</span>), </span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;user_input&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过模板参数格式化模板内容</span></span><br><span class="line">message = chat_template.format_messages(name=<span class="string">&quot;小爱同学&quot;</span>, user_input=<span class="string">&quot;你的名字叫什么？&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(message)</span><br></pre></td></tr></table></figure><p>这样子我们就可以得到一个正确的<code>Message</code>了， 如上代码执行结果如下：</p><p><img src="/assets/img/ailearn/ai-learn05-2.png" alt=""></p><p>返回的内容如下说明：</p><ul><li>SystemMessage: 系统设定，设定大模型的角色</li><li>HumanMessage: 人类消息，代表用户输入的消息</li><li>AIMessage: 人工智能消息，代表大模型返回的消息</li></ul><p>LangChain还抽象了其他提示语模版，具体如下：</p><ul><li>PromptTemplate: 普通提示词模板，返回一个字符串</li><li>ChatPromptTemplate: 聊天消息模板，返回一个<code>ChatPromptTemplate</code>对象，可以设定大模型角色和示例</li></ul><h1 id="3-上下文-MessagesPlaceHolder"><a href="#3-上下文-MessagesPlaceHolder" class="headerlink" title="3. 上下文 MessagesPlaceHolder"></a>3. 上下文 MessagesPlaceHolder</h1><p><code>MessagesPlaceHolder</code>主要作用在特定位置添加消息列表(等于占位符)， 可以集中管理消息列表，更好聊天过程注入上下文。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage, HumanMessage, AIMessage</span><br><span class="line"></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是人工智能助手&quot;</span>), </span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;msgs&quot;</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 这里我们可以之前的定义的消息列表放在一起</span></span><br><span class="line">msgs=[SystemMessage(content=<span class="string">&#x27;你的名字是小爱同学&#x27;</span>), HumanMessage(content=<span class="string">&#x27;你好&#x27;</span>), AIMessage(content=<span class="string">&#x27;你好，我是人工智能助手，很高兴为您服务&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(chat_template.invoke(msgs))</span><br></pre></td></tr></table></figure><h1 id="4-提示词示例-FewShot"><a href="#4-提示词示例-FewShot" class="headerlink" title="4.提示词示例 FewShot"></a>4.提示词示例 FewShot</h1><p>在之前<a href="https://qborfy.com/ailearn/ai-learn03.html">03篇 AI从零开始 - Prompt提示语学习与应用</a>中也提到过示例的重要性， 这里我们不在说示例对应大模型应用中的重要性了。</p><p>我们看看 在 LangChain中如何讲示例集 给到大模型中，其中<code>FewShot</code>主要作用是给大模型提供示例，让大模型更好的理解用户输入，从而生成更符合用户预期的结果，从而降低 AI 幻觉。</p><blockquote><p>这里可以理解成模型的微小型训练，让大模型能依据我们提供少量示例（有点类似小RAG知识库），从而更加更加准确的答案。</p></blockquote><p>在 LangChain 创建一个示例集，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts.few_shot <span class="keyword">import</span> FewShotPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;谁的寿命更长， 穆罕默德二世还是爱因斯坦？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>: </span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        爱因斯坦活了 76 岁。</span></span><br><span class="line"><span class="string">        穆罕默德二世活了 89 岁。</span></span><br><span class="line"><span class="string">        因此，穆罕默德二世比爱因斯坦活得更长。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;目前电影票房第一名是谁？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        《阿凡达》的票房是 27.9 亿美元。</span></span><br><span class="line"><span class="string">        《复仇者联盟 4：终局之战》的票房是 27.8 亿美元。</span></span><br><span class="line"><span class="string">        因此，《阿凡达》的票房更高。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 这里我们创建一个简单示例模板，用来分析解析示例的 question 和 answer</span></span><br><span class="line">example_prompt = PromptTemplate(input_variables=[<span class="string">&quot;question&quot;</span>, <span class="string">&quot;answer&quot;</span>], template=<span class="string">&quot;问题：&#123;question&#125;\\n答案：&#123;answer&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用 FewShotPromptTemplate 可以根据模板+示例去生成一个拥有示例集的提示语模板</span></span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">    examples=examples,</span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    suffix=<span class="string">&quot;问题：&#123;input&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">&quot;谁的寿命更长， 穆罕默德二世还是爱因斯坦？&quot;</span>))</span><br></pre></td></tr></table></figure><p>输出结果如下：</p><p><img src="/assets/img/ailearn/ai-learn05-2.png" alt=""></p><h1 id="5-示例选择器-ExampleSelector"><a href="#5-示例选择器-ExampleSelector" class="headerlink" title="5. 示例选择器 ExampleSelector"></a>5. 示例选择器 ExampleSelector</h1><p>示例集合等同于一个知识库，在正式环境中我们不可能把完整的知识库都给到模型，因此我们需要去分析用户输入，从而选择合适的示例，LangChain 提供了<code>ExampleSelector</code>类来帮助我们实现这个功能。</p><p>LangChain 提供了不同的<code>ExampleSelector</code>，具体如下：</p><ul><li><code>SemanticSimilarityExampleSelector</code>: 语义相似性示例选择， 会根据用户输入，然后通过嵌入模型计算输入与示例之间的相似性，然后使用向量数据库进行相似搜索，从示例集合中选择最相似的示例。</li><li><code>MaxMarginalRelevanceExampleSelector</code>: 基于 最大边际相关性（MMR） 的示例选择器,  希望在从示例集中选择与输入 既相关又多样化 的示例， 通过平衡 相关性 与 多样性 来优化示例选择效果。</li></ul><p>通常情况下，我们使用<code>SemanticSimilarityExampleSelector</code>， 根据上面示例集合，我们根据问题去选择示例，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ExapleSelector 示例筛选器</span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts.example_selector <span class="keyword">import</span> SemanticSimilarityExampleSelector</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain_ollama.embeddings <span class="keyword">import</span> OllamaEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> FewShotPromptTemplate, PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 引用 shaw/dmeta-embedding-zh 模型做为嵌入模型，其对中文支持度更加友好</span></span><br><span class="line">ollama_emb = OllamaEmbeddings(</span><br><span class="line">    base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, </span><br><span class="line">    model=<span class="string">&quot;shaw/dmeta-embedding-zh&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;谁的寿命更长， 穆罕默德二世还是爱因斯坦？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>: </span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        爱因斯坦活了 76 岁。</span></span><br><span class="line"><span class="string">        穆罕默德二世活了 89 岁。</span></span><br><span class="line"><span class="string">        因此，穆罕默德二世比爱因斯坦活得更长。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;目前电影票房第一名是谁？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        《阿凡达》的票房是 27.9 亿美元。</span></span><br><span class="line"><span class="string">        《复仇者联盟 4：终局之战》的票房是 27.8 亿美元。</span></span><br><span class="line"><span class="string">        因此，《阿凡达》的票房更高。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: <span class="string">&quot;深圳第一高楼是哪个？&quot;</span>,</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        深圳平安国际金融中心（平安中心）的楼高是 593米。</span></span><br><span class="line"><span class="string">        深圳京基100的楼高是441.8米。</span></span><br><span class="line"><span class="string">        所以深圳第一高楼是平安国际金融中心。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">example_selector = SemanticSimilarityExampleSelector.from_examples(</span><br><span class="line">    <span class="comment"># 这里是示例集合</span></span><br><span class="line">    examples=examples,</span><br><span class="line">    <span class="comment"># 用户生成嵌入的嵌入类，用于衡量语义的相似度</span></span><br><span class="line">    embeddings=ollama_emb,</span><br><span class="line">    <span class="comment"># 用于计算相似性的向量存储库，这里使用的是 Chroma， 一个保存在内容的向量存储库</span></span><br><span class="line">    vectorstore_cls=Chroma(),</span><br><span class="line">    <span class="comment"># 选择前 k 个最相似的示例 这里设置为 1</span></span><br><span class="line">    k=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">question = <span class="string">&quot;穆罕默德二世？&quot;</span></span><br><span class="line"><span class="comment"># 选择最相似的示例</span></span><br><span class="line">selected_examples = example_selector.select_examples(&#123;<span class="string">&quot;question&quot;</span>: question&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来结合 FewShotPromptTemplate 我们就可以得到更加准备且少量的示例 PromptTemplate</span></span><br><span class="line">example_prompt = PromptTemplate(input_variables=[<span class="string">&quot;question&quot;</span>, <span class="string">&quot;answer&quot;</span>], template=<span class="string">&quot;问题：&#123;question&#125;\\n答案：&#123;answer&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">    <span class="comment"># 这里调整完最相似的示例集合</span></span><br><span class="line">    examples=selected_examples, </span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    suffix=<span class="string">&quot;问题：&#123;input&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=question))</span><br></pre></td></tr></table></figure><p>具体输出效果如下图：</p><p><img src="/assets/img/ailearn/ai-learn05-4.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文我们完整学习了 LangChain 中如何使用 PromptTemplate去更好的创建一个提示语模板，从而降低 大模型的自我创新性（降低AI 幻觉）。</p><p>这里总结一下整个实现过程 约等于 后续 RAG知识库训练过程，如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn05-5.png" alt=""></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一节学习了&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn04.html&quot;&gt;04篇 AI从零开始 - LangChain学习与实战(1) 基础知识&lt;/a&gt;，对Langchain有了基础的认知和简单应用，其中我们使用&lt;code&gt;PromptTemplate&lt;/code&gt;去实现一次大模型对话。&lt;/p&gt;
&lt;p&gt;同时我们在&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn03.html&quot;&gt;03篇 AI从零开始 - Prompt提示语学习与应用&lt;/a&gt;也学习了提示语生成规范，但是在结合 LangChain中我们应该如何利用&lt;code&gt;PromptTemplate&lt;/code&gt;提示模板+提示语规范去降低 AI幻觉呢？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;AI幻觉&lt;/strong&gt;, 指人工智能（尤其是大语言模型）生成看似合理但实际错误、虚构或与现实不符的内容的现象。本质是模型在缺乏真实理解能力的情况下，基于统计模式生成的「自信错误」。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>04篇 AI从零开始 - LangChain学习与实战(1) 基础知识</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn04.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn04.html</id>
    <published>2025-02-18T07:00:00.000Z</published>
    <updated>2025-02-21T02:19:22.461Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>上一节学习了<a href="https://qborfy.com/ailearn/ai-learn03.html">03篇 AI从零开始 - AI从零开始 - Prompt提示语学习与应用</a>，但是我们发现，Prompt提示语虽然可以让我们得到想要的答案，但是它也有缺点，比如：</p><ul><li>只调用单个大模型的对话提示语来生成答案，且无法验证答案的正确性；</li><li>大模型是没有记忆能力，且有token上下对话长度限制，无法实现多轮对话；</li><li>多步骤推理任务，需要多次调用大模型，效率低下</li></ul><p>如果要开发一个完整 LLM应用，开发者需要手动处理：</p><ul><li>多组件集成：模型调用、外部数据源、记忆存储、业务逻辑等模块的拼接</li><li>上下文管理：对话历史、长期记忆、知识库检索的复杂交互</li><li>流程编排：多步骤推理、条件分支、循环控制等逻辑</li></ul><p>接下来，我们学习一下LangChain，它是一个基于链式调用的LLM框架，可以让我们更加方便地使用大模型，实现多轮对话、多步骤推理等复杂功能。</p><span id="more"></span><h1 id="1-是什么"><a href="#1-是什么" class="headerlink" title="1. 是什么"></a>1. 是什么</h1><blockquote><p>Langchain是开发由大型语言模型（LLMS）提供支持的应用程序的框架。</p></blockquote><p>从我理解的是， LangChain 是一个用于开发大语言模型（LLM）应用的框架，它的核心价值在于简化复杂语言模型应用的开发流程，并提供标准化的工具链。</p><h2 id="1-1-基础功能"><a href="#1-1-基础功能" class="headerlink" title="1.1  基础功能"></a>1.1  基础功能</h2><p>Langchain 提供了以下基础功能：</p><ul><li>LLM调用: 支持调用 OpenAI、Hugging Face、Azure 等主流的 LLM 服务， 同时支持缓存。</li><li>Prompt管理: 拥有大量的文档加载器，比如 PDF、Markdown等</li><li>对索引的支持: 文档分割器，向量化，对接向量存储与搜索，比如 Chroma、Pinecone、Qdrand等 </li><li>Chains链路调用: LLMChain、各种工具Chain等</li></ul><h2 id="1-2-必知概念"><a href="#1-2-必知概念" class="headerlink" title="1.2 必知概念"></a>1.2 必知概念</h2><h3 id="LLM模型和Prompt提示语"><a href="#LLM模型和Prompt提示语" class="headerlink" title="LLM模型和Prompt提示语"></a>LLM模型和Prompt提示语</h3><p>Langchain 针对所有的LLM大模型的 API 进行抽象，统一了大模型访问API，同时也提供了 Prompt 模板管理机制。</p><h3 id="Chain-链"><a href="#Chain-链" class="headerlink" title="Chain 链"></a>Chain 链</h3><p>可以把 Chain 理解为任务。一个 Chain 就是一个任务，当然也可以像链条一样，一个一个的执行多个链。</p><h3 id="LCEL-表达式"><a href="#LCEL-表达式" class="headerlink" title="LCEL 表达式"></a>LCEL 表达式</h3><p>LCEL: LangChain Expression Language，通过表达式解决工作流编排问题，可以灵活自定义 AI任务处理流程，也就是自定义链。</p><h3 id="数据增强生成-RAG"><a href="#数据增强生成-RAG" class="headerlink" title="数据增强生成 RAG"></a>数据增强生成 RAG</h3><p>RAG: Retrieval Augmented Generation，用于增强大模型的知识内容，录入新的信息到大模型中的一种模式。</p><h3 id="Agents-智能体"><a href="#Agents-智能体" class="headerlink" title="Agents 智能体"></a>Agents 智能体</h3><p>Agent其实是大模型的一种应用设计模式，利用 LLM自然语言理解能力和推理能力，去实现用户输入需求自动调用外部系统、设置去共同完成任务。</p><p><img src="/assets/img/ailearn/ai-learn04-1.png" alt=""></p><p>常见的智能体：</p><ul><li>对话机器人，值班客服，智能客服等</li><li>知识库问答，基于某个知识库进行回答</li><li>智能写作，如：创意写作，文本摘要等</li></ul><h3 id="Memory-模型记忆"><a href="#Memory-模型记忆" class="headerlink" title="Memory 模型记忆"></a>Memory 模型记忆</h3><p>LangChain提供一套内存机制，让LLM可以记住对话上下文内容，从而实现模型记忆。</p><h3 id="OutParsesr-输出解释器"><a href="#OutParsesr-输出解释器" class="headerlink" title="OutParsesr 输出解释器"></a>OutParsesr 输出解释器</h3><p>Langchain接收大模型返回文本内容（原始数据基本上是 markdown格式）后，可以使用专门的输出解析器转换数据结果，比如转成 json， 或者转换为 python对象等。</p><h3 id="Vectorstores-向量数据库"><a href="#Vectorstores-向量数据库" class="headerlink" title="Vectorstores 向量数据库"></a>Vectorstores 向量数据库</h3><p>将 Document 文档转换成向量存储，才能进行向量存储。因为大模型只能处理向量，所以需要将文本转换成向量。</p><p>转换成向量也很简单，只需要我们把数据存储到对应的向量数据库中即可完成向量的转换。</p><p>官方也提供了很多的向量数据库供我们使用。</p><blockquote><p><a href="https://python.langchain.com/en/latest/modules/indexes/vectorstores.html">https://python.langchain.com/en/latest/modules/indexes/vectorstores.html</a></p></blockquote><h3 id="Embedding-嵌入"><a href="#Embedding-嵌入" class="headerlink" title="Embedding 嵌入"></a>Embedding 嵌入</h3><p>Embedding（嵌入） 是将文本转化为数值向量（vector）的核心技术，用于捕捉语义信息并实现机器可理解的表示。</p><p>Langchain 提供了多种 Embedding 模型调用，具体可以到官网查看，<a href="https://python.langchain.com/docs/integrations/text_embedding/">Embedding models  嵌入模型</a>。</p><p>更多概念可以到官方文档查看：<a href="https://python.langchain.com/docs/concepts/#concepts">LangChain官方概念指南</a>。</p><h2 id="1-3-基础框架"><a href="#1-3-基础框架" class="headerlink" title="1.3 基础框架"></a>1.3 基础框架</h2><p>LangChain(v0.3版本)的框架图如下：</p><p><img src="/assets/img/ailearn/ai-learn04-2.png" alt="langchain-architecture"></p><p>更加详细说明</p><ul><li>LangChain-Core: 抽象了不同组件和组合在一起的方法，包括：聊天模型、向量存储、工具等核心组件的接口，尽量不依赖其他库。</li><li>LangChain: LangChain对外提供主要入口框架，集成绝大部分功能点。</li><li>Integration packages: 主流库的集成，比如：langchain-openai、langchain-anthropic，这里他们可以自主控制版本，这里可以看到<a href="https://python.langchain.com/docs/integrations/providers/">集成包的信息</a>。</li><li>LangChain-community: Langchain社区提供的工具包，比如：langchain-ollama、langchain-duckduckgo、langchain-google、langchain-bing等。</li><li>LangGraph: 提供给 Langchain 链中更多可扩展性，用于创建常见代理类型的高级接口，以及用于组成自定义流程的底层应用程序接口。</li><li>langServe: 可以让你的链转换为Restful服务暴露给外部系统</li><li>LangSmith: 一个开发人员平台，可让您调试，测试，评估和监视LLM应用程序。</li></ul><h1 id="2-怎么做"><a href="#2-怎么做" class="headerlink" title="2. 怎么做"></a>2. 怎么做</h1><p>为了更好地使用 LangChain，我们先来写一个简单的例子，来了解下 LangChain 的使用流程。</p><h2 id="2-1-安装和初始化项目"><a href="#2-1-安装和初始化项目" class="headerlink" title="2.1 安装和初始化项目"></a>2.1 安装和初始化项目</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">新建目录</span></span><br><span class="line">mkdir ai-learn04-langchain &amp;&amp; cd ai-learn04-langchain</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">初始化venv环境</span></span><br><span class="line">python -m venv venv</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">激活venv环境</span></span><br><span class="line">. venv/bin/activate</span><br></pre></td></tr></table></figure><p>安装后续依赖pip 新建文件<code>requirements.txt</code>，写入以下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">langchain==0.3.19</span><br><span class="line">langchain-community==0.3.17</span><br><span class="line">langchain-ollama==0.2.3</span><br></pre></td></tr></table></figure><p>执行<code>pip install -r requirements.txt</code>安装依赖。</p><h2 id="2-2-第一次调用大模型问答"><a href="#2-2-第一次调用大模型问答" class="headerlink" title="2.2 第一次调用大模型问答"></a>2.2 第一次调用大模型问答</h2><p>新建一个<code>demo1.py</code>文件，写入以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现langchain调用 ollama 大模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama.llms <span class="keyword">import</span> OllamaLLM</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">llm = OllamaLLM(base_url=<span class="string">&quot;http://127.0.0.1:11434&quot;</span>, model=<span class="string">&quot;deepseek-r1:32b&quot;</span>)</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;你是世界级的 AI 技术专家, &#123;input&#125;&quot;</span></span><br><span class="line"><span class="comment"># 这里我们使用一个简单的模板</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    template=template</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 创建一个简单的链式调用</span></span><br><span class="line">chain = prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行链式调用</span></span><br><span class="line">response = chain.invoke(&#123;</span><br><span class="line">    <span class="string">&quot;input&quot;</span>:<span class="string">&quot;请写一篇关于 AI 的文章，字数不大于 100&quot;</span></span><br><span class="line">&#125;)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure><p>输出结果如下图所示：</p><p><img src="/assets/img/ailearn/ai-learn04-3.png" alt="langchain-1"></p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><p>Langchain让我们实现调用一个大模型API 变得更加简单，只需要几行代码就会实现一个简单对话。主要实现逻辑为：</p><ul><li>引入 Langchain 封装好的大模型的库</li><li>创建一个 PromptTemplate 模板</li><li>创建一个链式调用，包括：PromptTemplate | 大模型 | StrOutputParser</li><li>执行链式调用并输出结果</li></ul><blockquote><p>记录问题： 如果我部署的大模型 Langchain 没有找到对应的模型，应该怎么做？</p></blockquote><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://python.langchain.com/docs/introduction/">LangChain官方文档</a></li><li><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide">LangChain中文教程</a></li><li><a href="https://blog.csdn.net/qq_56591814/article/details/135040694">LangChain（0.0.340）官方文档十一：Agents之Agent Types</a></li><li><a href="https://www.bilibili.com/video/BV1BgfBYoEpQ/?spm_id_from=333.337.search-card.all.click&vd_source=b7fdd8e45e19e1ed72549bc7a40058f6">(哔哩哔哩视频)2025吃透LangChain大模型全套教程（LLM+RAG+OpenAI+Agent）通俗易懂，学完即就业!</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek-R1模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一节学习了&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn03.html&quot;&gt;03篇 AI从零开始 - AI从零开始 - Prompt提示语学习与应用&lt;/a&gt;，但是我们发现，Prompt提示语虽然可以让我们得到想要的答案，但是它也有缺点，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只调用单个大模型的对话提示语来生成答案，且无法验证答案的正确性；&lt;/li&gt;
&lt;li&gt;大模型是没有记忆能力，且有token上下对话长度限制，无法实现多轮对话；&lt;/li&gt;
&lt;li&gt;多步骤推理任务，需要多次调用大模型，效率低下&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果要开发一个完整 LLM应用，开发者需要手动处理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多组件集成：模型调用、外部数据源、记忆存储、业务逻辑等模块的拼接&lt;/li&gt;
&lt;li&gt;上下文管理：对话历史、长期记忆、知识库检索的复杂交互&lt;/li&gt;
&lt;li&gt;流程编排：多步骤推理、条件分支、循环控制等逻辑&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来，我们学习一下LangChain，它是一个基于链式调用的LLM框架，可以让我们更加方便地使用大模型，实现多轮对话、多步骤推理等复杂功能。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>03篇 AI从零开始 - Prompt提示语学习与应用</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn03.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn03.html</id>
    <published>2025-02-12T07:00:00.000Z</published>
    <updated>2025-02-13T12:40:45.204Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>前面我们在<a href="https://qborfy.com/ailearn/ai-learn02.html#more">02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1</a>中学习如何搭建本地大模型，本篇我们学习如何使用Prompt提示语，来让 AI 返回结果更加有符合我们所需要的效果。</p><h1 id="1-Prompt提示语基础学习"><a href="#1-Prompt提示语基础学习" class="headerlink" title="1. Prompt提示语基础学习"></a>1. Prompt提示语基础学习</h1><p>在很多AI学习的文章中，我们都会看到Prompt提示语，那么Prompt提示语是什么，有什么作用呢？</p><p>在OpenAI的官方文档中，对Prompt提示语的解释是：</p><blockquote><p>Prompt: A prompt is a short text that is used to guide the model’s output. It can be used to provide context, specify the desired output format, or even to control the model’s behavior.<br>翻译中文则是“Prompt: Prompt是一种用于指导模型输出的短文本。它可以用于提供上下文、指定所需的输出格式，甚至可以用于控制模型的行为。”</p></blockquote><p>我们简单理解一下，Prompt提示语就是，我们给模型输入一段文本，告诉模型，我们想要什么结果，模型就会按照我们的要求，生成我们想要的结果。</p><span id="more"></span><p>一个规范的提示语，有几个关键的组成部分: </p><ul><li><strong>角色</strong>: 是指希望 AI 在完成任务时所扮演的身份或视角。通过定义角色，可以让 AI 的输出更具专业性、针对性或特定风格。</li><li><strong>上下文</strong>: 是提供给模型的背景信息或对话历史，它像一条线索链，帮助 AI 更好地理解当前任务的关联性和具体要求。</li><li><strong>指令/任务</strong>:  是希望 AI 执行的具体操作的核心陈述。它是提示语的“行动命令”，直接影响输出的方向和形式。</li><li><strong>范例</strong>: 是提示语中最直观的示范材料，它能像教学案例一样具象化你的需求，降低沟通歧义。</li><li><strong>输出格式</strong>: 就像为AI搭建一个展示成果的舞台框架，它决定了信息的组织方式和最终呈现形态。合理设置格式可以提升信息传达效率，尤其适用于需要结构化数据的场景。</li></ul><p>接下来，我们针对不同的提示语分别了解一下提示语不同组成部分的作用。</p><h2 id="1-1-角色"><a href="#1-1-角色" class="headerlink" title="1.1 角色"></a>1.1 角色</h2><h3 id="为什么需要设置角色？"><a href="#为什么需要设置角色？" class="headerlink" title="为什么需要设置角色？"></a><strong>为什么需要设置角色？</strong></h3><p>想象你要拍一部电影：</p><ul><li><strong>无指定角色</strong>：演员自由发挥，可能不符合剧情需求；</li><li><strong>明确角色</strong>：导演指定演员演医生、侦探或喜剧人，表演会更贴合剧本。</li></ul><p>同样，<strong>赋予 AI 角色</strong>相当于让它戴上不同的“职业帽子”，输出效果会有显著差异！</p><hr><h3 id="如何通过角色优化提示语？"><a href="#如何通过角色优化提示语？" class="headerlink" title="如何通过角色优化提示语？"></a><strong>如何通过角色优化提示语？</strong></h3><h4 id="1️⃣-专业型角色"><a href="#1️⃣-专业型角色" class="headerlink" title="1️⃣ 专业型角色"></a>1️⃣ <strong>专业型角色</strong></h4><p>当需要权威性或技术性内容时，可指定专家身份：</p><ul><li>❌ 普通提问：<br>“告诉我如何减肥。”  </li><li>✅ 角色限定：<br>“假如你是营养学教授，为一名BMI超标的上班族制定安全减重方案，需包含饮食、运动和心理调节建议。”</li></ul><h4 id="2️⃣-创意型角色"><a href="#2️⃣-创意型角色" class="headerlink" title="2️⃣ 创意型角色"></a>2️⃣ <strong>创意型角色</strong></h4><p>激发 AI 的故事力或艺术性表达：</p><ul><li>❌ 通用请求：<br>“写一首诗。”  </li><li>✅ 角色+风格：<br>“模仿李白的浪漫主义风格，以‘人工智能与月亮’为主题，写一首七言绝句。”</li></ul><h4 id="3️⃣-中介型角色"><a href="#3️⃣-中介型角色" class="headerlink" title="3️⃣ 中介型角色"></a>3️⃣ <strong>中介型角色</strong></h4><p>让 AI 模拟特定对象的口吻：</p><ul><li>❌ 直白需求：<br>“教孩子刷牙。”  </li><li>✅ 角色转换：<br>“你是一只爱干净的卡通兔子，用儿歌和拟声词教3岁小朋友正确的刷牙步骤。”</li></ul><hr><h3 id="角色的进阶用法"><a href="#角色的进阶用法" class="headerlink" title="角色的进阶用法"></a><strong>角色的进阶用法</strong></h3><ul><li><strong>多重角色协作</strong>：<br>“你既是编剧又是影评人。先为科幻短片《火星幼儿园》写一个大纲，再从观众角度分析它的创新点和风险。”  </li><li><strong>反向角色训练</strong>：<br>“你现在是小学生，我来教你勾股定理。如果我讲解不清楚，请随时提出幼稚的问题。”  </li></ul><hr><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a><strong>注意事项</strong></h3><ul><li>🎯 <strong>角色与目标一致</strong>：避免让诗人写代码，或程序员作抒情诗（除非刻意制造反差）；  </li><li>📝 <strong>细化角色特征</strong>：年龄、行业、性格等描述越具体，输出越生动；  </li><li>🔄 <strong>动态调整角色</strong>：同一对话中可通过指令如“现在切换为经济学家身份”改变 AI 应答模式。</li></ul><hr><h3 id="小练习✨"><a href="#小练习✨" class="headerlink" title="小练习✨"></a><strong>小练习✨</strong></h3><p>优化以下提示语，加入角色设定：<br>❌ 原句：”介绍一下太阳能的好处。”<br>✅ 参考答案：”假设你是环保机构的科普讲师，用通俗易懂的语言向农村老人列举太阳能的3个实际优点，避免使用专业术语。”</p><hr><p>通过角色设定，你能像导演指挥演员一样，精准调动 AI 的能力边界和表达风格🎭。试试给你的下一个提示语“发一张工作证”吧！</p><h2 id="1-2-上下文"><a href="#1-2-上下文" class="headerlink" title="1.2 上下文"></a>1.2 上下文</h2><h3 id="为什么要关注上下文？"><a href="#为什么要关注上下文？" class="headerlink" title="为什么要关注上下文？"></a><strong>为什么要关注上下文？</strong></h3><p>假设你和朋友聊天：</p><ul><li><p><strong>没有上下文：</strong><br>你突然说：”好的，明天见！”<br>朋友会困惑：”明天要见面吗？约在哪里？”</p></li><li><p><strong>有上下文：</strong><br>你先说：”周末想去看电影吗？” → 朋友回复：”好啊，看哪部？” → 你再答：”《奥本海默》怎么样？明晚7点万达影院。” → 最后说：”没问题，明天见！”<br>（通过多轮对话建立清晰的情境）</p></li></ul><p>同理，<strong>AI 需要足够的上下文才能精准回应你的需求。</strong></p><hr><h3 id="如何在提示语中添加上下文？"><a href="#如何在提示语中添加上下文？" class="headerlink" title="如何在提示语中添加上下文？"></a><strong>如何在提示语中添加上下文？</strong></h3><h4 id="1️⃣-单次提问中提供背景"><a href="#1️⃣-单次提问中提供背景" class="headerlink" title="1️⃣ 单次提问中提供背景"></a>1️⃣ <strong>单次提问中提供背景</strong></h4><ul><li><p>❌ 模糊提问：<br>“这段话翻译成英文。”<br>（AI 不知道原文用途、语气或专业术语是否需要调整）</p></li><li><p>✅ 带上下文的提问：<br>“这是一份医疗器械说明书的技术参数部分，请用专业学术英语翻译以下中文段落，保留术语缩写：[附上原文]”  </p></li></ul><h4 id="2️⃣-多轮对话中延续上下文"><a href="#2️⃣-多轮对话中延续上下文" class="headerlink" title="2️⃣ 多轮对话中延续上下文"></a>2️⃣ <strong>多轮对话中延续上下文</strong></h4><ul><li><p>第一轮：<br>“我想写一封辞职信，模板太正式了，能帮我改得温和一些吗？”<br>AI 生成初稿。</p></li><li><p>第二轮：<br>“谢谢！请在结尾加一句‘感谢团队过去三年的支持’，并用口语化词汇替换‘因个人职业规划’这句。”<br>（AI 会根据前文调整，而不是重新生成无关内容）</p></li></ul><h4 id="3️⃣-隐式上下文的利用"><a href="#3️⃣-隐式上下文的利用" class="headerlink" title="3️⃣ 隐式上下文的利用"></a>3️⃣ <strong>隐式上下文的利用</strong></h4><p>即使不主动说明，AI 也会根据输入内容自动推断隐含信息。例如：  </p><ul><li>你输入：”李白是谁？” → AI 默认回答诗人身份。  </li><li>若你输入：”王者荣耀里的李白技能怎么用？” → AI 会自动切换到游戏角色解析。</li></ul><hr><h3 id="上下文的常见误区"><a href="#上下文的常见误区" class="headerlink" title="上下文的常见误区"></a><strong>上下文的常见误区</strong></h3><ul><li><p>🚫 <strong>信息过载</strong>：堆砌无关细节会让 AI 迷失重点。<br>✅ 技巧：只保留与任务强相关的背景。</p></li><li><p>🚫 <strong>断层跳跃</strong>：在多轮对话中突然切换话题而不重置上下文。<br>✅ 技巧：新任务开始时可以说”现在我们需要讨论另一个问题……”</p></li></ul><hr><h3 id="小练习✍️"><a href="#小练习✍️" class="headerlink" title="小练习✍️"></a><strong>小练习✍️</strong></h3><p>优化以下缺乏上下文的 Prompt：<br>❌ 原句：”解释一下量子力学。”<br>✅ 优化后：”我是一名高中生，刚学完原子结构章节，请用比喻和日常例子简单解释量子力学中的‘叠加态’概念。”</p><hr><p>通过合理控制上下文，你可以让 AI 的输出更贴近真实需求，就像给导航软件设定起点和终点一样重要 🌟</p><h2 id="1-3-指令-任务"><a href="#1-3-指令-任务" class="headerlink" title="1.3 指令/任务"></a>1.3 指令/任务</h2><h3 id="指令的本质是什么？"><a href="#指令的本质是什么？" class="headerlink" title="指令的本质是什么？"></a><strong>指令的本质是什么？</strong></h3><p>如果把 AI 比作员工，那么指令就是你布置的工作任务。<br>-<strong>模糊指令</strong> = “整理这份资料”（员工不确定按什么标准分类或呈现）<br>-<strong>清晰指令</strong> = “将会议纪要中的待办事项提取出来，按优先级排序，标记负责人和截止时间”（明确动作、规则、交付形态）</p><h3 id="如何设计有效指令？"><a href="#如何设计有效指令？" class="headerlink" title="如何设计有效指令？"></a><strong>如何设计有效指令？</strong></h3><h4 id="1️⃣-动词先行-结果导向"><a href="#1️⃣-动词先行-结果导向" class="headerlink" title="1️⃣ 动词先行 + 结果导向"></a>1️⃣ <strong>动词先行 + 结果导向</strong></h4><p>直接用动词开头，声明核心任务类型：</p><ul><li>❌ 笼统请求：<br>“关于气候变化的数据。”  </li><li>✅ 明确指令：<br>“对比近十年全球碳排放量变化趋势，用柱状图数据表格展示，标注主要国家增减幅度。”</li></ul><h4 id="2️⃣-区分任务层级"><a href="#2️⃣-区分任务层级" class="headerlink" title="2️⃣ 区分任务层级"></a>2️⃣ <strong>区分任务层级</strong></h4><ul><li><strong>基础操作类</strong>（单一动作）：<br>“将以下英文论文摘要翻译成简体中文。”  </li><li><strong>综合分析类</strong>（多步骤处理）：<br>“阅读这三篇社会学的田野调查报告，总结研究方法共性，批判性分析其样本选择偏差风险。”</li></ul><h4 id="3️⃣-约束条件绑定"><a href="#3️⃣-约束条件绑定" class="headerlink" title="3️⃣ 约束条件绑定"></a>3️⃣ <strong>约束条件绑定</strong></h4><p>附加限制条件缩小任务范围：<br>-“用小学生能理解的比喻，解释区块链原理（不超过100字）”<br>-“生成5条七夕节珠宝促销朋友圈文案，要求押韵，每条附带表情符号🌹💎”</p><h3 id="典型错误与修正"><a href="#典型错误与修正" class="headerlink" title="典型错误与修正"></a><strong>典型错误与修正</strong></h3><table><thead><tr><th><strong>问题类型</strong></th><th>❌ 低效示例</th><th>✅ 优化思路</th></tr></thead><tbody><tr><td><strong>缺少主指令</strong></td><td>“我觉得最近经济形势不太好……”</td><td>➡️ 补全动作：”分析当前CPI上涨对普通人消费的影响，并提出3条省钱建议。”</td></tr><tr><td><strong>多指令混杂</strong></td><td>“总结这本书并推荐类似书籍再写个书评”</td><td>➡️ 分步拆解：<br>1. 用三句话概括《人类简史》核心观点<br>2. 推荐3本同主题著作并说明理由<br>3. 撰写200字幽默风格短评</td></tr><tr><td><strong>指令过泛</strong></td><td>“写一篇关于人工智能的文章”</td><td>➡️ 精准聚焦：<br>1. 用一句话概括人工智能技术发展现状<br>2. 介绍人工智能在医疗、金融、教育等领域的应用<br>3. 分析人工智能对人类社会的影响</td></tr><tr><td><strong>指令过细</strong></td><td>“用表格展示2023年Q4各品类销售数据”</td><td>➡️ 精简概括：<br>1. 用柱状图展示各品类销售额占比<br>2. 用折线图展示销售额变化趋势<br>3. 用饼图展示各品类销售额占比变化趋势</td></tr></tbody></table><h3 id="高阶技巧"><a href="#高阶技巧" class="headerlink" title="高阶技巧"></a><strong>高阶技巧</strong></h3><ul><li><strong>隐性指令传递</strong>：<br>通过示例暗示任务要求（如提供已排版文本让 AI 模仿格式）  </li><li><strong>元指令调控</strong>：<br>预先约定响应规则（例：”所有回答先用一句话总结结论，再用分点论述”）</li></ul><h3 id="小练习"><a href="#小练习" class="headerlink" title="小练习"></a><strong>小练习</strong></h3><p>改写以下模糊指令：<br>❌ 原句：”处理这些客户反馈。”<br>✅ 参考方案：”从2023年Q4投诉邮件中统计出现频率最高的前5类质量问题，用饼图可视化占比，并提出改进措施关键词。”</p><p>清晰的指令如同GPS坐标，能让 AI 准确抵达目的地📍。记住：<strong>不要问AI能做什么，而是告诉TA该怎么做</strong>。</p><h2 id="1-4-范例"><a href="#1-4-范例" class="headerlink" title="1.4 范例"></a>1.4 范例</h2><h3 id="为什么需要提供范例？"><a href="#为什么需要提供范例？" class="headerlink" title="为什么需要提供范例？"></a><strong>为什么需要提供范例？</strong></h3><p>试想两种学习方式：</p><ul><li><strong>纯文字描述</strong>：<br>“画一只猫，要有科技感”</li><li><strong>图文对照</strong>：<br>“参考这张赛博朋克风格的机械猫设计图（附图），保持齿轮关节和荧光线条的特征，但把瞳孔改成三角形”</li></ul><p>显然第二种方式更能锁定预期效果。<strong>范例就是给AI的视觉锚点或样式模板</strong>。</p><h3 id="何时需要使用范例？"><a href="#何时需要使用范例？" class="headerlink" title="何时需要使用范例？"></a><strong>何时需要使用范例？</strong></h3><h4 id="1️⃣-风格迁移"><a href="#1️⃣-风格迁移" class="headerlink" title="1️⃣ 风格迁移"></a>1️⃣ <strong>风格迁移</strong></h4><p>当涉及抽象审美或文体要求时：  </p><ul><li>❌ 语言描述困难：<br>“我想要复古的海报字体”  </li><li>✅ 图片+文字说明：<br>“参照这张1950年代电影海报的字体风格（附图），为咖啡馆店名’旧时光’设计LOGO，保留斑驳纹理但不做褪色处理”</li></ul><h4 id="2️⃣-复杂格式规范"><a href="#2️⃣-复杂格式规范" class="headerlink" title="2️⃣ 复杂格式规范"></a>2️⃣ <strong>复杂格式规范</strong></h4><p>需要结构化输出时：  </p><ul><li>❌ 纯文本要求易出错：<br>“按照学术期刊格式调整参考文献”  </li><li>✅ 提供模板示例：  <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># 目标格式示例：</span></span><br><span class="line">[1] Author A, Author B. Title[J]. Journal Name, 2023, 10(2): 25-30. DOI:xxxx  </span><br><span class="line"><span class="section"># 待处理的原始文献：  </span></span><br><span class="line">Smith J et al. Climate Change Impacts... (后续略)</span><br></pre></td></tr></table></figure></li></ul><h4 id="3️⃣-语义校准"><a href="#3️⃣-语义校准" class="headerlink" title="3️⃣ 语义校准"></a>3️⃣ <strong>语义校准</strong></h4><p>防止专业领域用词偏差：  </p><ul><li>❌ 泛化表述：<br>“写芯片制造工艺的创新点”  </li><li>✅ 对标样例：<br>“仿照下面这段光刻技术突破的描述（附范例），用相同技术文档结构说明3D封装工艺的优势：<br>【范例】极紫外光刻(EUV)通过…实现了线宽微缩至7nm以下…(下略)”</li></ul><h3 id="范例的使用技巧"><a href="#范例的使用技巧" class="headerlink" title="范例的使用技巧"></a><strong>范例的使用技巧</strong></h3><table><thead><tr><th><strong>方法</strong></th><th><strong>应用场景</strong></th><th><strong>实例</strong></th></tr></thead><tbody><tr><td><strong>正反例对比</strong></td><td>明确质量红线</td><td>“广告标语要像例句A这样突出产品功能，避免例句B空洞的情感词”</td></tr><tr><td><strong>渐进迭代</strong></td><td>持续优化输出</td><td>首轮提供基础范例→收到初稿后追加修改意见：”请参考新范例增加数据对比模块”</td></tr><tr><td><strong>跨模态引导</strong></td><td>打通不同表现形式</td><td>上传手绘流程图草图并要求：”将此逻辑转化为PPT图示，配色参考附件企业VI手册”</td></tr></tbody></table><h3 id="注意事项-1"><a href="#注意事项-1" class="headerlink" title="注意事项"></a><strong>注意事项</strong></h3><ul><li>⚠️ <strong>版权风险</strong>：避免直接复制受保护的内容作为范例  </li><li>💡 <strong>适度精简</strong>：关键片段优于完整长文（特殊需求除外）  </li><li>🔄 <strong>动态更新</strong>：长期使用时定期刷新范例以防模型过拟合陈旧模式</li></ul><h3 id="小练习🔧"><a href="#小练习🔧" class="headerlink" title="小练习🔧"></a><strong>小练习🔧</strong></h3><p>优化以下提示语：<br>❌ 原句：”帮我想几句婚礼祝福语”<br>✅ 升级版：  </p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">请模仿这个获奖贺词的排比句式（附范例），创作3句适合长辈致辞的中式婚礼祝福语，每句以&quot;一愿&quot;开头，融入梅兰竹菊意象：</span><br><span class="line"></span><br><span class="line">【范例】</span><br><span class="line">&quot;一愿你策马山河，青春不改凌云志  </span><br><span class="line">二愿你执笔星辰，热血常存赤子心  </span><br><span class="line">三愿你回望征途，笑颜永似少年时&quot;</span><br></pre></td></tr></table></figure><p>用好范例就如同给AI配备了「临摹字帖」，能大幅提升输出质量的稳定性和精确度✨ 下次遇到抽象需求时，记得问自己：<strong>能否找到一个具体参照物来示范？</strong></p><h2 id="1-5-输出格式"><a href="#1-5-输出格式" class="headerlink" title="1.5 输出格式"></a>1.5 输出格式</h2><h3 id="为什么要规定输出格式？"><a href="#为什么要规定输出格式？" class="headerlink" title="为什么要规定输出格式？"></a><strong>为什么要规定输出格式？</strong></h3><p>设想你需要一份报告：</p><ul><li><strong>无格式要求</strong>：<br>AI可能返回杂乱的长段落，关键信息被淹没  </li><li><strong>有格式约束**</strong>:<br>“用Markdown表格对比iPhone14/15参数，分为屏幕、摄像头、电池三列，最后添加优缺点总结栏”</li></ul><p>后者不仅便于快速扫描比较，还能直接复制到文档中使用，节省二次编辑时间。</p><hr><h3 id="常见格式类型及应用"><a href="#常见格式类型及应用" class="headerlink" title="常见格式类型及应用"></a><strong>常见格式类型及应用</strong></h3><table><thead><tr><th><strong>格式类别</strong></th><th><strong>适用场景</strong></th><th><strong>示例指令</strong></th></tr></thead><tbody><tr><td><strong>自然段落</strong></td><td>故事创作、观点阐述</td><td>“用三个连贯段落描述未来城市交通，每段以设问句开头”</td></tr><tr><td><strong>结构化列表</strong></td><td>要点罗列、步骤说明</td><td>“列出5种提高记忆力的科学方法，每个方法含①原理简述②实操步骤③每日耗时”</td></tr><tr><td><strong>表格/图表</strong></td><td>数据对比、参数分析</td><td>“创建对比表显示各省GDP增速，包含排名、省份名称、2022vs2023增长率、变化幅度”</td></tr><tr><td><strong>代码块</strong></td><td>编程辅助、公式展示</td><td>“用Python代码演示线性回归预测房价，要求包含注释和matplotlib可视化部分”</td></tr><tr><td><strong>对话体</strong></td><td>情景模拟、访谈记录</td><td>“编写客服与顾客关于退换货政策的对话，体现专业性与共情力，交替发言至少8轮”</td></tr></tbody></table><hr><h3 id="格式设计四要素"><a href="#格式设计四要素" class="headerlink" title="格式设计四要素"></a><strong>格式设计四要素</strong></h3><h4 id="1️⃣-层次分明"><a href="#1️⃣-层次分明" class="headerlink" title="1️⃣ 层次分明"></a>1️⃣ <strong>层次分明</strong></h4><ul><li>使用标题分级：<br>“# 年度总结\n## 业绩亮点\n### 客户增长”</li><li>添加序号标识：<br>“解决方案分三点呈现：⑴…⑵…⑶…”</li></ul><h4 id="2️⃣-留白控制"><a href="#2️⃣-留白控制" class="headerlink" title="2️⃣ 留白控制"></a>2️⃣ <strong>留白控制</strong></h4><ul><li>限制长度：<br>“每个论点阐述不超过50字”</li><li>空行分隔：<br>“章节之间用—分割”</li></ul><h4 id="3️⃣-标记强化"><a href="#3️⃣-标记强化" class="headerlink" title="3️⃣ 标记强化"></a>3️⃣ <strong>标记强化</strong></h4><ul><li>重点标注：<br>“关键技术名词用<strong>粗体</strong>表示”</li><li>颜色提示（支持渲染的平台）：<br>“盈利数据标为绿色，亏损标红色”</li></ul><h4 id="4️⃣-交互适配"><a href="#4️⃣-交互适配" class="headerlink" title="4️⃣ 交互适配"></a>4️⃣ <strong>交互适配</strong></h4><ul><li>平台兼容：<br>“输出格式兼容微信排版，无需Markdown语法”</li><li>设备优化：<br>“生成适合手机竖屏浏览的信息图文案”</li></ul><hr><h3 id="经典组合技"><a href="#经典组合技" class="headerlink" title="经典组合技"></a><strong>经典组合技</strong></h3><ul><li><strong>格式嵌套</strong>：<br>“先以时间轴形式梳理辛亥革命大事件（年份+事件+影响），再用SWOT分析法总结历史意义”  </li><li><strong>动态格式</strong>：<br>“根据输入内容自动选择最佳呈现方式：争议话题用正反方辩论体，客观知识用问答体”</li></ul><hr><h3 id="避坑指南"><a href="#避坑指南" class="headerlink" title="避坑指南"></a><strong>避坑指南</strong></h3><ul><li>🚫 <strong>过度格式化</strong>：简单的天气查询不需要五级目录  </li><li>✔️ <strong>格式验证</strong>：添加自检指令如”请确保JSON格式有效”  </li><li>🌐 <strong>编码统一</strong>：跨境使用注明”所有计量单位采用公制”</li></ul><hr><h3 id="实训练习📝"><a href="#实训练习📝" class="headerlink" title="实训练习📝"></a><strong>实训练习📝</strong></h3><p>优化下列提示语：<br>❌ 原句：”说说新能源汽车的优点”<br>✅ 格式增强版：  </p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">请按以下框架组织内容：</span><br><span class="line"><span class="section"># 新能源汽车优势分析</span></span><br><span class="line"><span class="section">## 环境效益</span></span><br><span class="line"><span class="bullet">-</span> 减排表现 ▸ 量化数据对比燃油车</span><br><span class="line"><span class="bullet">-</span> 噪音控制 ▸ 城市道路实测分贝值</span><br><span class="line"><span class="section">## 经济效益 </span></span><br><span class="line"><span class="bullet">-</span> 补贴政策 ▸ 2023最新购置税减免额度</span><br><span class="line"><span class="bullet">-</span> 维保成本 ▸ 三年周期预估费用表</span><br><span class="line">► 最后用[❗]符号标注最具颠覆性的创新点</span><br></pre></td></tr></table></figure><p>掌握格式设计就相当于获得了<strong>信息整形术</strong>——同样的内容经过精心排版，价值感知度可提升300%以上。记住：<strong>好的格式不是束缚，而是专业的可视化表达！</strong></p><h1 id="2-Prompt实践应用"><a href="#2-Prompt实践应用" class="headerlink" title="2. Prompt实践应用"></a>2. Prompt实践应用</h1><p>通过上面的讲解，相信大家对Prompt已经有了初步了解，那么接下来，我们通过一个具体的例子， 利用 5 大核心要素去构建一个系统工程化的 Prompt，来帮助大家更好的理解 Prompt 的应用。</p><p>目标： <strong>根据用户输入的关键词， 生成用户所需要的 SQL 语句。</strong></p><h2 id="2-1-角色定位"><a href="#2-1-角色定位" class="headerlink" title="2.1  角色定位"></a>2.1  角色定位</h2><p>对模型的角色定位越精准越好，ta 就越容易理解用户的意图，从而生成更符合用户需求的答案。</p><p>比如这里我们需要生成 SQL 语句，那么我们就可以将模型的角色定位为 <code>SQL 语句生成器</code>，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">您是具有以下能力的专业数据库工程师：</span><br><span class="line">- 准确解析用户业务场景关键词</span><br><span class="line">- 掌握ANSI SQL标准及主流数据库方言</span><br><span class="line">- 熟悉数据库设计范式与性能优化原则</span><br><span class="line">- 具备多表关联查询设计能力</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-2-上下文"><a href="#2-2-上下文" class="headerlink" title="2.2  上下文"></a>2.2  上下文</h2><p>上下文包括用户所操作的数据库的结构信息，如表名、字段等，以及用户的查询意图，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">用户需要快速生成准确SQL语句但可能面临：</span><br><span class="line">1. 不熟悉复杂表关联结构</span><br><span class="line">2. 对特定函数用法不明确(如时间处理函数)</span><br><span class="line">3. 多条件组合逻辑易混淆</span><br><span class="line">4. 需要兼顾查询性能优化</span><br></pre></td></tr></table></figure><h2 id="2-3-指令-任务"><a href="#2-3-指令-任务" class="headerlink" title="2.3 指令/任务"></a>2.3 指令/任务</h2><p>用户将提供一些关键词或者简短的描述，描述他们想从数据库中查询什么信息。系统需要根据这些信息生成正确的SQL查询语句。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">按以下步骤处理用户输入的关键词：</span><br><span class="line">1. 语义解析：识别关键词中的核心要素</span><br><span class="line">   - 操作类型(SELECT/INSERT/UPDATE/DELETE)</span><br><span class="line">   - 目标表/字段</span><br><span class="line">   - 过滤条件(时间范围、状态值等)</span><br><span class="line">   - 排序/分组需求</span><br><span class="line">   - 分页参数</span><br><span class="line"></span><br><span class="line">2. 结构映射：</span><br><span class="line">   a. 自动关联相关表的JOIN条件</span><br><span class="line">   b. 识别VARCHAR字段自动添加引号</span><br><span class="line">   c. 数值型字段保持原生格式</span><br><span class="line">   d. 日期字段转换处理(如STR_TO_DATE)</span><br><span class="line"></span><br><span class="line">3. 逻辑校验：</span><br><span class="line">   - 当检测到危险操作时(如无条件的DELETE)添加警示</span><br><span class="line">   - 对超过3表关联的查询建议索引优化</span><br><span class="line">   - 为模糊查询(%value%)提示性能影响</span><br></pre></td></tr></table></figure><h2 id="2-4-范例"><a href="#2-4-范例" class="headerlink" title="2.4  范例"></a>2.4  范例</h2><p>提供一些示例输入和对应的SQL输出，帮助系统理解任务，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[输入关键词] </span><br><span class="line">&quot;需要最近三个月上海地区单价超过5000元的电子产品订单，按金额降序排&quot;</span><br><span class="line"></span><br><span class="line">[生成SQL]</span><br><span class="line">SELECT </span><br><span class="line">    o.order_id,</span><br><span class="line">    u.user_name,</span><br><span class="line">    p.product_name,</span><br><span class="line">    o.order_amount,</span><br><span class="line">    o.create_time</span><br><span class="line">FROM </span><br><span class="line">    orders o</span><br><span class="line">    JOIN users u ON o.user_id = u.user_id</span><br><span class="line">    JOIN products p ON o.product_id = p.product_id</span><br><span class="line">WHERE </span><br><span class="line">    o.region = &#x27;上海&#x27;</span><br><span class="line">    AND p.category = &#x27;电子产品&#x27;</span><br><span class="line">    AND o.order_amount &gt; 5000</span><br><span class="line">    AND o.create_time &gt;= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)</span><br><span class="line">ORDER BY </span><br><span class="line">    o.order_amount DESC</span><br><span class="line">LIMIT 100;</span><br><span class="line"></span><br><span class="line">[说明]</span><br><span class="line">1. 自动关联三表JOIN</span><br><span class="line">2. 数值条件未加引号</span><br><span class="line">3. 添加LIMIT防止结果集过大</span><br><span class="line">4. 时间条件使用函数动态计算</span><br></pre></td></tr></table></figure><h2 id="2-5-输出格式"><a href="#2-5-输出格式" class="headerlink" title="2.5 输出格式"></a>2.5 输出格式</h2><p>输出格式是对输出数据结构的描述，具体例子如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[仅返回SQL语句，无需任何额外说明]</span><br></pre></td></tr></table></figure><h2 id="2-6-完整的应用示例"><a href="#2-6-完整的应用示例" class="headerlink" title="2.6 完整的应用示例"></a>2.6 完整的应用示例</h2><p>最终我们得到的 Prompt 如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">您是具有以下能力的专业数据库工程师：</span><br><span class="line">- 准确解析用户业务场景关键词</span><br><span class="line">- 掌握ANSI SQL标准及主流数据库方言</span><br><span class="line">- 熟悉数据库设计范式与性能优化原则</span><br><span class="line">- 具备多表关联查询设计能力</span><br><span class="line"></span><br><span class="line">用户需要快速生成准确SQL语句但可能面临：</span><br><span class="line">1. 不熟悉复杂表关联结构</span><br><span class="line">2. 对特定函数用法不明确(如时间处理函数)</span><br><span class="line">3. 多条件组合逻辑易混淆</span><br><span class="line">4. 需要兼顾查询性能优化</span><br><span class="line"></span><br><span class="line">按以下步骤处理用户输入的关键词：</span><br><span class="line">1. 语义解析：识别关键词中的核心要素</span><br><span class="line">   - 操作类型(SELECT/INSERT/UPDATE/DELETE)</span><br><span class="line">   - 目标表/字段</span><br><span class="line">   - 过滤条件(时间范围、状态值等)</span><br><span class="line">   - 排序/分组需求</span><br><span class="line">   - 分页参数</span><br><span class="line"></span><br><span class="line">2. 结构映射：</span><br><span class="line">   a. 自动关联相关表的JOIN条件</span><br><span class="line">   b. 识别VARCHAR字段自动添加引号</span><br><span class="line">   c. 数值型字段保持原生格式</span><br><span class="line">   d. 日期字段转换处理(如STR_TO_DATE)</span><br><span class="line"></span><br><span class="line">3. 逻辑校验：</span><br><span class="line">   - 当检测到危险操作时(如无条件的DELETE)添加警示</span><br><span class="line">   - 对超过3表关联的查询建议索引优化</span><br><span class="line">   - 为模糊查询(%value%)提示性能影响</span><br><span class="line"></span><br><span class="line">[输入关键词] </span><br><span class="line">&quot;需要最近三个月上海地区单价超过5000元的电子产品订单，按金额降序排&quot;</span><br><span class="line"></span><br><span class="line">[输出]</span><br><span class="line">SELECT</span><br><span class="line">    o.order_id,</span><br><span class="line">    u.user_name,</span><br><span class="line">    p.product_name,</span><br><span class="line">    o.order_amount,</span><br><span class="line">    o.create_time</span><br><span class="line">FROM</span><br><span class="line">    orders o</span><br><span class="line">    JOIN users u ON o.user_id = u.user_id</span><br><span class="line">    JOIN products p ON o.product_id = p.product_id</span><br><span class="line">WHERE</span><br><span class="line">    o.region = &#x27;上海&#x27;</span><br><span class="line">    AND p.category = &#x27;电子产品&#x27;</span><br><span class="line">    AND o.order_amount &gt; 5000</span><br><span class="line">    AND o.create_time &gt;= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)</span><br><span class="line">ORDER BY</span><br><span class="line">    o.order_amount DESC</span><br><span class="line">LIMIT 100;</span><br><span class="line"></span><br><span class="line">[说明]</span><br><span class="line">1. 自动关联三表JOIN</span><br><span class="line">2. 数值条件未加引号</span><br><span class="line">3. 添加LIMIT防止结果集过大</span><br><span class="line">4. 时间条件使用函数动态计算</span><br><span class="line"></span><br><span class="line">[仅返回SQL语句，无需任何额外说明]</span><br><span class="line"></span><br><span class="line">如果你已理解上述要求，请回答是的。</span><br></pre></td></tr></table></figure><p>通过 DeepSeek 输入后我们可以如下所示的结果：</p><p><img src="/assets/img/ailearn/ai-learn03-1.png" alt=""></p><p>当然这个只是 Prompt 的一个简单示例，实际应用中，Prompt 可以包含更复杂的逻辑，比如问题的分类，对答案的二次确认等等，以及结合知识库进行一定范围回答，甚至可以给出多个答案，然后评估答案的可信度，降低 AI 幻觉，后面就涉及到模型微调相关内容。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://www.promptingguide.ai/zh">提示工程指南</a></li><li><a href="https://github.com/dair-ai/Prompt-Engineering-Guide">Prompt-Engineering-Guide 英文原版</a></li><li><a href="https://platform.openai.com/docs/guides/prompt-engineering">OpenAI Prompt工程化</a></li><li><a href="https://platform.openai.com/docs/guides/prompt-generation">OpenAI Prompt生成器</a></li></ul><blockquote><p>声明：本文部分材料是基于<a href="https://chat.deepseek.com/">DeepSeek模型</a>生成。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们在&lt;a href=&quot;https://qborfy.com/ailearn/ai-learn02.html#more&quot;&gt;02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1&lt;/a&gt;中学习如何搭建本地大模型，本篇我们学习如何使用Prompt提示语，来让 AI 返回结果更加有符合我们所需要的效果。&lt;/p&gt;
&lt;h1 id=&quot;1-Prompt提示语基础学习&quot;&gt;&lt;a href=&quot;#1-Prompt提示语基础学习&quot; class=&quot;headerlink&quot; title=&quot;1. Prompt提示语基础学习&quot;&gt;&lt;/a&gt;1. Prompt提示语基础学习&lt;/h1&gt;&lt;p&gt;在很多AI学习的文章中，我们都会看到Prompt提示语，那么Prompt提示语是什么，有什么作用呢？&lt;/p&gt;
&lt;p&gt;在OpenAI的官方文档中，对Prompt提示语的解释是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prompt: A prompt is a short text that is used to guide the model’s output. It can be used to provide context, specify the desired output format, or even to control the model’s behavior.&lt;br&gt;翻译中文则是“Prompt: Prompt是一种用于指导模型输出的短文本。它可以用于提供上下文、指定所需的输出格式，甚至可以用于控制模型的行为。”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们简单理解一下，Prompt提示语就是，我们给模型输入一段文本，告诉模型，我们想要什么结果，模型就会按照我们的要求，生成我们想要的结果。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>02篇 AI从零开始 - 部署本地大模型 DeepSeek-R1</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn02.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn02.html</id>
    <published>2025-02-08T07:00:00.000Z</published>
    <updated>2025-02-12T14:28:19.043Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><p>之前两篇文章对于 AI 有了初步的了解，但是如何应用 AI 技术呢？去调用 openai 的接口，或者国内的接口都需要付费，而且接口调用次数有限，所以我们需要部署一个本地的大模型，这样就可以自己使用，而且可以自己控制调用次数。正好最近 DeepSeek比较火热，所以我们就在本地尝试部署一下 DeepSeek-R1大模型吧。</p><h1 id="1-了解DeepSeek-R1"><a href="#1-了解DeepSeek-R1" class="headerlink" title="1. 了解DeepSeek-R1"></a>1. 了解DeepSeek-R1</h1><p>在开始之前，我们需要先了解一下 <a href="https://www.deepseek.com/">DeepSeek</a>, 官网介绍是这么写的：</p><blockquote><p>探索未至之境，DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。<br>在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。</p></blockquote><p>同时它开源了几个大模型，主要如下：</p><ul><li><a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1</a>，总参数671B，上下文长度最大支持128K，是在性能对齐 OpenAI-o1 正式版。</li><li><a href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3</a>，DeepSeek 上一代开源大模型。</li></ul><p>因此，作为最新的大模型，DeepSeek-R1 是我们部署的首选。接下来我们继续了解 DeepSeek-R1。</p><span id="more"></span><blockquote><p>2025.01.20 DeepSeek-R1 发布，DeepSeek R1 是 DeepSeek AI 开发的第一代推理模型，擅长复杂的推理任务，官方对标OpenAI o1正式版。适用于多种复杂任务，如数学推理、代码生成和逻辑推理等。<br>根据官方信息DeepSeek R1 可以看到提供多个版本，包括完整版（671B 参数）和蒸馏版（1.5B 到 70B 参数）。完整版性能强大，但需要极高的硬件配置；蒸馏版则更适合普通用户，硬件要求较低</p></blockquote><p>** 蒸馏版：”老师教学生“ 让一个庞大的、复杂的模型（老师）教会一个小巧的模型（学生）如何像自己一样聪明地完成任务。 **</p><p>因此，我们选择部署 DeepSeek-R1 蒸馏版（由于硬件有限，下面部署会使用  32B 的模型），因为这个版本比较适合我们普通用户，而且部署起来比较简单。</p><h1 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2. 准备工作"></a>2. 准备工作</h1><h2 id="2-1-硬件准备"><a href="#2-1-硬件准备" class="headerlink" title="2.1  硬件准备"></a>2.1  硬件准备</h2><p>下面是个人硬件配置，大家可以用来参考即可：</p><ul><li>内存：32GB</li><li>GPU：Tesla T4 16GB</li><li>CPU：32核</li><li>操作系统： tLinux 3.1 </li><li>硬盘：1TB SSD</li></ul><p>网上有很多硬件和模型对比资料， 这里我就不详细介绍了，大家可以自行搜索。不过最低要求是：</p><ul><li>Windows: NVIDIA GTX 1650 4GB 或 AMD RX 5500 4GB，16GB 内存，50GB 存储空间</li><li>Linux: NVIDIA GTX 1660 6GB 或 AMD RX 5500 4GB，16GB 内存，50GB 存储空间</li><li>Mac: M2 MacBook Air（8GB 内存）</li></ul><h2 id="2-2-软件下载-模型下载"><a href="#2-2-软件下载-模型下载" class="headerlink" title="2.2  软件下载+模型下载"></a>2.2  软件下载+模型下载</h2><h3 id="2-2-1-Ollama安装"><a href="#2-2-1-Ollama安装" class="headerlink" title="2.2.1 Ollama安装"></a>2.2.1 Ollama安装</h3><p>主要依赖<code>Ollama</code>本地部署,这里再简单介绍一下  Ollama， 官网介绍如下：</p><blockquote><p>Ollama 是一个开源的本地大语言模型运行框架，专为在本地机器上便捷部署和运行大型语言模型（LLM）而设计。 官网地址为：<a href="https://ollama.com/">https://ollama.com/</a><br>Ollama 是一个基于 Go 语言开发的简单易用的本地大语言模型运行框架。可以将其类比为 docker（同基于 cobra (opens new window)包实现命令行交互中的 list,pull,push,run 等命令），事实上它也的确制定了类 docker 的一种模型应用标准。</p></blockquote><p>后面写一篇文章详细介绍一下其使用方法，目前我们先保持现状即可。</p><p>Linux安装 Ollama命令很简单： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure><p>等待安装完成即可，执行下面命令查看是否安装成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama -h</span><br></pre></td></tr></table></figure><h3 id="2-2-2-模型下载"><a href="#2-2-2-模型下载" class="headerlink" title="2.2.2 模型下载"></a>2.2.2 模型下载</h3><p>可以在 Ollama 官网下载模型，也可以通过 Ollama 命令下载模型，这里我们使用命令下载：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载模型</span></span><br><span class="line">ollama pull deepseek-r1:32b</span><br></pre></td></tr></table></figure><p>这里需要等待一段下载，看网速，一般至少需要几个小时。<br><img src="/assets/img/ailearn/ai-learn02-1.png" alt="alt text"></p><h2 id="2-3-docker安装"><a href="#2-3-docker安装" class="headerlink" title="2.3 docker安装"></a>2.3 docker安装</h2><p>Docker是一个开源的应用容器引擎，可以方便的将应用打包成容器，然后部署到不同的机器上，实现应用的跨平台部署。</p><p>后面大模型 Web UI应用部署会使用到 Docker，因此这里也简单介绍一下 Docker 的安装。</p><p>具体安装步骤可以参考官方教程：<a href="https://docs.docker.com/get-started/get-docker/">https://docs.docker.com/get-started/get-docker/</a></p><p>国内安装可以参考：<a href="https://www.runoob.com/docker/ubuntu-docker-install.html">https://www.runoob.com/docker/ubuntu-docker-install.html</a></p><h1 id="3-部署模型"><a href="#3-部署模型" class="headerlink" title="3. 部署模型"></a>3. 部署模型</h1><p>其实在上一个步骤已经完成模型下载，想要让其运行，则需要进行以下操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动  ollama api服务</span></span><br><span class="line">ollama serve --</span><br><span class="line"><span class="comment"># </span></span><br><span class="line">ollama run deepseek-r1:32b</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="3-1-测试模型服务"><a href="#3-1-测试模型服务" class="headerlink" title="3.1 测试模型服务"></a>3.1 测试模型服务</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:11434/api/generate -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;deepseek-r1:32b&quot;,</span></span><br><span class="line"><span class="string">  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型会返回相关结果</span></span><br></pre></td></tr></table></figure><h2 id="3-2-设置允许其他机器访问"><a href="#3-2-设置允许其他机器访问" class="headerlink" title="3.2 设置允许其他机器访问"></a>3.2 设置允许其他机器访问</h2><p>经过上面的设置，ollama服务已经启动，但是其他机器无法访问，因此需要设置允许其他机器访问，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置允许其他机器访问</span></span><br><span class="line">vim /etc/systemd/system/ollama.service</span><br><span class="line"><span class="comment"># 写入如下内容</span></span><br><span class="line">[Service]</span><br><span class="line">Environment=<span class="string">&quot;OLLAMA_HOST=0.0.0.0:11434&quot;</span></span><br><span class="line"><span class="comment"># 重启 ollama api服务</span></span><br><span class="line">systemctl restart ollama</span><br><span class="line"><span class="comment"># 或者如下命令， 关闭或启动 ollama api服务</span></span><br><span class="line">systemctl stop ollama</span><br><span class="line">systemctl start ollama</span><br></pre></td></tr></table></figure><h1 id="4-可视化UI"><a href="#4-可视化UI" class="headerlink" title="4. 可视化UI"></a>4. 可视化UI</h1><p>有了大模型服务，但是只能在命令窗口里输入聊天感觉不行，那么如何可视化呢？这里推荐一个工具：Dify，官方地址：<a href="https://github.com/langgenius/dify。">https://github.com/langgenius/dify。</a></p><h2 id="4-1-部署-Dify"><a href="#4-1-部署-Dify" class="headerlink" title="4.1  部署 Dify"></a>4.1  部署 Dify</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/langgenius/dify.git</span><br><span class="line"><span class="built_in">cd</span> dify</span><br><span class="line"><span class="built_in">cd</span> docker</span><br><span class="line"><span class="built_in">cp</span> .env.example .<span class="built_in">env</span></span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><p>启动成功后就可以访问了：<a href="http://localhost/install">http://localhost/install</a> 进行配置管理员账号。</p><h2 id="4-2-设置模型供应商"><a href="#4-2-设置模型供应商" class="headerlink" title="4.2 设置模型供应商"></a>4.2 设置模型供应商</h2><p>在右上角找我的头像，点击设置，选择模型供应商，选择 <code>Ollama</code>，添加模型命名为<code>DeepSeek-32B</code>，具体如下：</p><p><img src="/assets/img/ailearn/ai-learn02-2.png" alt="alt text"></p><p>配置完后，就可以开始创建应用，并将模型应用到应用中。</p><h2 id="4-3-创建应用"><a href="#4-3-创建应用" class="headerlink" title="4.3  创建应用"></a>4.3  创建应用</h2><p>在首页创建空白应用 -&gt;  选择聊天助手 -&gt; 进入应用后在右上角选择 <code>DeepSeek-32B</code>模型，就可以开始聊天。</p><p><img src="/assets/img/ailearn/ai-learn02-3.png" alt="alt text"><br><img src="/assets/img/ailearn/ai-learn02-4.png" alt="alt text"></p><p>聊天界面如下：</p><p><img src="/assets/img/ailearn/ai-learn02-5.png" alt="alt text"></p><p>具体聊天效果，响应速度还可以可以的。</p><p><img src="/assets/img/ailearn/ai-learn02-6.png" alt="alt text"></p><p>Dify.AI 还支持很多功能，比如：录入知识库，让聊天助手能基于知识库回答用户的问题，这样子就可以变成智能客服了。其他功能大家都可以自己去摸索，后面 AI 系列学习也会继续介绍。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1官方文档</a></li><li><a href="https://www.cnblogs.com/shanren/p/18702244">必看：DeepSeek-R1本地部署！超详细教程~</a></li><li><a href="https://www.cnblogs.com/shanren/p/18702244">手把手带你用DeepSeek-R1和Ollama搭建本地应用，一文搞定！</a></li><li><a href="https://www.cnblogs.com/shook/p/18700561">DeepSeek-R1本地部署简单使用</a></li><li><a href="https://juejin.cn/post/7278244851041189949">从教师到学生：神奇的“知识蒸馏”之旅——原理详解篇</a></li><li><a href="https://wiki.eryajf.net/pages/97047e/">带你认识本地大语言模型框架Ollama(可直接上手)</a></li><li><a href="https://github.com/ollama/ollama/blob/main/docs">Ollama官方文档</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;之前两篇文章对于 AI 有了初步的了解，但是如何应用 AI 技术呢？去调用 openai 的接口，或者国内的接口都需要付费，而且接口调用次数有限，所以我们需要部署一个本地的大模型，这样就可以自己使用，而且可以自己控制调用次数。正好最近 DeepSeek比较火热，所以我们就在本地尝试部署一下 DeepSeek-R1大模型吧。&lt;/p&gt;
&lt;h1 id=&quot;1-了解DeepSeek-R1&quot;&gt;&lt;a href=&quot;#1-了解DeepSeek-R1&quot; class=&quot;headerlink&quot; title=&quot;1. 了解DeepSeek-R1&quot;&gt;&lt;/a&gt;1. 了解DeepSeek-R1&lt;/h1&gt;&lt;p&gt;在开始之前，我们需要先了解一下 &lt;a href=&quot;https://www.deepseek.com/&quot;&gt;DeepSeek&lt;/a&gt;, 官网介绍是这么写的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;探索未至之境，DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。&lt;br&gt;在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同时它开源了几个大模型，主要如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-R1&quot;&gt;DeepSeek-R1&lt;/a&gt;，总参数671B，上下文长度最大支持128K，是在性能对齐 OpenAI-o1 正式版。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V3&quot;&gt;DeepSeek-V3&lt;/a&gt;，DeepSeek 上一代开源大模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，作为最新的大模型，DeepSeek-R1 是我们部署的首选。接下来我们继续了解 DeepSeek-R1。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>赚钱学习系列 01篇 - 重新认识自己</title>
    <link href="https://www.qborfy.com/money/01.html"/>
    <id>https://www.qborfy.com/money/01.html</id>
    <published>2025-02-08T07:00:00.000Z</published>
    <updated>2025-02-11T09:46:06.376Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://juejin.cn/post/7456417337676595212">程序员的出路</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerli</summary>
      
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="赚钱学习" scheme="https://www.qborfy.com/tags/%E8%B5%9A%E9%92%B1%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>01篇 AI从零开始 - 基础知识和环境准备</title>
    <link href="https://www.qborfy.com/ailearn/ai-learn01.html"/>
    <id>https://www.qborfy.com/ailearn/ai-learn01.html</id>
    <published>2025-02-06T07:00:00.000Z</published>
    <updated>2025-02-12T14:29:18.352Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="AI-基础知识"><a href="#AI-基础知识" class="headerlink" title="AI 基础知识"></a>AI 基础知识</h1><p>不管学习什么技术，每个技术里面都会包含一些专业术语， 了解这些术语，有助于我们更好的理解技术，以及更好的使用技术。</p><span id="more"></span><p>针对 AI 领域，我们先从网上找到一篇AI技术应用文章《<a href="https://cloud.tencent.com/developer/article/2420057">使用RAG-GPT和Ollama搭建智能客服</a>》，摘取部分精要内容，如下：</p><blockquote><p>智能文档的在线检索流程可以用一张图说明，上图中展示了一个完整的问答流程：</p><ul><li>用户发起query</li><li>结合Bot实际应用场景，评估是否对query进行rewrite</li><li>Retieval模块根据query检索出Indexing中的相关的文档</li><li>将召回的文档进行Reranking</li><li>并且根据relevance score进行过滤，过滤掉低质的文档</li><li>形成合适的Prompt后输入到LLM大模型中，最后生成答案</li></ul></blockquote><h2 id="术语解释"><a href="#术语解释" class="headerlink" title="术语解释"></a>术语解释</h2><ul><li>LLM大模型：指模型参数量特别大，比如 GPT-4 模型参数量达到了 1750 亿，而 GPT-3 模型参数量只有 175 亿。</li><li>GPT：Generative Pre-trained Transformer，生成式预训练Transformer，是 OpenAI 开发的一种语言模型，可以用于文本生成、文本摘要、文本翻译、文本分类、问答系统等任务。</li><li>Transformer：一种基于注意力机制的神经网络结构，可以用于自然语言处理、语音识别、图像识别等任务。</li><li>RAG：Retrieval-Augmented Generation，检索增强生成，是一种基于检索和生成相结合的文本生成方法，可以用于文本摘要、问答系统等任务。</li><li>知识库：指一个存储大量知识的数据集，可以用于问答系统、文本生成等任务。</li><li>召回：指从大规模数据中找到与查询相关的信息的过程，可以用于问答系统、文本生成等任务。</li><li>Prompt：指一个文本或一个问题的描述，可以用于文本生成、问答系统等任务。</li><li>重写：指对用户输入的query进行一定的修改，以更好地匹配模型，可以用于问答系统、文本生成等任务。</li><li>模型训练：指使用大量数据对模型进行训练，以使其能够更好地完成任务的过程，可以用于机器学习、深度学习等任务。</li><li>Agent：智能体，是一种通用问题解决器。从软件工程的角度看来，智能体是一种基于大语言模型的，具备规划思考能力、记忆能力、使用工具函数的能力，能自主完成给定任务的计算机程序。</li><li>Function Calling：是一种实现大型语言模型连接外部工具的机制。通过 API 调用 LLM 时，调用方可以描述函数，包括函数的功能描述、请求参数说明、响应参数说明，让 LLM 根据用户的输入，合适地选择调用哪个函数，同时理解用户的自然语言，并转换为调用函数的请求参数（通过 JSON 格式返回）。调用方使用 LLM 返回的函数名称和参数，调用函数并得到响应。最后，如果需求，把函数的响应传给 LLM，让 LLM 组织成自然语言回复用户。</li></ul><h2 id="技术框架"><a href="#技术框架" class="headerlink" title="技术框架"></a>技术框架</h2><ul><li>Huging Face: 在模型，数据集和应用程序的机器学习社区，提供了一个非常流行的开源库，名为“Transformers”。这个库最初是以提供各种基于 Transformer 架构的预训练模型（如 BERT、GPT-2、RoBERTa 等）为目的而创建的。随着时间的推移，它已经发展成为一个全面的机器学习库，支持多种语言模型和任务。官网站点为：<a href="https://huggingface.com/">https://huggingface.com/</a></li><li>LangChain: 是一个基于大型语言模型（LLM）开发应用程序的框架，简化了LLM应用程序生命周期的每个阶段。 官网站点为：<a href="https://python.langchain.com/docs/introduction/">https://python.langchain.com/docs/introduction/</a></li><li>Ollama: Ollama 是一个开源的本地大语言模型运行框架，专为在本地机器上便捷部署和运行大型语言模型（LLM）而设计。 官网站点为：<a href="https://ollama.com/">https://ollama.com/</a></li></ul><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h2 id="1-安装-Python"><a href="#1-安装-Python" class="headerlink" title="1. 安装 Python"></a>1. 安装 Python</h2><blockquote><p>Python 是一种高级编程语言，它具有简单易学、易于扩展、丰富的库和工具包等优点，被广泛应用于数据科学、机器学习、Web开发、自动化测试等领域。</p></blockquote><h3 id="1-1-普通安装"><a href="#1-1-普通安装" class="headerlink" title="1.1 普通安装"></a>1.1 普通安装</h3><p>Python 的安装非常简单，只需要在官方网站下载安装包，然后按照提示进行安装即可。以下是安装 Python 的步骤：</p><ol><li>打开 Python 官方网站：<a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li><li>点击 “Downloads” 按钮，进入下载页面</li><li>选择适合自己操作系统的 Python 版本，然后点击 “Download” 按钮</li><li>下载完成后，双击安装包，按照提示进行安装</li><li>安装完成后，打开命令行终端，输入 <code>python --version</code> 命令，如果输出了 Python 的版本号，说明 Python 已经安装成功</li></ol><h3 id="1-2-通过-Anaconda-安装"><a href="#1-2-通过-Anaconda-安装" class="headerlink" title="1.2 通过 Anaconda 安装"></a>1.2 通过 Anaconda 安装</h3><p>Anaconda 是一个开源的 Python 发行版，它包含了 Python 和许多常用的科学计算库，可以方便地安装和管理 Python 环境。</p><p>一般国内选择清华源（<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/），国外选择官方源（https://）。">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/），国外选择官方源（https://）。</a></p><p>Mac或 Linux安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 Anaconda</span></span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2021.11-Linux-x86_64.sh</span><br><span class="line">bash Anaconda3-2021.11-Linux-x86_64.sh</span><br><span class="line"><span class="comment"># 激活 Anaconda</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="comment"># 查看 Anaconda 版本</span></span><br><span class="line">conda --version</span><br></pre></td></tr></table></figure><p>Windows安装则参考这个教程： <a href="https://www.cnblogs.com/ajianbeyourself/p/17654155.html">https://www.cnblogs.com/ajianbeyourself/p/17654155.html</a></p><p>正常开发我建议是使用 Anaconda，因为 Anaconda 会自动管理 Python 环境，方便切换和安装不同的 Python 版本。</p><h2 id="2-安装-PyTorch"><a href="#2-安装-PyTorch" class="headerlink" title="2. 安装 PyTorch"></a>2. 安装 PyTorch</h2><p>PyTorch 是一个基于 Python 的深度学习框架，它提供了丰富的工具和库，可以方便地实现深度学习模型和算法。目前如果需要本地部署大模型的话，建议还是在本地环境安装 PyTorch。</p><p>可以通过pip安装，也可以通过conda安装，这里推荐使用conda安装，因为conda安装会自动管理依赖，方便切换和安装不同的 PyTorch 版本。</p><p>安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 PyTorch</span></span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch</span><br><span class="line"><span class="comment"># 查看 PyTorch 版本</span></span><br><span class="line">python -c <span class="string">&quot;import torch; print(torch.__version__)&quot;</span></span><br></pre></td></tr></table></figure><p>关于 PyTorch的教学文档，可以参考这个文档：<a href="https://datawhalechina.github.io/thorough-pytorch/">https://datawhalechina.github.io/thorough-pytorch/</a></p><h2 id="3-安装-Hugging-Face-Transformers"><a href="#3-安装-Hugging-Face-Transformers" class="headerlink" title="3. 安装 Hugging Face Transformers"></a>3. 安装 Hugging Face Transformers</h2><p>Hugging Face Transformers 是由Hugging Face 创建的深度学习开源框架。 它提供API 和工具来下载最先进的预训练模型，并进一步调整它们以最大限度地提高性能。 这些模型支持不同模式下的常见任务，例如自然语言处理、计算机视觉、音频和多模式应用程序。</p><p>安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 Hugging Face Transformers</span></span><br><span class="line">pip install transformers</span><br><span class="line"><span class="comment"># 查看 Hugging Face Transformers 版本</span></span><br><span class="line">python -c <span class="string">&quot;import transformers; print(transformers.__version__)&quot;</span></span><br></pre></td></tr></table></figure><h2 id="4-安装-Langchain"><a href="#4-安装-Langchain" class="headerlink" title="4. 安装 Langchain"></a>4. 安装 Langchain</h2><p>LangChain 是一种软件框架，旨在帮助创建利用大型语言模型 (LLM) 的应用程序。 LangChain 的优势在于其广泛的集成和功能。 它包括 API 包装器、Web 抓取子系统、代码分析工具、文档摘要工具等。 它还支持 OpenAI、Anthropic、HuggingFace 等现成的大型语言模型以及各种数据源和类型。</p><p>安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 LangChain</span></span><br><span class="line">pip install langchain</span><br><span class="line"><span class="comment"># 查看 LangChain 版本</span></span><br><span class="line">python -c <span class="string">&quot;import langchain; print(langchain.__version__)&quot;</span></span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://learn.microsoft.com/zh-cn/azure/databricks/machine-learning/train-model/huggingface/">什么是 Hugging Face Transformers</a></li><li><a href="https://cloud.tencent.com/developer/article/2422923">一文带你了解大模型——智能体（Agent）</a></li><li><a href="https://learn.microsoft.com/zh-cn/azure/databricks/large-language-models/langchain">用于 LLM 开发的 Azure Databricks 上的 LangChain</a></li><li><a href="https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng">LangChain 的中文入门教程</a></li><li><a href="https://www.langchain.asia/get_started/introduction">LangChain 🦜️🔗 中文网</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;AI-基础知识&quot;&gt;&lt;a href=&quot;#AI-基础知识&quot; class=&quot;headerlink&quot; title=&quot;AI 基础知识&quot;&gt;&lt;/a&gt;AI 基础知识&lt;/h1&gt;&lt;p&gt;不管学习什么技术，每个技术里面都会包含一些专业术语， 了解这些术语，有助于我们更好的理解技术，以及更好的使用技术。&lt;/p&gt;</summary>
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="AI学习" scheme="https://www.qborfy.com/tags/AI%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ学习</title>
    <link href="https://www.qborfy.com/test.html"/>
    <id>https://www.qborfy.com/test.html</id>
    <published>2024-09-06T08:21:13.000Z</published>
    <updated>2024-09-06T08:21:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>可以源码安装（python环境）<br>service rabbitmq-server start</p><p>也可以docker安装，依赖docker环境</p><p>运行成功后有两个端口：</p><ol><li>5672，其他客户端调用链接使用</li><li>15672，后台管理系统使用</li></ol><p>支持配置文件，参考docker内配置文件路径： /etc/rabbitmq/conf.d/10-defaults.conf</p><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>virtual host<br>类似mysql支持多个用户访问同一个实例（IP+PORT）的不同数据库</p><p>exchange交换机<br>类似一种邮箱或存储队列，支持加入或转发推送能力</p><h1 id="五种消息类型"><a href="#五种消息类型" class="headerlink" title="五种消息类型"></a>五种消息类型</h1><h2 id="HelloWorld"><a href="#HelloWorld" class="headerlink" title="HelloWorld"></a>HelloWorld</h2><p>正常邮箱类型， 生产者往RabbitMQ队列增加消息，但是消费者不一定要及时看</p><h2 id="Worker模型"><a href="#Worker模型" class="headerlink" title="Worker模型"></a>Worker模型</h2><p>对比 邮箱模型， 只要生产消息 就会马上竞争消费掉，可以有效的避免消息堆积</p><h2 id="订阅模型"><a href="#订阅模型" class="headerlink" title="订阅模型"></a>订阅模型</h2><p>Fanout（广播模型）: 将消息发送给绑定给交换机的所有队列(因为他们使用的是同一个RoutingKey)。</p><p>Direct（定向）: 把消息发送给拥有指定Routing Key (路由键)的队列。</p><p>Topic（通配符）: 把消息传递给拥有 符合Routing Patten(路由模式)的队列。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;p&gt;可以源码安装（python环境）&lt;br&gt;service rabbitmq-server start&lt;/p&gt;
&lt;p&gt;也可以docker安装，依</summary>
      
    
    
    
    
    <category term="学习总结" scheme="https://www.qborfy.com/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>翻译-服务器端请求伪造 (SSRF)</title>
    <link href="https://www.qborfy.com/today_2024/20240814.html"/>
    <id>https://www.qborfy.com/today_2024/20240814.html</id>
    <published>2024-09-06T08:20:08.000Z</published>
    <updated>2024-09-06T08:20:13.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>做一个有温度和有干货的技术分享作者 —— <a href="https://qborfy.com">Qborfy</a></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近在研究SSR，发现很多服务都会用到SSRF，所以就顺便研究了一下SSRF。</p><p>下面是一篇从网络上翻译过来的文章， 大家简单参考了解。</p><span id="more"></span><h1 id="什么是-SSRF？"><a href="#什么是-SSRF？" class="headerlink" title="什么是 SSRF？"></a>什么是 SSRF？</h1><p>服务器端请求伪造是一种 Web 安全漏洞，允许攻击者导致服务器端，从而发出非法请求。</p><p>在典型的 SSRF 攻击中，攻击者可能会导致服务器连接到仅供内部使用的服务。在其他情况下，他们可能能够强制服务器连接到任意外部系统。这可能会泄露敏感数据，例如授权凭据。</p><img src="/assets/img/server-side request forgery.svg"><h1 id="SSRF攻击的危害"><a href="#SSRF攻击的危害" class="headerlink" title="SSRF攻击的危害"></a>SSRF攻击的危害</h1><p>SSRF 攻击通常会导致未经授权的操作或组织内的数据访问。这可能位于易受攻击的网站中，也可能位于该网站可以与之通信的其他后端系统上。在某些情况下，SSRF 漏洞可能允许攻击者执行任意命令。</p><p>与外部第三方系统连接，如：接入第三方的登录等， 更容易受到SSRF漏洞攻击。</p><h1 id="常见的SSRF攻击"><a href="#常见的SSRF攻击" class="headerlink" title="常见的SSRF攻击"></a>常见的SSRF攻击</h1><p>SSRF 攻击通常利用信任关系， 去攻击的网站， 并执行未经授权的操作。这些信任关系可能与服务器相关，或者与同一组织内的其他后端系统相关。</p><h2 id="针对服务器的-SSRF-攻击"><a href="#针对服务器的-SSRF-攻击" class="headerlink" title="针对服务器的 SSRF 攻击"></a>针对服务器的 SSRF 攻击</h2><p>在针对服务器的 SSRF 攻击中，攻击者会通过内部络接口向网站的服务器发出 HTTP 请求。这通常涉及提供带有主机名的 URL，例如127.0.0.1 或localhost。</p><p>例如，想象一个购物网站，它允许用户查看特定商店中是否有商品的库存。为了提供信息，网站必须查询各种后端 REST API。它通过前端 HTTP 请求将 URL 当成参数传递到后端，然后执行 API 端点来实现此目的。当用户查看商品的库存状态时，他们的浏览器会发出以下请求：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://stock.weliketoshop.net:8080/product/stock/check%3FproductId%3D6%26storeId%3D1</span><br></pre></td></tr></table></figure><p>这会导致服务器向指定的 URL 发出请求，检索库存状态，并将其返回给用户。</p><p>在此示例中，攻击者可以修改请求以指定服务器本地的 URL：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://localhost/admin</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>服务器获取<code>/admin</code> URL 的内容并将其返回给用户。</p><p>攻击者可以访问<code>/admin</code> URL，但管理功能通常只有经过身份验证的用户才能访问。这意味着攻击者不会看到任何感兴趣的内容。但是，如果对/admin URL 的请求来自本地计算机，则会绕过正常的访问控制。应用程序授予对管理功能的完全访问权限，因为请求似乎源自受信任的位置。</p><p>为什么应用程序会以这种方式运行，并隐式信任来自本地计算机的请求？出现这种情况的原因有多种：</p><ul><li>鉴权控制只在前端网关层控制，却没有在服务器上做任何限制。</li><li>出于容灾设计，允许来自本地的任何用户无需登录即可进行管理访问，只有完全信任的用户会直接来自服务器。</li><li>后管系统与用户系统用不同的端口号，并且用户可能无法直接访问。</li></ul><p>这种信任关系（其中源自本地计算机的请求的处理方式与普通请求不同）通常使 SSRF 成为严重漏洞。</p><h2 id="针对其他后端系统的-SSRF-攻击"><a href="#针对其他后端系统的-SSRF-攻击" class="headerlink" title="针对其他后端系统的 SSRF 攻击"></a>针对其他后端系统的 SSRF 攻击</h2><p>在某些情况下，应用程序服务器能够与用户无法直接访问的后端系统进行交互。这些系统通常具有不可访问的专用 IP 地址。后端系统通常受到网络拓扑的保护，因此它们的安全状况通常较弱。在许多情况下，内部后端系统包含敏感功能，任何能够与系统交互的人都可以在无需身份验证的情况下访问这些功能。</p><p>在前面的示例中，假设后端 URL <a href="https://192.168.0.68/admin">https://192.168.0.68/admin</a> 有一个管理界面。攻击者可以提交以下请求来利用SSRF漏洞，并访问管理界面：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://192.168.0.68/admin</span><br></pre></td></tr></table></figure><h1 id="规避常见的-SSRF-防御"><a href="#规避常见的-SSRF-防御" class="headerlink" title="规避常见的 SSRF 防御"></a>规避常见的 SSRF 防御</h1><p>包含 SSRF 行为以及旨在防止恶意利用的防御措施的应用程序很常见。通常，这些防御措施是可以被规避的。</p><h2 id="具有基于黑名单的输入过滤器的-SSRF"><a href="#具有基于黑名单的输入过滤器的-SSRF" class="headerlink" title="具有基于黑名单的输入过滤器的 SSRF"></a>具有基于黑名单的输入过滤器的 SSRF</h2><p>某些应用程序会阻止包含主机名（如127.0.0.1和localhost或敏感 URL（如<code>/admin</code>的输入，可如下设计：</p><ul><li>使用替代 IP 表示形式127.0.0.1 ，例如2130706433 、 017700000001或127.1等，作为超管系统等别名。</li><li>注册您自己的域名，解析为127.0.0.1 。您可以使用spoofed.burpcollaborator.net来实现此目的。</li><li>使用 URL 编码或大小写变化来混淆被阻止的字符串。</li><li>提供您控制的 URL，该 URL 会重定向到目标 URL。尝试对目标 URL 使用不同的重定向代码以及不同的协议。例如，在重定向过程中从http:切换到https: URL 已被证明可以绕过某些反 SSRF 过滤器。</li></ul><h2 id="具有基于白名单的输入过滤器的-SSRF"><a href="#具有基于白名单的输入过滤器的-SSRF" class="headerlink" title="具有基于白名单的输入过滤器的 SSRF"></a>具有基于白名单的输入过滤器的 SSRF</h2><p>某些应用程序仅允许匹配允许值白名单的输入。过滤器可能会在输入的开头或包含在输入中查找匹配项。您可以通过利用 URL 解析中的不一致来绕过此过滤器。</p><p>URL 规范包含许多在 URL 使用此方法实现即席解析和验证时可能会被忽略的功能：</p><ul><li>您可以使用@字符将凭据嵌入到 URL 中的主机名之前。例如： <code>https://expected-host:fakepassword@evil-host</code></li><li>您可以使用#字符来指示 URL 片段。例如： <code>https://evil-host#expected-host</code></li><li>您可以利用 DNS 命名层次结构将所需的输入放入您控制的完全限定的 DNS 名称中。例如：<code>https://expected-host.evil-host</code></li><li>您可以对字符进行 URL 编码以混淆 URL 解析代码。如果实现过滤器的代码处理 URL 编码字符的方式与执行后端 HTTP 请求的代码不同，则这尤其有用。您还可以尝试双编码字符；一些服务器对它们收到的输入进行递归 URL 解码，这可能会导致进一步的差异。</li><li>您可以结合使用这些技术。</li></ul><h2 id="通过开放重定向绕过-SSRF-过滤器"><a href="#通过开放重定向绕过-SSRF-过滤器" class="headerlink" title="通过开放重定向绕过 SSRF 过滤器"></a>通过开放重定向绕过 SSRF 过滤器</h2><p>有时可以通过利用开放重定向漏洞来绕过基于过滤器的防御。</p><p>在前面的示例中，假设用户提交的 URL 经过严格验证，以防止恶意利用 SSRF 行为。但是，允许 URL 的应用程序包含开放重定向漏洞。如果用于发出后端 HTTP 请求的 API 支持重定向，您可以构造一个满足过滤器的 URL，并将请求重定向到所需的后端目标。</p><p>例如，该应用程序包含一个开放重定向漏洞，其中以下 URL：<code>/product/nextProduct?currentProductId=6&amp;path=http://evil-user.net</code></p><p>返回重定向到：<code>http://evil-user.net</code></p><p>您可以利用开放重定向漏洞绕过URL过滤，利用SSRF漏洞，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST /product/stock HTTP/1.0</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">Content-Length: 118</span><br><span class="line"></span><br><span class="line">stockApi=http://weliketoshop.net/product/nextProduct?currentProductId=6&amp;path=http://192.168.0.68/admin</span><br></pre></td></tr></table></figure><p>此 SSRF 漏洞之所以有效，是因为应用程序首先验证提供的stockAPI URL 是否位于允许的域上（事实确实如此）。然后，应用程序请求提供的 URL，这会触发开放重定向。它遵循重定向，并向攻击者选择的内部 URL 发出请求。</p><h2 id="隐藏的SSRF-漏洞"><a href="#隐藏的SSRF-漏洞" class="headerlink" title="隐藏的SSRF 漏洞"></a>隐藏的SSRF 漏洞</h2><p>如果您可以导致应用程序向提供的 URL 发出后端 HTTP 请求，但后端请求的响应未在应用程序的前端响应中返回，则会出现 隐藏的SSRF漏洞。</p><p>隐藏的SSRF更难利用，但有时会导致在服务器或其他后端组件上完全远程执行代码。</p><h2 id="寻找-SSRF-漏洞的隐藏攻击点"><a href="#寻找-SSRF-漏洞的隐藏攻击点" class="headerlink" title="寻找 SSRF 漏洞的隐藏攻击点"></a>寻找 SSRF 漏洞的隐藏攻击点</h2><p>许多服务器端请求伪造漏洞很容易被发现，因为应用程序的正常流量涉及包含完整URL的请求参数。 SSRF 的其他示例更难找到。</p><h3 id="请求中的部分-URL"><a href="#请求中的部分-URL" class="headerlink" title="请求中的部分 URL"></a>请求中的部分 URL</h3><p>有时，应用程序仅将主机名或 URL 路径的一部分放入请求参数中。然后，提交的值会在服务器端合并到所请求的完整 URL 中。如果该值很容易被识别为主机名或 URL 路径，则潜在的攻击面可能是显而易见的。但是，作为完整 SSRF 的可利用性可能会受到限制，因为您无法控制所请求的整个 URL。</p><h3 id="数据格式中的-URL"><a href="#数据格式中的-URL" class="headerlink" title="数据格式中的 URL"></a>数据格式中的 URL</h3><p>某些应用程序以某种规范传输数据，该规范允许包含数据解析器可能请求该格式的 URL。一个明显的例子是 XML 数据格式，它已广泛用于 Web 应用程序中，用于将结构化数据从客户端传输到服务器。当应用程序接受 XML 格式的数据并解析它时，它可能容易受到XXE 注入的攻击。它还可能容易通过 XXE 受到 SSRF 的攻击。当我们研究 XXE 注入漏洞时，我们将更详细地介绍这一点。</p><h3 id="通过-Referer-标头进行-SSRF"><a href="#通过-Referer-标头进行-SSRF" class="headerlink" title="通过 Referer 标头进行 SSRF"></a>通过 Referer 标头进行 SSRF</h3><p>一些应用程序使用服务器端分析软件来跟踪访问者。该软件通常会在请求中记录 Referer 标头，因此它可以跟踪传入链接。通常，分析软件会访问 Referer 标头中出现的任何第三方 URL。这样做通常是为了分析引用站点的内容，包括传入链接中使用的锚文本。因此，Referer 标头通常是 SSRF 漏洞的有用攻击面。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://portswigger.net/web-security/ssrf">原文地址： 《服务器端请求伪造 (SSRF)》</a></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;做一个有温度和有干货的技术分享作者 —— &lt;a href=&quot;https://qborfy.com&quot;&gt;Qborfy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近在研究SSR，发现很多服务都会用到SSRF，所以就顺便研究了一下SSRF。&lt;/p&gt;
&lt;p&gt;下面是一篇从网络上翻译过来的文章， 大家简单参考了解。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术分享" scheme="https://www.qborfy.com/tags/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    <category term="每日更新" scheme="https://www.qborfy.com/tags/%E6%AF%8F%E6%97%A5%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
</feed>
