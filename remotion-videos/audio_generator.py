#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨è§†é¢‘éŸ³é¢‘ç”Ÿæˆå·¥å…·
ä½¿ç”¨Qwen3-TTSæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡åœºæ™¯è§£è¯´éŸ³é¢‘

ğŸ¯ åŠŸèƒ½ç‰¹ç‚¹ï¼š
â€¢ æ”¯æŒä¸¤ç§æ¨¡å¼ï¼šæ–‡æœ¬æ¨¡å¼å’Œå­—å¹•æ¨¡å¼
â€¢ æ–‡æœ¬æ¨¡å¼ï¼šç›´æ¥ä»é…ç½®çš„æ–‡æœ¬ç”ŸæˆéŸ³é¢‘
â€¢ å­—å¹•æ¨¡å¼ï¼šä»å­—å¹•JSONæ–‡ä»¶è¯»å–æ–‡æœ¬ç”ŸæˆéŸ³é¢‘ï¼Œå¹¶è‡ªåŠ¨æ›´æ–°æ—¶é—´æˆ³
â€¢ éŸ³é¢‘æ—¶é•¿æ§åˆ¶ï¼šé¿å…éŸ³é¢‘è¿‡é•¿ï¼Œè‡ªåŠ¨è£å‰ªè¶…è¿‡30ç§’çš„éŸ³é¢‘
â€¢ è¯­éŸ³è´¨é‡ä¼˜åŒ–ï¼šé™ä½æ¸©åº¦å‚æ•°ï¼Œæé«˜è¯­éŸ³ç¨³å®šæ€§
â€¢ ä¸¥æ ¼é‡‡æ ·ç­–ç•¥ï¼šå‡å°‘è¯­éŸ³ä¹±ç å’Œé‡å¤é—®é¢˜
â€¢ éŸ³é¢‘åå¤„ç†ï¼šéŸ³é‡æ ‡å‡†åŒ–ã€ä½é€šæ»¤æ³¢æé«˜æ¸…æ™°åº¦
â€¢ é‡è¯•æœºåˆ¶ï¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„ä»»åŠ¡ï¼Œæé«˜æˆåŠŸç‡
â€¢ æ™ºèƒ½è·³è¿‡ï¼šè‡ªåŠ¨æ£€æµ‹å·²å­˜åœ¨çš„éŸ³é¢‘æ–‡ä»¶

è¯­éŸ³è§’è‰²ï¼šç»Ÿä¸€ä½¿ç”¨æ¸©æŸ”å¥³ç”Ÿè§’è‰²ï¼Œç¡®ä¿è¯­éŸ³é£æ ¼ä¸€è‡´
éŸ³é¢‘æ—¶é•¿ï¼šæ™ºèƒ½æ§åˆ¶ï¼Œé¿å…è¿‡é•¿éŸ³é¢‘ï¼Œç¡®ä¿ä¸è§†é¢‘åŒæ­¥
æ¨¡å‹é…ç½®ï¼šä½¿ç”¨æœ¬åœ°ä¸‹è½½çš„Qwen3-TTSæ¨¡å‹ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import torch
import soundfile as sf
from qwen_tts import Qwen3TTSModel
import librosa
import numpy as np
from tqdm import tqdm

# Qwen3-TTSæ¨¡å‹å®ä¾‹ï¼ˆå…¨å±€å•ä¾‹ï¼‰
_qwen_model = None


class AudioGeneratorConfig:
    """éŸ³é¢‘ç”Ÿæˆé…ç½®ç±»"""
    
    def __init__(
        self,
        video_name: str,
        output_dir: str,
        model_path: str = "./Qwen3-TTS-12Hz-1.7B-Base",
        reference_audio: str = "./borfy.mp3",
        reference_text: str = "5åˆ†é’Ÿ AIï¼Œæ¯å¤©ææ‡‚ä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼ä»Šå¤©æˆ‘ä»¬å­¦ä¹ ï¼Œ ç›‘ç£å­¦ä¹ ã€‚",
        mode: str = "text"  # "text" æˆ– "caption"
    ):
        """
        åˆå§‹åŒ–é…ç½®
        
        Args:
            video_name: è§†é¢‘åç§°
            output_dir: è¾“å‡ºç›®å½•
            model_path: TTSæ¨¡å‹è·¯å¾„
            reference_audio: å‚è€ƒéŸ³é¢‘è·¯å¾„
            reference_text: å‚è€ƒæ–‡æœ¬
            mode: ç”Ÿæˆæ¨¡å¼ï¼Œ"text"ï¼ˆæ–‡æœ¬æ¨¡å¼ï¼‰æˆ– "caption"ï¼ˆå­—å¹•æ¨¡å¼ï¼‰
        """
        self.video_name = video_name
        self.output_dir = output_dir
        self.model_path = model_path
        self.reference_audio = reference_audio
        self.reference_text = reference_text
        self.mode = mode


class AudioGenerator:
    """é€šç”¨éŸ³é¢‘ç”Ÿæˆå™¨"""
    
    def __init__(self, config: AudioGeneratorConfig):
        """åˆå§‹åŒ–éŸ³é¢‘ç”Ÿæˆå™¨"""
        self.config = config
        self.model = None
    
    def get_model(self) -> Optional[Qwen3TTSModel]:
        """è·å–æˆ–åˆå§‹åŒ–Qwen3-TTSæ¨¡å‹"""
        global _qwen_model
        
        if _qwen_model is None:
            try:
                print("ğŸ”§ åŠ è½½Qwen3-TTSæ¨¡å‹...")
                
                model_kwargs = {
                    "pretrained_model_name_or_path": self.config.model_path,
                    "device_map": "auto",
                    "torch_dtype": torch.bfloat16,
                    "low_cpu_mem_usage": True,
                }
                
                _qwen_model = Qwen3TTSModel.from_pretrained(**model_kwargs)
                print("âœ… Qwen3-TTSæ¨¡å‹åŠ è½½å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ Qwen3-TTSæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                print("ğŸ’¡ å»ºè®®æ£€æŸ¥ï¼š")
                print(f"   1. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆ{self.config.model_path}ï¼‰")
                print("   2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
                print("   3. ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")
                return None
        
        return _qwen_model
    
    def load_caption_text(self, caption_file: str) -> Optional[str]:
        """ä»å­—å¹•JSONæ–‡ä»¶ä¸­è¯»å–å¹¶åˆå¹¶æ–‡æœ¬"""
        try:
            with open(caption_file, 'r', encoding='utf-8') as f:
                captions = json.load(f)
            
            # åˆå¹¶æ‰€æœ‰å­—å¹•æ–‡æœ¬ï¼Œç”¨é€—å·åˆ†éš”
            text_parts = [caption['text'] for caption in captions]
            full_text = "ï¼Œ".join(text_parts)
            
            return full_text
        except Exception as e:
            print(f"âŒ è¯»å–å­—å¹•æ–‡ä»¶å¤±è´¥ {caption_file}: {e}")
            return None
    
    def update_caption_timestamps(
        self, 
        caption_file: str, 
        audio_duration_ms: int
    ) -> bool:
        """æ ¹æ®éŸ³é¢‘æ—¶é•¿æ›´æ–°å­—å¹•æ—¶é—´æˆ³"""
        try:
            # è¯»å–å­—å¹•æ–‡ä»¶
            with open(caption_file, 'r', encoding='utf-8') as f:
                captions = json.load(f)
            
            if not captions:
                print(f"âš ï¸  å­—å¹•æ–‡ä»¶ä¸ºç©º: {caption_file}")
                return False
            
            # è·å–åŸå§‹å­—å¹•çš„æ€»æ—¶é•¿ï¼ˆå…¼å®¹ä¸åŒçš„å­—æ®µåï¼‰
            last_caption = captions[-1]
            if 'endMs' in last_caption:
                original_duration_ms = last_caption['endMs']
                time_fields = ['startMs', 'endMs', 'timestampMs']
            elif 'end' in last_caption:
                original_duration_ms = last_caption['end']
                time_fields = ['start', 'end']
            else:
                print(f"âš ï¸  æ— æ³•è¯†åˆ«å­—å¹•æ—¶é—´å­—æ®µæ ¼å¼")
                return False
            
            # å¦‚æœéŸ³é¢‘æ—¶é•¿ä¸åŸå§‹æ—¶é•¿ç›¸å·®ä¸å¤§ï¼ˆÂ±10%ï¼‰ï¼Œåˆ™ä¸æ›´æ–°
            duration_diff_ratio = abs(audio_duration_ms - original_duration_ms) / original_duration_ms
            if duration_diff_ratio < 0.1:
                print(f"   å­—å¹•æ—¶é•¿ä¸éŸ³é¢‘æ—¶é•¿æ¥è¿‘ï¼Œæ— éœ€æ›´æ–° (å·®å¼‚: {duration_diff_ratio*100:.1f}%)")
                return True
            
            # è®¡ç®—æ—¶é—´ç¼©æ”¾æ¯”ä¾‹
            scale_ratio = audio_duration_ms / original_duration_ms
            print(f"   åŸå§‹æ—¶é•¿: {original_duration_ms}ms, éŸ³é¢‘æ—¶é•¿: {audio_duration_ms}ms, ç¼©æ”¾æ¯”ä¾‹: {scale_ratio:.2f}")
            
            # æ›´æ–°æ‰€æœ‰å­—å¹•çš„æ—¶é—´æˆ³
            for caption in captions:
                for field in time_fields:
                    if field in caption:
                        caption[field] = int(caption[field] * scale_ratio)
            
            # ä¿å­˜æ›´æ–°åçš„å­—å¹•æ–‡ä»¶
            with open(caption_file, 'w', encoding='utf-8') as f:
                json.dump(captions, f, ensure_ascii=False, indent=2)
            
            print(f"âœ“ å­—å¹•æ—¶é—´æˆ³å·²æ›´æ–°: {caption_file}")
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°å­—å¹•æ—¶é—´æˆ³å¤±è´¥ {caption_file}: {e}")
            return False
    
    def generate_tts_audio(
        self, 
        text: str, 
        output_path: str, 
        max_retries: int = 3
    ) -> Tuple[bool, int]:
        """
        ä½¿ç”¨Qwen3-TTSç”ŸæˆéŸ³é¢‘
        
        Returns:
            (success, audio_duration_ms): æˆåŠŸæ ‡å¿—å’ŒéŸ³é¢‘æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
        """
        for attempt in range(max_retries):
            model = self.get_model()
            if model is None:
                return False, 0
            
            print(f"ğŸ”„ å°è¯•ç”Ÿæˆè¯­éŸ³ (ç¬¬{attempt + 1}æ¬¡)...")
            
            try:
                wavs, sr = model.generate_voice_clone(
                    ref_audio=self.config.reference_audio,
                    ref_text=self.config.reference_text,
                    text=text,
                    language="chinese",
                    max_new_tokens=512,
                    do_sample=True,
                    top_k=10,
                    top_p=0.7,
                    temperature=0.3,
                    repetition_penalty=1.5,
                    subtalker_dosample=True,
                    subtalker_top_k=10,
                    subtalker_top_p=0.7,
                    subtalker_temperature=0.3,
                )
                
                # ä¿å­˜éŸ³é¢‘
                sf.write(output_path, wavs[0], sr)
                
                # éŸ³é¢‘åå¤„ç†
                audio_duration_seconds = 0
                try:
                    audio, sr_loaded = librosa.load(output_path, sr=None)
                    
                    # æ£€æŸ¥éŸ³é¢‘æ—¶é•¿
                    audio_duration_seconds = len(audio) / sr_loaded
                    print(f"ğŸ“Š éŸ³é¢‘æ—¶é•¿: {audio_duration_seconds:.2f}ç§’")
                    
                    # å¦‚æœéŸ³é¢‘è¿‡é•¿ï¼Œè¿›è¡Œè£å‰ªï¼ˆæœ€å¤§30ç§’ï¼‰
                    if audio_duration_seconds > 30:
                        print("âš ï¸  éŸ³é¢‘è¿‡é•¿ï¼Œè¿›è¡Œè£å‰ª...")
                        max_samples = int(30 * sr_loaded)
                        audio = audio[:max_samples]
                        audio_duration_seconds = len(audio) / sr_loaded
                        print(f"âœ“ è£å‰ªåæ—¶é•¿: {audio_duration_seconds:.2f}ç§’")
                    
                    # éŸ³é‡æ ‡å‡†åŒ–åˆ°-3dB
                    audio_normalized = librosa.util.normalize(audio) * 0.7
                    
                    # æ·»åŠ è½»å¾®çš„ä½é€šæ»¤æ³¢ï¼Œæé«˜è¯­éŸ³æ¸…æ™°åº¦
                    audio_filtered = librosa.effects.preemphasis(audio_normalized, coef=0.97)
                    
                    sf.write(output_path, audio_filtered, sr_loaded)
                    print(f"âœ“ éŸ³é¢‘åå¤„ç†å®Œæˆ: {output_path}")
                    
                    # æ£€æŸ¥éŸ³é¢‘è´¨é‡
                    if audio_duration_seconds < 1.0:
                        print("âš ï¸  éŸ³é¢‘è¿‡çŸ­ï¼Œå¯èƒ½ç”Ÿæˆå¤±è´¥")
                        continue
                        
                except Exception as e:
                    print(f"âš ï¸  éŸ³é¢‘åå¤„ç†å¤±è´¥ï¼Œä½†åŸå§‹éŸ³é¢‘å·²ä¿å­˜: {e}")
                
                print(f"âœ“ ç”ŸæˆéŸ³é¢‘: {output_path}")
                return True, int(audio_duration_seconds * 1000)
                
            except Exception as e:
                print(f"âŒ ç¬¬{attempt + 1}æ¬¡ç”Ÿæˆå¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    print("ğŸ”„ ç­‰å¾…2ç§’åé‡è¯•...")
                    import time
                    time.sleep(2)
        
        return False, 0
    
    def get_audio_duration_ms(self, audio_path: str) -> Optional[int]:
        """è·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰"""
        try:
            audio, sr = librosa.load(audio_path, sr=None)
            duration_seconds = len(audio) / sr
            duration_ms = int(duration_seconds * 1000)
            return duration_ms
        except Exception as e:
            print(f"âŒ è¯»å–éŸ³é¢‘æ—¶é•¿å¤±è´¥ {audio_path}: {e}")
            return None
    
    def generate_audio_with_captions(
        self,
        text: str,
        audio_output_path: str,
        caption_output_path: str,
        reference_audio: Optional[str] = None,
        speed: float = 1.0
    ) -> bool:
        """
        ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            audio_output_path: éŸ³é¢‘è¾“å‡ºè·¯å¾„
            caption_output_path: å­—å¹•è¾“å‡ºè·¯å¾„
            reference_audio: å‚è€ƒéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
            speed: è¯­é€Ÿï¼ˆæš‚æœªå®ç°ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # å¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘ï¼Œæ›´æ–°é…ç½®
        if reference_audio:
            self.config.reference_audio = reference_audio
        
        # ç”ŸæˆéŸ³é¢‘
        success, audio_duration_ms = self.generate_tts_audio(text, audio_output_path)
        if not success:
            return False
        
        # ç”Ÿæˆå­—å¹•æ–‡ä»¶ï¼ˆç®€å•çš„å•å¥å­—å¹•ï¼‰
        try:
            captions = [{
                "text": text,
                "startMs": 0,
                "endMs": audio_duration_ms,
                "timestampMs": 0
            }]
            
            with open(caption_output_path, 'w', encoding='utf-8') as f:
                json.dump(captions, f, ensure_ascii=False, indent=2)
            
            print(f"âœ“ å­—å¹•æ–‡ä»¶ç”Ÿæˆ: {caption_output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ å­—å¹•æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def generate_from_config(
        self, 
        scenes: Dict[str, Dict[str, str]]
    ) -> Tuple[int, int, int]:
        """
        æ ¹æ®åœºæ™¯é…ç½®ç”ŸæˆéŸ³é¢‘
        
        Args:
            scenes: åœºæ™¯é…ç½®å­—å…¸ï¼Œæ ¼å¼ï¼š
                {
                    "scene1": {
                        "name": "åœºæ™¯åç§°",
                        "text": "æ–‡æœ¬å†…å®¹",  # æ–‡æœ¬æ¨¡å¼
                        "caption_file": "å­—å¹•æ–‡ä»¶è·¯å¾„",  # å­—å¹•æ¨¡å¼
                        "output_file": "è¾“å‡ºæ–‡ä»¶è·¯å¾„"
                    }
                }
        
        Returns:
            (success_count, skipped_count, failed_count): æˆåŠŸã€è·³è¿‡ã€å¤±è´¥çš„æ•°é‡
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path(self.config.output_dir).mkdir(parents=True, exist_ok=True)
        
        success_count = 0
        skipped_count = 0
        failed_count = 0
        
        for scene_id, scene_config in tqdm(scenes.items(), desc="å¤„ç†éŸ³é¢‘"):
            scene_name = scene_config.get('name', scene_id)
            output_file = scene_config['output_file']
            
            # æ„å»ºå®Œæ•´çš„è¾“å‡ºè·¯å¾„
            if not output_file.startswith('/'):
                output_path = os.path.join(self.config.output_dir, output_file)
            else:
                output_path = output_file
            
            print(f"\nğŸ“ å¤„ç†åœºæ™¯: {scene_id} - {scene_name}")
            
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if Path(output_path).exists():
                print(f"âœ“ éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨: {output_path}")
                
                # è¯»å–éŸ³é¢‘æ—¶é•¿
                audio_duration_ms = self.get_audio_duration_ms(output_path)
                if audio_duration_ms is not None:
                    print(f"ğŸ“Š éŸ³é¢‘æ—¶é•¿: {audio_duration_ms/1000:.2f}ç§’")
                    
                    # å¦‚æœæ˜¯å­—å¹•æ¨¡å¼ï¼Œæ›´æ–°å­—å¹•æ—¶é—´æˆ³
                    if self.config.mode == "caption" and 'caption_file' in scene_config:
                        caption_file = scene_config['caption_file']
                        if not caption_file.startswith('/'):
                            caption_file = os.path.join(self.config.output_dir, caption_file)
                        
                        print(f"ğŸ”„ æ›´æ–°å­—å¹•æ—¶é—´æˆ³...")
                        if self.update_caption_timestamps(caption_file, audio_duration_ms):
                            success_count += 1
                            skipped_count += 1
                            print(f"âœ… åœºæ™¯å¤„ç†å®Œæˆï¼ˆä½¿ç”¨å·²å­˜åœ¨éŸ³é¢‘ï¼‰")
                            continue
                    else:
                        success_count += 1
                        skipped_count += 1
                        print(f"âœ… åœºæ™¯å¤„ç†å®Œæˆï¼ˆä½¿ç”¨å·²å­˜åœ¨éŸ³é¢‘ï¼‰")
                        continue
            
            # è·å–æ–‡æœ¬å†…å®¹
            if self.config.mode == "caption" and 'caption_file' in scene_config:
                # å­—å¹•æ¨¡å¼ï¼šä»å­—å¹•æ–‡ä»¶è¯»å–
                caption_file = scene_config['caption_file']
                if not caption_file.startswith('/'):
                    caption_file = os.path.join(self.config.output_dir, caption_file)
                
                text = self.load_caption_text(caption_file)
                if text is None:
                    print(f"âŒ è·³è¿‡åœºæ™¯ {scene_id}ï¼šæ— æ³•è¯»å–å­—å¹•æ–‡ä»¶")
                    failed_count += 1
                    continue
            elif 'text' in scene_config:
                # æ–‡æœ¬æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨é…ç½®çš„æ–‡æœ¬
                text = scene_config['text']
            else:
                print(f"âŒ è·³è¿‡åœºæ™¯ {scene_id}ï¼šç¼ºå°‘æ–‡æœ¬æˆ–å­—å¹•æ–‡ä»¶é…ç½®")
                failed_count += 1
                continue
            
            print(f"   æ–‡æœ¬: {text[:50]}...")
            
            # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
            if len(text) > 200:
                print("âš ï¸  æ–‡æœ¬è¿‡é•¿ï¼Œå¯èƒ½å½±å“éŸ³é¢‘è´¨é‡")
            
            # ç”ŸæˆTTSéŸ³é¢‘
            success, audio_duration_ms = self.generate_tts_audio(text, output_path)
            if success:
                print(f"âœ… åœºæ™¯éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {output_path}")
                success_count += 1
                
                # å¦‚æœæ˜¯å­—å¹•æ¨¡å¼ï¼Œæ›´æ–°å­—å¹•æ—¶é—´æˆ³
                if self.config.mode == "caption" and 'caption_file' in scene_config:
                    caption_file = scene_config['caption_file']
                    if not caption_file.startswith('/'):
                        caption_file = os.path.join(self.config.output_dir, caption_file)
                    
                    print(f"ğŸ”„ æ›´æ–°å­—å¹•æ—¶é—´æˆ³...")
                    self.update_caption_timestamps(caption_file, audio_duration_ms)
            else:
                print(f"âŒ åœºæ™¯éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {scene_id}")
                failed_count += 1
        
        return success_count, skipped_count, failed_count


def check_dependencies() -> bool:
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    required_packages = [
        "torch", "transformers", "accelerate", "qwen_tts", 
        "soundfile", "librosa", "numpy", "tqdm"
    ]
    
    print("ğŸ” æ£€æŸ¥Qwen3-TTSä¾èµ–åŒ…...")
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ“ {package}")
        except ImportError:
            missing_packages.append(package)
            print(f"âœ— {package}")
    
    if missing_packages:
        print(f"\nâŒ ç¼ºå°‘å¿…éœ€ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("ğŸ’¡ è¯·è¿è¡Œ: pip install -r requirement.txt")
        return False
    
    print("âœ… æ‰€æœ‰å¿…éœ€ä¾èµ–åŒ…å·²å®‰è£…")
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"ğŸ® GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    return True


# å¯¼å‡ºå…¼å®¹æ—§æ¥å£çš„å‡½æ•°
def generate_audio_with_captions(
    text: str,
    audio_output_path: str,
    caption_output_path: str,
    reference_audio: str = "./borfy.mp3",
    speed: float = 1.0
) -> bool:
    """
    ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
    
    Args:
        text: è¦è½¬æ¢çš„æ–‡æœ¬
        audio_output_path: éŸ³é¢‘è¾“å‡ºè·¯å¾„
        caption_output_path: å­—å¹•è¾“å‡ºè·¯å¾„
        reference_audio: å‚è€ƒéŸ³é¢‘è·¯å¾„
        speed: è¯­é€Ÿï¼ˆæš‚æœªå®ç°ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    config = AudioGeneratorConfig(
        video_name="default",
        output_dir=os.path.dirname(audio_output_path),
        reference_audio=reference_audio,
        mode="text"
    )
    
    generator = AudioGenerator(config)
    return generator.generate_audio_with_captions(
        text=text,
        audio_output_path=audio_output_path,
        caption_output_path=caption_output_path,
        reference_audio=reference_audio,
        speed=speed
    )


if __name__ == "__main__":
    print("=" * 60)
    print("é€šç”¨è§†é¢‘éŸ³é¢‘ç”Ÿæˆå·¥å…·")
    print("=" * 60)
    print("ğŸ¤– ä½¿ç”¨Qwen3-TTSæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³è§£è¯´")
    print("ğŸ¯ æ”¯æŒæ–‡æœ¬æ¨¡å¼å’Œå­—å¹•æ¨¡å¼")
    print("=" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("   è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„éŸ³é¢‘ç”Ÿæˆå·¥å…·åº“")
    print("   è¯·åœ¨å…¶ä»–è„šæœ¬ä¸­å¯¼å…¥å¹¶ä½¿ç”¨ AudioGenerator ç±»")
    print("   æˆ–ä½¿ç”¨ generate_audio_with_captions å‡½æ•°")
    print("\nç¤ºä¾‹:")
    print("   from audio_generator import AudioGenerator, AudioGeneratorConfig")
    print("   config = AudioGeneratorConfig(...)")
    print("   generator = AudioGenerator(config)")
    print("   generator.generate_from_config(scenes)")
