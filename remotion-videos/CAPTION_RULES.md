# 字幕规则说明

## 字幕显示模式

视频字幕采用**逐行显示模式**，每次只显示一句完整的话。

### 规则要点

1. **逐行显示**：每个字幕条目显示一句完整的话
2. **不合并显示**：不将多句话合并在一起显示
3. **时长同步**：每句话的时长根据音频实际时长设置
4. **语音同步**：确保字幕与语音完全同步

### 字幕文件格式

```json
[
  {
    "text": "这是第一句话",
    "startMs": 0,
    "endMs": 2000,
    "timestampMs": 0,
    "confidence": 1.0
  },
  {
    "text": "这是第二句话",
    "startMs": 2000,
    "endMs": 4000,
    "timestampMs": 2000,
    "confidence": 1.0
  }
]
```

### 字段说明

- `text`: 字幕文本内容（一句完整的话）
- `startMs`: 开始时间（毫秒）
- `endMs`: 结束时间（毫秒）
- `timestampMs`: 时间戳（毫秒，通常等于startMs）
- `confidence`: 置信度（0-1之间，通常为1.0）

### 字幕样式

- **位置**：底部居中，距离底部100px
- **字体大小**：30px
- **字体粗细**：粗体（bold）
- **颜色**：白色
- **背景**：半透明黑色（rgba(0,0,0,0.6)）
- **阴影**：2px 2px 4px rgba(0,0,0,0.8)
- **圆角**：10px
- **内边距**：12px 25px
- **最大宽度**：95%

### 时长计算规则

每个场景的时长 = 音频时长 + 30帧缓冲时间（1秒）

这个缓冲时间确保：
1. 声音能够播放完整
2. 观看用户有时间反应和理解内容

### 示例

#### Scene 1 字幕示例

```json
[
  {
    "text": "无监督学习",
    "startMs": 0,
    "endMs": 2180,
    "timestampMs": 0,
    "confidence": 1.0
  },
  {
    "text": "5分钟AI",
    "startMs": 2180,
    "endMs": 3633,
    "timestampMs": 2180,
    "confidence": 1.0
  },
  {
    "text": "每天搞懂一个知识点",
    "startMs": 3633,
    "endMs": 5813,
    "timestampMs": 3633,
    "confidence": 1.0
  }
]
```

每句话独立显示，不会合并。

### 技术实现

字幕组件 `CaptionComponent.tsx` 使用以下逻辑：

1. 根据当前帧计算时间（毫秒）
2. 查找当前时间范围内的字幕条目
3. 显示匹配的单条字幕文本
4. 不使用 TikTok 风格的合并显示

### 注意事项

1. 字幕文件必须放在 `public/UnsupervisedLearningVideo/` 目录下
2. 文件命名格式：`scene{N}-captions.json`
3. 时间戳必须精确，确保与音频同步
4. 每句话的时长应该合理，不要太短或太长
5. 字幕文本应该简洁明了，易于阅读

### 生成字幕的工具

使用 `tts_unsupervised.py` 脚本可以：
1. 生成音频文件
2. 自动更新字幕文件的时长
3. 确保音频和字幕同步

```bash
python tts_unsupervised.py
```

### 后续规则

**所有新的字幕文件都必须遵循此规则**：
- 逐行显示
- 一句一条
- 时长精确
- 语音同步
